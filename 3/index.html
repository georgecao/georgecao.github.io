<!DOCTYPE html>
<html lang="zh_CN">
  <head>
    <meta charset="utf-8"/>
    <title>REPLoop</title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="author" content="乔治">
    <meta name="keywords" content="REPL,REPLoop,George,乔治">
    <meta name="generator" content="JBake v2.7.0.1">
    <meta property=og:locale content=zh_CN>
    <!-- Le styles -->
    <link href="../css/bootstrap.min.css" rel="stylesheet">
    <link href="../css/asciidoctor.css" rel="stylesheet">
    <link href="../css/base.css" rel="stylesheet">
    <link href="../css/prettify.css" rel="stylesheet">

    <!-- HTML5 shim, for IE6-8 support of HTML5 elements -->
    <!--[if lt IE 9]>
      <script src="../js/html5shiv.min.js"></script>
    <![endif]-->

    <!-- Fav and touch icons -->
    <!--<link rel="apple-touch-icon-precomposed" sizes="144x144" href="../assets/ico/apple-touch-icon-144-precomposed.png">
    <link rel="apple-touch-icon-precomposed" sizes="114x114" href="../assets/ico/apple-touch-icon-114-precomposed.png">
    <link rel="apple-touch-icon-precomposed" sizes="72x72" href="../assets/ico/apple-touch-icon-72-precomposed.png">
    <link rel="apple-touch-icon-precomposed" href="../assets/ico/apple-touch-icon-57-precomposed.png">-->
    <link rel="shortcut icon" href="../img/favicon.svg">
    <script data-ad-client="ca-pub-2350040335860411" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  </head>
  <body onload="prettyPrint()">
    <div id="wrap">	
	<!-- Fixed navbar -->
    <div class="navbar navbar-default navbar-fixed-top" role="navigation">
      <div class="container">
        <div class="navbar-header">
          <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </button>
          <a class="navbar-brand" href="../">REPLoop</a>
        </div>
        <div class="navbar-collapse collapse">
          <ul class="nav navbar-nav">
            <li><a href="../index.html">博客</a></li>
            <li><a href="../archive.html">归档</a></li>
            <li><a href="../tags/index.html">标签</a></li>
            <li><a href="../about.html">关于</a></li>
            <li><a href="../feed.xml">订阅</a></li>
          </ul>
        </div><!--/.nav-collapse -->
      </div>
    </div>
    <div class="container">
  		<a href="blog/2020/02/understanding-memory-reordering.html"><h1>理解内存重排序以及为什写无锁多线程代码时很重要</h1></a>
  		<p>
			<a href="/about.html"><strong>George Cao</strong></a>于2020年02月29日
					<span class="badge badge-dark">内存模型</span>
					<span class="badge badge-dark">多线程</span>
					<span class="badge badge-dark">原子性</span>
					<span class="badge badge-dark">多线程</span>
					<span class="badge badge-dark">内存重排序</span>
		</p>
  		<p><div id="preamble"> 
 <div class="sectionbody"> 
  <div class="paragraph"> 
   <p>此系列前一篇文章中，<a href="https://www.reploop.org/blog/2020/02/lock-free-multithreading-with-atomic-operations.html">用原子操作实现无锁多线程</a>，我介绍了无锁多线程：并发软件中线程同步的底层机制。</p> 
  </div> 
  <div class="paragraph"> 
   <p>基于 <strong>原子操作</strong>，也就是CPU直接执行的不能细分为更小步骤的机器指令，相比传统的同步原语如<a href="https://www.reploop.org/blog/2020/02/introduction-to-thread-synchronization.html">互斥锁和信号量</a>，无锁多线程提供了更快和更细粒度控制的同步机制。</p> 
  </div> 
  <div class="paragraph"> 
   <p>一如既往的，能力越大，责任越大。无锁编码中你更接近本质，因此理解机器是如何工作的以及机器的特性是非常有益的。</p> 
  </div> 
  <div class="paragraph"> 
   <p>本文中我会介绍一些硬件（和软件）对无锁代码产生的非常重要的副作用。这也是惊叹计算机内部小型世界的复杂性的机会。</p> 
  </div> 
  <div class="ulist"> 
   <div class="title">
    本系列中的其他文章
   </div> 
   <ul> 
    <li> <p><a href="https://www.reploop.org/blog/2020/02/a-gentle-introduction-to-multithreading.html">多线程简介</a> - 一步一步走进并发的世界</p> </li> 
    <li> <p><a href="https://www.reploop.org/blog/2020/02/introduction-to-thread-synchronization.html">线程同步简介</a> - 多线程应用中最常见的并发控制方法之一</p> </li> 
    <li> <p><a href="https://www.reploop.org/blog/2020/02/lock-free-multithreading-with-atomic-operations.html">用原子操作实现无锁多线程</a> - 底层线程同步</p> </li> 
   </ul> 
  </div> 
 </div> 
</div> 
<div class="sect1"> 
 <h2 id="内存重排序或者不愉快的惊喜">内存重排序或者不愉快的惊喜</h2> 
 <div class="sectionbody"> 
  <div class="paragraph"> 
   <p>现有编程课程首先要教你的是计算机如何 <strong>顺序</strong> 执行用源代码写出的指令。一段程序就是文本文件中的一系列操作，处理器会从上到下执行这些操作。</p> 
  </div> 
  <div class="paragraph"> 
   <p>意外的，这常常是一个谎言：你的机器有能力按需调整 <em>一些</em> 底层指令的执行顺序，尤其是内存读取的时候。这个诡异的修改，叫做 <strong>内存重排序</strong>，会发生在硬件和软件层面，且经常是因为性能的原因。</p> 
  </div> 
  <div class="paragraph"> 
   <p>内存重排序开发出来旨在利用那些原本要浪费掉的指令周期。这个技巧能大幅度提升你程序的执行速度；另一方面，它可能对无锁多线程造成严重破坏。我们马上能看到为啥。</p> 
  </div> 
  <div class="paragraph"> 
   <p>我们先来仔细看一下内存重排序这种不可预知的行为存在的原因。</p> 
  </div> 
 </div> 
</div> 
<div class="sect1"> 
 <h2 id="内存重排序总结">内存重排序总结</h2> 
 <div class="sectionbody"> 
  <div class="paragraph"> 
   <p>程序想要执行，必须加载进 <strong>主内存</strong>。CPU的任务就是执行存储在那的指令，同时在必要的时候读数据或者写数据。</p> 
  </div> 
  <div class="paragraph"> 
   <p>随着时间的推移，这种类型的内存和处理器比起来变得非常慢。例如，一个现代的CPU一个纳秒内能够执行10个指令，但是需要纳秒的许多倍时间从此内存中读取数据！工程师们不喜欢时间就这样浪费了，所以他们给CPU配上了容量很小但是速度非常快的特殊内存，我们称之为 <strong>缓存</strong>。</p> 
  </div> 
  <div class="paragraph"> 
   <p>缓存是处理为了避免和慢速主内存交互，用来存储CPU最常用的数据的。如果CPU需要从主内存读取或者写入主内存，它首先检测缓存看是不是有所需数据的副本。如果有，处理器就直接从缓存读取或者写入缓存而不会等待相比较慢的主内存的响应。</p> 
  </div> 
  <div class="paragraph"> 
   <p>现代CPU有多个核心组成的，<strong>核心(core)</strong> 是真正执行计算的组件。每个核心拥有自己的独立缓存，如下图所示：</p> 
  </div> 
  <div class="imageblock"> 
   <div class="content"> 
    <img src="https://www.reploop.org/blog/2020/02/images/cpu-cache-main-memory.png" alt="CPU" width="cache and main memory"> 
   </div> 
   <div class="title">
    Figure 1. 多个核心通过缓存和主内存交互的简化模型。这也叫做共享内存系统，因为主内存被多个实体访问。
   </div> 
  </div> 
  <div class="paragraph"> 
   <p>总而言之，缓存能让计算机运行更快。更准确的说，缓存通过让处理器总是繁忙和高效来帮助处理器不要因为等待主内存响应而浪费宝贵的时间。</p> 
  </div> 
  <div class="sect2"> 
   <h3 id="内存重排序作为优化技巧">内存重排序作为优化技巧</h3> 
   <div class="paragraph"> 
    <p>很明显缓存机制增加了多核场景下系统的复杂性。现在你需要详细的规则来决定数据如何在不同的缓存间流动，来保证每个核心有最新版本的数据，称之为 <strong>缓存一致性协议</strong>，他可能引发非常大的性能下降。所以工程师们就设想用内存重排序来充分发挥每个核心的作用。</p> 
   </div> 
   <div class="paragraph"> 
    <p>内存重排序为什么会发生的理由有很多个。比如，考虑2个核心同时访问同样的内存块。核心A从内存读取数据，核心B写入数据到内存。内存一致性协议可能会强制核心A等待核心B将本地修改的数据写回到主内存，这样核心A就能读到最新的数据。等待的核心可以选择提前执行其他内存指令，而不是浪费珍贵的指令周期啥也不做，即使这个和你在程序中明确的代码顺序不一样。</p> 
   </div> 
   <div class="paragraph"> 
    <p>当特定的优化开启了，编译器和虚拟机也会自用重排序指令。这些变化发生在编译时，可以通过汇编码或者字节码很容易的看到。软件内存重排序是充分利用底层硬件可能提供的特性来让你的代码运行的更快。</p> 
   </div> 
  </div> 
 </div> 
</div> 
<div class="sect1"> 
 <h2 id="硬件内存重排序的具体样例">硬件内存重排序的具体样例</h2> 
 <div class="sectionbody"> 
  <div class="paragraph"> 
   <p>考虑下面用硬件伪代码写的样例。程序的每一个步骤都对应一个处理器指令：</p> 
  </div> 
  <div class="listingblock"> 
   <div class="content"> 
    <pre class="prettyprint highlight"><code data-lang="c">x = 0
v = false

thread_one():
    while load(v) == false:
        continue
    print(load(x))

thread_two():
    store(x, 1)
    store(v, true)</code></pre> 
   </div> 
  </div> 
  <div class="paragraph"> 
   <p>上面的代码片段中2个线程并发运行在2个不同的核心上。第1个线程等待第2个线程将 <code>v</code> 设置为 <code>true</code>。让我们假设 <code>store()</code> 和 <code>load()</code> 都是读取内存的原子的CPU指令。</p> 
  </div> 
  <div class="paragraph"> 
   <p>你预计第1个线程在屏幕上打印出什么？如果他在线程2之前启动（ <a href="https://internalpointers.com/post/gentle-introduction-multithreading#race-conditions">并不总是这样的</a>），就没有正确的答案了。如果没有重排序发生，你可能会看到1。尽管如此，如果第2个线程中的存储指令发生重排序，<code>v</code> 的更新也可能发生在 <code>x</code> 之前，打印语句可能打印出 <code>0</code>。相似的，内存重排序也可能发生在第1个线程中，也就是 <code>x</code> 的加载可能发生在 <code>v</code> 的检测之前。</p> 
  </div> 
 </div> 
</div> 
<div class="sect1"> 
 <h2 id="内存重排序对多线程的影响">内存重排序对多线程的影响</h2> 
 <div class="sectionbody"> 
  <div class="paragraph"> 
   <p>硬件内存重排序在单核计算机上没有问题，因为线程是操作系统控制的软件结构。CPU就是收到连续的内存指令流。指令还是可以被重新排序，不过要符合一个基本规则：给定内核的内存访问看上去就像和代码写的一样。所以，内存重排序可能会发生，但是只在不影响最终结果的前提下。</p> 
  </div> 
  <div class="paragraph"> 
   <p>这个规则也适用于多核场景下的每个单核，但不适用于不同操作同时跑在独立的硬件上的情况（ <a href="https://internalpointers.com/post/gentle-introduction-multithreading#what-threads-are-used-for">真并行(true parallelism)</a>）。让你的线程跑在两个物理内核上，你就会碰到上面样例中的各种诡异问题，更不用说让编译器和虚拟机执行重排序了。</p> 
  </div> 
  <div class="paragraph"> 
   <p>常规的如互斥锁和信号量等<a href="https://www.reploop.org/blog/2020/02/introduction-to-thread-synchronization.html">锁同步机制</a>是设计用来处理硬件和软件层面的内存重排序的。毕竟他们是上层技术。</p> 
  </div> 
  <div class="paragraph"> 
   <p>不过，应用无锁方案的多线程程序更接近底层：就像<a href="https://www.reploop.org/blog/2020/02/lock-free-multithreading-with-atomic-operations.html">上一篇文章</a>看到的，它利用存储和加载原子指令来同步线程。 搞笑的是这些操作可能被重排序，从而破坏了你的严谨计划。</p> 
  </div> 
 </div> 
</div> 
<div class="sect1"> 
 <h2 id="如何解决内存重排序的问题">如何解决内存重排序的问题</h2> 
 <div class="sectionbody"> 
  <div class="paragraph"> 
   <p>你肯定不会基于一些随机变化的东西构建你的同步机制。这个问题可以通过引入 <strong>内存屏障</strong> 的方式来解决。内存屏障是强制处理器按照可预知的方式访问内存的CPU指令。内存屏障的工作方式类似路障：内存屏障之前的指令保证先于内存屏障之后的指令执行。</p> 
  </div> 
  <div class="paragraph"> 
   <p>内存屏障是硬件层面的：你得直接和CPU交互。这是一个底层的解决方案，且不利用程序的可移植性。解决这个问题最好的方式是软件层次，利用操作系统，编译器或虚拟机提供的工具。</p> 
  </div> 
  <div class="paragraph"> 
   <p>尽管如此，软件工具也仅仅是中间阶段。为了构建一个此问题的清晰的全景图，我们首先全局看一下所有可能在硬件或者软件系统中的内存场景。<strong>内存模型</strong> 在这个过程中发挥重要作用。</p> 
  </div> 
 </div> 
</div> 
<div class="sect1"> 
 <h2 id="内存模型">内存模型</h2> 
 <div class="sectionbody"> 
  <div class="paragraph"> 
   <p>内存模型是抽象的方式描述系统中涉及到访问和重排序内存可能或者不可能发生的事情。处理器和编程语言会实现一个，尤其是利用多线程技术的时候：内存模型同时适用于硬件和软件层面。</p> 
  </div> 
  <div class="paragraph"> 
   <p>当系统对改变内存操作顺序非常谨慎，我们说系统遵循 <strong>强内存模型</strong>。相反的，<strong>弱内存模型</strong> 中你可能碰到各种各样的重排序。比如，x86系列的处理器属于前一类，而ARM和PowerPC处理器则属于后一类。软件层面又是怎么样的呢？</p> 
  </div> 
  <div class="sect2"> 
   <h3 id="软件内存模型的好处">软件内存模型的好处</h3> 
   <div class="paragraph"> 
    <p>硬件内存模型存在的原因很明显，而对应的软件内存模型让你能够按需重排内存访问顺序。这个特性在你写无锁多线程代码的代码能帮很大的忙。</p> 
   </div> 
   <div class="paragraph"> 
    <p>例如，为了避免同步机制中不受欢迎的原子操作的重排序，编译器可以编译出遵循强内存模型的机器码。当底层硬件实现的是弱内存模型的时候，编译器会通过加入正确的内存屏障指令来最大限度的提供你需要的内存模型。编译器也负责软件层面的内存重排序指令。使用软件内存模型可以解耦硬件细节。</p> 
   </div> 
   <div class="paragraph"> 
    <p>基本上，所有的编程语言都会实现一种内存模型，某种意义上说，他们都遵循特定的规则来处理内存。一些编程语言也就到此为止了，因为他们不直接处理多线程。其他的比如 <a href="https://docs.oracle.com/javase/9/docs/api/java/lang/invoke/VarHandle.html">Java</a>， <a href="https://doc.rust-lang.org/nomicon/atomics.html">Rust</a>和 <a href="https://en.cppreference.com/w/cpp/atomic/memory_order">C++</a>等也会提供上述的控制内存重排序行为的工具。</p> 
   </div> 
  </div> 
 </div> 
</div> 
<div class="sect1"> 
 <h2 id="细粒度内存模型">细粒度内存模型</h2> 
 <div class="sectionbody"> 
  <div class="paragraph"> 
   <p>强和弱内存模型是对内存操作如何重排序的理论上的分类。具体到真实的编码，大多数支持原子操作的编程语言会提供3种控制内存重排序的方式。我们仔细看一下。</p> 
  </div> 
  <div class="sect2"> 
   <h3 id="1顺序一致">1）顺序一致</h3> 
   <div class="paragraph"> 
    <p>较少干扰的内存重排序方式就是根本不重排序。这是强内存模型的一种形式，称之为顺序一致：这正是解决上面提到的所有无锁多线程问题所需要的。禁用重排序能让你的多线程程序容易理解：源代码是按照书写顺序执行的。</p> 
   </div> 
   <div class="paragraph"> 
    <p>顺序一致给并行代码执行加了另外一个重要特性：它强制了所有线程中的所有内存原子操作的 <strong>整体顺序</strong>。为了更好理解这句话，考虑如下的硬件伪代码样例：</p> 
   </div> 
   <div class="listingblock"> 
    <div class="content"> 
     <pre class="prettyprint highlight"><code data-lang="c">x = 0
y = 0

thread_A:
    store(x, 1)

thread_B:
    store(y, 1)

thread_C:
    assert(load(x) == 1 &amp;&amp; load(y) == 0)

thread_D:
    assert(load(x) == 0 &amp;&amp; load(y) == 1)</code></pre> 
    </div> 
   </div> 
   <div class="paragraph"> 
    <p>我们暂时不考虑单个线程内的内存重排序，看一下全局情况。如果线程按照A-C-B-D的顺序运行，线程C能看到 <code>x == 1</code> 和 <code>y == 0</code>，这是因为线程C是在线程A和线程B之间运行的，因此线程C的断言不会失败。但是这也是问题所在：顺序一致强加的全局顺序迫使线程D看到与线程C一样的事件，因此线程D的断言会失败。线程D不可能看到和线程C不一样的存储顺序。换句话说，线性一致下，所有的线程都看到同样的东西。</p> 
   </div> 
   <div class="paragraph"> 
    <p>就像前面说过的，这是一个非常直观和自然的思考多线程执行的方式。尽管如此，顺序一致也取消了内存重排序带来的任何硬件或者软件优化：这通常会引起严重性能瓶颈。顺序一致有些时候是必要的，比如多生产者-多消费者情况下消费者必须按照生产者的生产顺序消费。</p> 
   </div> 
  </div> 
  <div class="sect2"> 
   <h3 id="2获取_释放顺序">2）获取-释放顺序</h3> 
   <div class="paragraph"> 
    <p><strong>获取-释放</strong> 是强和弱内存模型的中间状态。首先，获取-释放和顺序一致工作方式相似，除了没有全局执行顺序。我们在看一下上面的那个例子：在获取-释放情况下，线程D是允许看到不同于线程C的事件，因此线程D的断言有可能会通过。</p> 
   </div> 
   <div class="paragraph"> 
    <p>全局顺序的缺失其实是个副作用。获取-释放是针对 <em>特定</em> 共享原子变量在 <em>多个线程之间</em> 同步的。也就是说，你在线程A和线程C之间同步共享变量 <code>x</code>，使得线程C只能在线程A完成写入之后才读取。这种情况下，<code>y</code> 并没有考虑进去，所以你可碰到任何针对它的重排序。</p> 
   </div> 
   <div class="paragraph"> 
    <p>具体来说，支持这种有序性的编程语言允许你将内存访问标记为获取或者释放。当线程B触发某共享变量上标记为获取的原子加载操作，线程A中的同一个共享变量上标记为释放的原子存储可确保线程B将看到线程A执行的完整且不是重新排序的内存事件序列。我知道这比较烧脑，不过这是互斥锁的基础：关键区和它保护的区域就是用这个构建的（获取-释放名字来源于互斥锁术语，也就是获取和释放互斥锁）。</p> 
   </div> 
   <div class="paragraph"> 
    <p>获取-释放允许更多的优化机会，因为仅有部分内存重排序不被允许。换句话说，你的程序更不容易推理分析了。</p> 
   </div> 
  </div> 
  <div class="sect2"> 
   <h3 id="3松散顺序">3）松散顺序</h3> 
   <div class="paragraph"> 
    <p>还有一种弱内存模型的形式。<strong>松散顺序</strong> 的情况下，你写程序的时候根本不关心内存重排序。编译器和处理器可以尽可能的优化程序执行。当然了内存操作的原子特性是保留下来了：这在增加共享计数器的时候非常有用，这种情况下操作必须是原子的才能让其他线程不能看到未完成的中间状态。</p> 
   </div> 
   <div class="paragraph"> 
    <p>松散有序性不保证任何特定的内存重排序，所以这不是可以安全使用的线程同步工具。另一方面，这也允许使用任何内存技巧来提升你的多线程程序的性能。</p> 
   </div> 
  </div> 
 </div> 
</div> 
<div class="sect1"> 
 <h2 id="下一步">下一步？</h2> 
 <div class="sectionbody"> 
  <div class="paragraph"> 
   <p>这篇文章中，我想对内存重排序问题以及其存在的原因和它对无锁多线程的影响有一个全面的了解。接下来我会写一些使用原子操作的C++代码来实践一下。</p> 
  </div> 
  <div class="paragraph"> 
   <p>为什么是C++ ？因为C++语言近期引入了 <a href="https://en.cppreference.com/w/cpp/language/memormodel">非常详细的内存模型</a>，使得你能够细粒度的控制C++原子对象的内存重排序操作。我相信这是一个很好的方式去看顺序一致，获取-释放和松散有序在真实的场景下是如何一起工作的。祝我好运吧:)。</p> 
  </div> 
 </div> 
</div> 
<div class="sect1"> 
 <h2 id="参考">参考</h2> 
 <div class="sectionbody"> 
  <div class="ulist"> 
   <ul> 
    <li> <p>AA.VV. - <a href="https://www.morganclaypool.com/doi/abs/10.2200/S00346ED1V01Y201104CAC016">A Primer on Memory Consistency and Cache Coherence</a></p> </li> 
    <li> <p>AA. VV. - <a href="https://books.google.it/books?id=MMNiDwAAQBAJ">C++ Reactive Programming</a></p> </li> 
    <li> <p>Paul E. McKenney - <a href="http://www.puppetmastertrading.com/images/hwViewForSwHackers.pdf">Memory Barriers: a Hardware View for Software Hackers</a></p> </li> 
    <li> <p>cppreference.com - <a href="https://en.cppreference.com/w/cpp/atomic/memory_order">std::memory_order</a></p> </li> 
    <li> <p>GCC Wiki - <a href="https://gcc.gnu.org/wiki/Atomic/GCCMM/AtomicSync">Memory model synchronization modes</a></p> </li> 
    <li> <p>doc.rust-lang.org - <a href="https://doc.rust-lang.org/nomicon/atomics.html">Atomics</a></p> </li> 
    <li> <p>Herb Sutter - <a href="https://youtu.be/A8eCGOqgvH4?t=3419">Atomic Weapons 1 of 2</a></p> </li> 
    <li> <p>The ryg blog - <a href="https://fgiesen.wordpress.com/2014/07/07/cache-coherency/">Cache coherency primer</a></p> </li> 
    <li> <p>The ryg blog - <a href="https://fgiesen.wordpress.com/2014/08/18/atomics-and-contention/">Atomic operations and contention</a></p> </li> 
    <li> <p>Bartosz Milewski - <a href="https://bartoszmilewski.com/2008/12/01/c-atomics-and-memory-ordering/">C++ atomics and memory ordering</a></p> </li> 
    <li> <p>Bartosz Milewski - <a href="https://bartoszmilewski.com/2008/11/11/who-ordered-sequential-consistency/">Who ordered sequential consistency?</a></p> </li> 
    <li> <p>StackOverflow - <a href="https://stackoverflow.com/questions/30958375/memory-barriers-force-cache-coherency">Memory barriers force cache coherency?</a></p> </li> 
    <li> <p>StackOverflow - <a href="https://stackoverflow.com/questions/25345440/how-does-the-cache-coherency-protocol-enforce-atomicity">How does the cache coherency protocol enforce atomicity?</a></p> </li> 
    <li> <p>StackOverflow - <a href="https://stackoverflow.com/questions/42746793/does-a-memory-barrier-ensure-that-the-cache-coherence-has-been-completed">Does a memory barrier ensure that the cache coherence has been completed?</a></p> </li> 
    <li> <p>StackOverflow - <a href="https://stackoverflow.com/questions/6319146/c11-introduced-a-standardized-memory-model-what-does-it-mean-and-how-is-it-g">C11 introduced a standardized memory model. What does it mean? And how is it going to affect C programming?</a></p> </li> 
    <li> <p>StackOverflow - <a href="https://stackoverflow.com/questions/12340773/how-do-memory-order-seq-cst-and-memory-order-acq-rel-differ">How do memory_order_seq_cst and memory_order_acq_rel differ?</a></p> </li> 
    <li> <p>StackOverflow - <a href="https://stackoverflow.com/questions/12346487/what-do-each-memory-order-mean">What do each memory_order mean?</a></p> </li> 
    <li> <p>Just Software Solutions - <a href="https://www.justsoftwaresolutions.co.uk/threading/memory_models_and_synchronization.html">Memory Models and Synchronization</a></p> </li> 
    <li> <p>Wikipedia - <a href="https://en.wikipedia.org/wiki/CPU_cache">CPU cache</a></p> </li> 
    <li> <p>Wikipedia - <a href="https://en.wikipedia.org/wiki/Cache_coherence">Cache coherence</a></p> </li> 
    <li> <p>Wikipedia - <a href="https://en.wikipedia.org/wiki/Memory_barrier">Memory barrier</a></p> </li> 
    <li> <p>Wikipedia - <a href="https://en.wikipedia.org/wiki/Memory_ordering">Memory ordering</a></p> </li> 
    <li> <p>James Bornholt - <a href="https://www.cs.utexas.edu/~bornholt/post/memory-models.html">Memory Consistency Models: A Tutorial</a></p> </li> 
    <li> <p>Preshing on Programming - <a href="https://preshing.com/20120625/memory-ordering-at-compile-time/">Memory Ordering at Compile Time</a></p> </li> 
    <li> <p>Preshing on Programming - <a href="https://preshing.com/20120710/memory-barriers-are-like-source-control-operations/">Memory Barriers Are Like Source Control Operations</a></p> </li> 
    <li> <p>Linux Journal - <a href="https://www.linuxjournal.com/article/8211">Memory Ordering in Modern Microprocessors, Part I</a></p> </li> 
    <li> <p>Doug Lea - <a href="http://gee.cs.oswego.edu/dl/html/j9mm.html">Using JDK 9 Memory Order Modes</a></p> </li> 
   </ul> 
  </div> 
  <div class="paragraph"> 
   <p>本文译自https://www.internalpointers.com/post/understanding-memory-ordering，英文读者可直接阅读原文。</p> 
  </div> 
 </div> 
</div></p>
  		<a href="blog/2020/02/lock-free-multithreading-with-atomic-operations.html"><h1>用原子操作实现无锁多线程：底层线程同步</h1></a>
  		<p>
			<a href="/about.html"><strong>George Cao</strong></a>于2020年02月27日
					<span class="badge badge-dark">原子指令</span>
					<span class="badge badge-dark">多线程</span>
					<span class="badge badge-dark">无锁</span>
					<span class="badge badge-dark">无等待</span>
					<span class="badge badge-dark">并发</span>
					<span class="badge badge-dark">算法</span>
		</p>
  		<p><div id="preamble"> 
 <div class="sectionbody"> 
  <div class="paragraph"> 
   <p>本文经 <a href="https://it.linkedin.com/in/federicarinaldi">Federica Rinaldi</a>仔细审阅过，谢谢。</p> 
  </div> 
  <div class="paragraph"> 
   <p>"atom"在希腊语中拾不可再分割的意思。在计算机中一个任务被称为原子的是指他不能再细分了：它不能再拆分为更小的执行步骤了。</p> 
  </div> 
  <div class="paragraph"> 
   <p><em>原子性</em> 是多线程操作的一个重要特征：因为原子操作是不可在细分的，所以一个线程是不可能干扰另一个正在并发执行原子操作的线程的。例如，当一个线程原子写入共享数据，其他线程是没有办法读取到未完成的数据。相反的，当一个线程原子读取共享数据，这个数据就像是单个时间点上的数据。换句话说，就是没有<a href="https://www.reploop.org/blog/2020/02/a-gentle-introduction-to-multithreading.html">数据竞争</a>的风险。</p> 
  </div> 
  <div class="ulist"> 
   <div class="title">
    本系列中的其他文章
   </div> 
   <ul> 
    <li> <p><a href="https://www.reploop.org/blog/2020/02/a-gentle-introduction-to-multithreading.html">多线程简介</a> - 一步一步走进并发的世界</p> </li> 
    <li> <p><a href="https://www.reploop.org/blog/2020/02/introduction-to-thread-synchronization.html">线程同步简介</a> - 多线程应用中最常见的并发控制方法之一</p> </li> 
    <li> <p><a href="https://www.reploop.org/blog/2020/02/understanding-memory-reordering.html">理解内存重排序</a> - 为什写无锁多线程代码时它很重要</p> </li> 
   </ul> 
  </div> 
  <div class="paragraph"> 
   <p>在<a href="https://www.reploop.org/blog/2020/02/introduction-to-thread-synchronization.html">上一篇文章</a>中，我介绍了所谓的 <strong>同步原语</strong>，也就是最常用的线程同步工具。他们是用来为多线程间处理共享数据的操作提供原子性的。怎么做到的呢？其实就是直接让单个线程执行并发任务，同时操作系统阻塞了其他线程直到第一个线程完成它的工作。这么做的原因是一个被阻塞的线程对其他线程是无害的。考虑到阻塞线程的能力，同步原语也称为 <strong>阻塞机制</strong>。</p> 
  </div> 
  <div class="paragraph"> 
   <p>上一篇文章中的任意一种阻塞机制对大多数应用来说能够很好的工作。如果能够正确的使用，他们也是快速的和可靠的。尽管如此，他们还是有一些你可能需要考虑的缺点：</p> 
  </div> 
  <div class="olist arabic"> 
   <ol class="arabic"> 
    <li> <p>他们会阻塞其他线程 - 休眠的线程什么也不做，单纯的等待唤醒信号：这可能会浪费宝贵的时间；</p> </li> 
    <li> <p>他们会卡死你的应用 - 如果一个持有同步原语锁的线程不管什么原因崩溃了，这个锁就永远不会释放了，等待这个锁的线程就永远卡住了；</p> </li> 
    <li> <p>你对休眠哪个线程没什么控制 - 通常是操作系统选择阻塞哪个线程。这会引发一个被称之为 <strong>优先级反转</strong> 的不幸结果： 一个执行非常重要任务的高优先级线程被一个低优先级线程阻塞了。</p> </li> 
   </ol> 
  </div> 
  <div class="paragraph"> 
   <p>大多数时候你不会关注这些问题，因为他们不影响你应用程序的正确性。另一方面，有时候使线程一直运行是需要的，特别是你想发挥多处理器/多核硬件的能力。或者你就是不能容忍系统被一个崩溃的线程拖死，或者优先级反转的问题不容忽视。</p> 
  </div> 
 </div> 
</div> 
<div class="sect1"> 
 <h2 id="无锁编程来救场">无锁编程来救场</h2> 
 <div class="sectionbody"> 
  <div class="paragraph"> 
   <p>好消息：还有另一种控制多线程应用中并发任务的方法，为了避免上面提到的1）,2）和3）点问题，称之为 <strong>无锁编程</strong>，这是一种不用加锁和解锁就可以安全的在多线程之间共享变化数据的技术。</p> 
  </div> 
  <div class="paragraph"> 
   <p>坏消息：这是非常底层的东西。比传统的同步原语比如互斥锁和信号量还底层多了：这次我们会更接近本质。尽管如此，我发现无锁编程是一个很好的思想挑战，也是一个非常好的更好理解计算机如何工作的机会。</p> 
  </div> 
  <div class="paragraph"> 
   <p>无锁编程依赖 <strong>原子指令</strong>，这是CPU直接执行的原子操作。原子指令作为无锁编程的基础，我将在本文剩下的部分首先介绍，然后展示如何利用它做并发控制。</p> 
  </div> 
 </div> 
</div> 
<div class="sect1"> 
 <h2 id="什么是原子指令">什么是原子指令？</h2> 
 <div class="sectionbody"> 
  <div class="paragraph"> 
   <p>思考计算中执行的任何操作，比如在屏幕上展示一张图片。这个操作是由许多更小的操作构成的：将文件读入内存，解压缩图片，点亮屏幕上的像素等等。如果你不停的细分这些更小的操作，也就是分为更小更小的操作，你最终会不能在分了。此时得到的处理器执行的肉眼可见的最小操作称之为 <strong>机器指令</strong>，也就是硬件可直接执行的命令。</p> 
  </div> 
  <div class="imageblock"> 
   <div class="content"> 
    <img src="https://www.reploop.org/blog/2020/02/images/software-hardware-layers.png" alt="Software - hardware layers"> 
   </div> 
   <div class="title">
    Figure 1. 计算机程序的不同层次。虚线代表软件层次，实线代表硬件层次。
   </div> 
  </div> 
  <div class="paragraph"> 
   <p>取决于不同的CPU架构，一些机器指令是原子的，也就是单个的，不能切分的，不会被中断的。一些其他的指令则不是原子的：处理器私底下以更小的操作的方式做了更多的工作，这些操作称之为 <strong><a href="https://en.wikipedia.org/wiki/Micro-operation">微指令</a></strong>。让我们给出更正式的分类：原子指令是不能在细分的CPU指令。更确切的说，原子指令可以被归为2个主要类型：<strong>存储与加载</strong> 和 <strong>读取-修改-写入（RMW）</strong>。</p> 
  </div> 
  <div class="sect2"> 
   <h3 id="存储与加载原子指令">存储与加载原子指令</h3> 
   <div class="paragraph"> 
    <p>存储和加载是处理器都需要的：用来写入（<strong>存储</strong>）和读取（<strong>加载</strong>）内存数据。在某些情况下，许多CPU架构保证这些操作是天然原子的。例如，实现了 <a href="https://en.wikipedia.org/wiki/X86">x86架构</a>的处理器使用 <strong>MOV</strong> 指令从内存中读取数据并交给CPU。这个操作如果处理的是 <a href="https://www.ibm.com/support/knowledgecenter/en/SSUFAU_1.0.0/com.ibm.ent.pl1.zos.doc/lr/alnmnt.html">对齐</a>的数据就能保证是原子的，对齐的数据是指能让CPU一次性读取出来的方式存储的数据。</p> 
   </div> 
  </div> 
  <div class="sect2"> 
   <h3 id="读取_修改_写入rmw原子指令">读取-修改-写入(RMW)原子指令</h3> 
   <div class="paragraph"> 
    <p>一些更复杂的操作不能够单独用一些简单存储和加载指令来完成。例如，增加存储中的数值需要至少3个原子的加载和存储指令，这就使的增加内存中数值这个操作不是原子的。<strong>读取-修改-写入（RMW）</strong> 指令可以做到这个，也就有了通过一个原子操作完成多个操作的能力。除了RMW，还有非常多此类的指令。一些CPU架构全部提供，一些则提供一部分，下面列举一些：</p> 
   </div> 
   <div class="ulist"> 
    <ul> 
     <li> <p><a href="https://en.wikipedia.org/wiki/Test-and-set">测试并设置</a> - 一个原子操作完成往内存中写入1并且返回赋值之前的值；</p> </li> 
     <li> <p><a href="https://en.wikipedia.org/wiki/Fetch-and-add">获取并增加</a> - 一个原子操作完成增加内存中的数值并且返回增加之前的值；</p> </li> 
     <li> <p><a href="https://en.wikipedia.org/wiki/Compare-and-swap">比较并交换（CAS）</a> - 比较内存中的数据和提供的数据，如果他们是相同的，将提供的另一个数据写入该内存中。</p> </li> 
    </ul> 
   </div> 
   <div class="paragraph"> 
    <p>以上这些操作都是一个原子操作完成多个操作。这是一个非常重要的特性，使得读取-修改-写入指令适合无锁多线程操作。我们很快就会看到为什么适合了。</p> 
   </div> 
  </div> 
 </div> 
</div> 
<div class="sect1"> 
 <h2 id="原子指令的三个层次">原子指令的三个层次</h2> 
 <div class="sectionbody"> 
  <div class="paragraph"> 
   <p>以上所有这些指令都属于硬件层面的：他们直接和CPU交互。这种工作方式是非常困难并且不可移植，因为一些指令可能在不同得架构下叫不同得名字，一些指令在不同的处理器模型上则根本不存在！因此，你也不太可能用到这些，除非你在针对特定得机器写非常底层得代码。</p> 
  </div> 
  <div class="paragraph"> 
   <p>上到软件层面，许多操作系统提供了各自的原子指令。姑且称之为 <strong>原子操作(atomic operations)</strong>，因为我们正在抽象出物理机器指令对应得原子操作。 例如， Windows系统上可能会用到 <a href="https://docs.microsoft.com/en-us/windows/desktop/sync/interlocked-variable-access">Interlocked API</a>，这是一组原子方式处理变量得函数。 MacOS则用 <a href="https://developer.apple.com/documentation/kernel/osatomic_h?language=objc">OSAtomc.h</a>头文件提供的函数做同样的事情。他们肯定是隐藏了硬件的具体实现，但是你还是受限于他们特定的环境。</p> 
  </div> 
  <div class="paragraph"> 
   <p>实现可移植原子操作的最好办法是使用你所选择的编程语言提供的原子操作。比如Java语言中有 <strong>java.util.concurrent.atomic</strong> 包；C++提供了 <strong>std::atomic</strong> 头文件； Haskell有 <strong>Data.Atomics</strong> 包等等。一般来讲，如果一个编程语言能处理多线程，那就很有可能会提供原子操作的支持。这样的话就是编译器（如果是编译语言）或者虚拟机（如果是解析语言）负责从底层操作系统API或者硬件中找到最合适的指令来实现原子操作。</p> 
  </div> 
  <div class="imageblock"> 
   <div class="content"> 
    <img src="https://www.reploop.org/blog/2020/02/images/atomics-levels.png" alt="Three levels of atomic instructions"> 
   </div> 
   <div class="title">
    Figure 2. 原子指令和操作的层级。虚线代表软件层次，实线代表硬件层次。
   </div> 
  </div> 
  <div class="paragraph"> 
   <p>例如，C++ 的编译器GCC通常是直接将 C++语言的原子操作和对象对应到机器指令。如果不能直接映射到硬件上，它也会利用其他可用的原子操作来实现特定操作。最坏情况下，在一个不提供原子操作的平台上，它可能利用其他阻塞策略来实现了，当然了这肯定不是无锁的实现。</p> 
  </div> 
 </div> 
</div> 
<div class="sect1"> 
 <h2 id="在多线程中使用原子操作">在多线程中使用原子操作</h2> 
 <div class="sectionbody"> 
  <div class="paragraph"> 
   <p>我们现在看看原子操作是如何使用的。 考虑增加一个简单的变量，这本来就不是原子操作，因为此操作由3个不同的步骤构成：读取数值，给数值加1，将结果写回。 一般来说，你可能会使用互斥锁来正确实现这个操作（伪代码）：</p> 
  </div> 
  <div class="listingblock"> 
   <div class="content"> 
    <pre class="prettyprint highlight"><code data-lang="c">mutex = initialize_mutex()
x     = 0

reader_thread()
    mutex.lock()
    print(x)
    mutex.unlock()

writer_thread()
    mutex.lock()
    x++
    mutex.unlock()</code></pre> 
   </div> 
  </div> 
  <div class="paragraph"> 
   <p>首先获得互斥锁的线程会继续执行，而其他线程则等待第一个线程执行完毕。</p> 
  </div> 
  <div class="paragraph"> 
   <p>相反的，无锁方案使用了不同的模式：通过原子操作，线程可以随意执行而不用阻塞，例如：</p> 
  </div> 
  <div class="listingblock"> 
   <div class="content"> 
    <pre class="prettyprint highlight"><code data-lang="c">x = 0

reader_thread()
    print(load(x))

writer_thread()
    fetch_and_add(x, 1)</code></pre> 
   </div> 
  </div> 
  <div class="paragraph"> 
   <p>我假设了 <code>fetch_and_add()</code> 和 <code>load()</code> 是基于相应的硬件指令的原子操作。 你可能已经发现了，这里并没有使用锁。 并发调用这些函数的多个线程都可以继续执行。<code>load()</code> 函数的原子性将保证不会有读线程读取到未完成修改的数据，同时因为 <code>fetch_and_add()</code> 的原子性，也不会有写线程能够部分修改数据。</p> 
  </div> 
  <div class="sect2"> 
   <h3 id="现实世界中的原子操作">现实世界中的原子操作</h3> 
   <div class="paragraph"> 
    <p>现在，上面这个例子显示了原子操作的一个重要特性：他们仅针对原子类型，如boolean型，字符串，整数等。但是真的程序是需要使用同步技术来实现更复杂的数据结构，比如数组，向量，对象，数据向量，对象里包含数据等等。如何用基于原子类型的简单操作来保证负责数据的原子性？</p> 
   </div> 
   <div class="paragraph"> 
    <p>无锁编程迫使你跳出常规的同步原语来思考问题。你不直接用原子操作保护共享资源，而是用互斥锁或者信号量。同样的，你会基于原子操作构建 <strong>无锁算法</strong> 或者 <strong>无锁数据结构</strong> 来确定多个线程如何访问你的数据。</p> 
   </div> 
   <div class="paragraph"> 
    <p>例如，上面看到的 <em>fetch-and-add</em> 操作可以用来实现一个基本的信号量，而这个信号量就可以用来协调多个线程。毫无意外，所有传统的阻塞同步工具都是基于原子操作的实现的。</p> 
   </div> 
   <div class="paragraph"> 
    <p>人们写了很多个无锁数据结构，比如Folly的 <a href="https://github.com/facebook/folly/blob/master/folly/AtomicHashMap.h">AtomicHashMap</a>， <a href="https://www.boost.org/doc/libs/1_70_0/doc/html/lockfree.html">Boost.Lockfree类库</a>，多生产者/多消费者， <a href="https://github.com/cameron314/concurrentqueue">先进先出队列</a>(FIFO)，或者诸如 <a href="https://www.youtube.com/watch?v=rxQ5K9lo034">读取-复制-更新（RCU）</a>和 <a href="https://en.wikipedia.org/wiki/Shadow_paging">影子分页</a>(Shadow Paging)等一些算法。从头开始写这些原子工具很困难，更不用说让他们正确工作。这也是大多数时候你可能会使用已经存在的，实战检验过得算法与数据结构，而不是使用自己实现的。</p> 
   </div> 
  </div> 
  <div class="sect2"> 
   <h3 id="比较并交换cas循环">比较并交换(CAS)循环</h3> 
   <div class="paragraph"> 
    <p>具体到实际应用，<strong>比较并交换循环</strong>(<strong>CAS loop</strong>)可能是无锁编程中最常用的技巧，无论你是使用现成的数据结构或者从头开始实现算法。这是基于对应的 <em>比较并交换</em> 原子操作（CAS）而且有一个很好的特点：他能支持多个写线程。这是用到复杂系统中的并发算法的一个重要特征。</p> 
   </div> 
   <div class="paragraph"> 
    <p>CAS循环非常有趣是因为他在无锁代码中引入了重复模式，同时引入了用于推理的理论概念。我们进一步看一下。</p> 
   </div> 
  </div> 
  <div class="sect2"> 
   <h3 id="cas循环实现">CAS循环实现</h3> 
   <div class="paragraph"> 
    <p>操作系统或者编程语言提供的CAS函数可能是这样的：</p> 
   </div> 
   <div class="listingblock"> 
    <div class="content"> 
     <pre class="prettyprint highlight"><code data-lang="c">boolean compare_and_swap(shared_data, expected_value, new_value);</code></pre> 
    </div> 
   </div> 
   <div class="paragraph"> 
    <p>他的入参有共享数据的引用/指针，预期共享数据当前的值以及将要赋值的新值。这个函数只有在 <code>shared_date.value == expected_value</code> 的情况下才会使用新数据替换原始数据，并且只有数据改变的情况下才返回 <code>true</code>。</p> 
   </div> 
   <div class="paragraph"> 
    <p>CAS循环的思路是不停的尝试比较和交换，直到操作成功。每一次尝试都需要给CAS函数传递共享数据的引用/指针，预期的数据和将要赋值的数据。这是和其他并发写线程配合的必要条件：如果其他线程在同步修改数据，也就是共享数据和预期数据不再匹配了，CAS函数就会失败。这样就支持了多个写线程。</p> 
   </div> 
   <div class="paragraph"> 
    <p>假设我们用CAS来实现前面代码片段实现的 <code>fetch-and-add</code> 算法，实现起来可能是这样的（伪代码）：</p> 
   </div> 
   <div class="listingblock"> 
    <div class="content"> 
     <pre class="prettyprint highlight"><code data-lang="c">x = 0

reader_thread()
    print(load(x))

writer_thread()
    temp = load(x)                              // (1)
    while(!compare_and_swap(x, temp, temp + 1)) // (2)</code></pre> 
    </div> 
   </div> 
   <div class="paragraph"> 
    <p>第（1）行代码加载共享数据，然后尝试和新的数据进行交换，直到交换成功返回 <code>true</code>（2）。</p> 
   </div> 
  </div> 
  <div class="sect2"> 
   <h3 id="交换范式">交换范式</h3> 
   <div class="paragraph"> 
    <p>正如前面说的，CAS循环在许多无锁算法中引入了重复模式:</p> 
   </div> 
   <div class="olist arabic"> 
    <ol class="arabic"> 
     <li> <p>创建共享数据的 <em>本地副本</em>；</p> </li> 
     <li> <p>按需修改本地副本；</p> </li> 
     <li> <p>合适的时候，通过 <em>交换</em> 更新后的数据与之前创建的副本数据来更新共享数据。</p> </li> 
    </ol> 
   </div> 
   <div class="paragraph"> 
    <p>第3）点是关键：交换是通过原子操作来保证原子性的。本地写线程针对副本数据做了大部分的脏活累活，等到合适的时候才发布更新到共享数据。这样的话，其他线程只能看到这个共享数据的2种状态：未修改的数据和修改后的数据。由于原子交换，看不到修改过程中的中间状态，或者出错的更新。</p> 
   </div> 
   <div class="paragraph"> 
    <p>这也是哲学上不同于加锁方案的：无锁算法中，多线程仅仅在执行交换的时候才需要交互，其他时候都不被打扰的运行，也感知不到其他线程的存在。多线程之间的交互点缩小了并且被限制在执行原子操作的期间。</p> 
   </div> 
  </div> 
  <div class="sect2"> 
   <h3 id="一种轻量级加锁形式">一种轻量级加锁形式</h3> 
   <div class="paragraph"> 
    <p>上面看到的 <em>循环直到成功</em> 的策略在许多无锁算法中用到了，被称之为 <strong>自旋锁(spinlock)</strong>：一个简单的循环，线程不停的尝试执行操作直到成功。这是一种轻量级的加锁形式，此时线程是实时活跃运行的，不会被操作系统休眠，尽管这个循环成功之前工作不会有进展。相比之下，互斥锁或者信号量中用到的常规锁代价非常高，因为一个挂起/唤醒周期需要大量的底层工作。</p> 
   </div> 
  </div> 
  <div class="sect2"> 
   <h3 id="aba问题">ABA问题</h3> 
   <div class="paragraph"> 
    <p>行（1）和（2）所示指令虽然有所不同，但不是连续的。另一个线程可能插入中间，再（1）读取完成之后修改共享数据。更确切的说，另一个线程可以将初始数据，假设为A，修改为B，然后在（2）所示的比较并交换操作执行之前再修改回A。执行CAS操作的线程不会发现数据的变化而成功执行交换操作。这就是所谓的ABA问题：有时候你可以简单的直接忽略，如果你的算法就像上面那个一样简单，而有时候你就需要避免此问题，因为这会给你的应用程序引入非常难以发现的问题。幸运的是有 <a href="https://en.wikipedia.org/wiki/Compare-and-swap#ABA_problem">几种方式</a> 可以绕过这个问题。</p> 
   </div> 
  </div> 
  <div class="sect2"> 
   <h3 id="cas循环可以交换任意的事情">CAS循环可以交换任意的事情</h3> 
   <div class="paragraph"> 
    <p>CAS循环经常用来交换指针，这也是 <em>比较并交换</em> 操作支持的类型之一。当你需要修改复杂的诸如对象或者数组的数据集的时候非常有用：创建本地数据副本，按需修改这个副本，合适的时候交换本地副本数据和全局共享数据的指针。这样的话全局共享数据就指向了本地副本数据在内存中指针，其他线程就会看到更新后的最新数据。</p> 
   </div> 
   <div class="paragraph"> 
    <p>这个技术允许你同步非原始数据实体(primitive entities)，尽管要做到这个也有一定的难度。比如交换完成之后，一个读线程还在读取老的指针？如何安全的删除之前的数据副本而不引起非常危险的野指针问题？工程师们再一次的找到了很多解决方案，比如使用支持内存自动 <a href="https://en.wikipedia.org/wiki/Garbage_collection_(computer_science)">垃圾回收</a>的语言，或者一些深奥的技术如 <a href="https://aturon.github.io/blog/2015/08/27/epoch/">分代内存回收</a>， <a href="https://en.wikipedia.org/wiki/Hazard_pointer">冒险指针</a>或者 <a href="https://en.wikipedia.org/wiki/Reference_counting">引用计数</a>。</p> 
   </div> 
  </div> 
 </div> 
</div> 
<div class="sect1"> 
 <h2 id="无锁和无等待">无锁和无等待</h2> 
 <div class="sectionbody"> 
  <div class="paragraph"> 
   <p>每个基于原子操作的算法或者数据结构都可以归为2类：<strong>无锁的</strong> 或者 <strong>无等待的</strong>。当你要评估基于原子操作的类库对你应用程序性能的影响时，这是一个非常重要的不同点。</p> 
  </div> 
  <div class="paragraph"> 
   <p>无锁算法允许其他线程继续执行有用的工作，尽管有一个线程正在忙等。换句话说，至少有一个线程是可以继续执行的。CAS循环是一个非常好的无锁算法例子，因为循环的过程中如果有一些交换尝试失败了，一定是因为另一个线程成功修改了共享数据。尽管如此，无锁算法可能会在无法预知的时间内不停的忙等，尤其是有许多个线程在同时竞争同一个共享数据：更确切的说，当 <strong>竞争</strong> 非常激烈的时候。极端情况下，一个无锁算法的CPU资源效率可能远远不及让阻塞线程休眠的互斥锁。</p> 
  </div> 
  <div class="paragraph"> 
   <p>相比之下，在无等待算法中（无锁算法的子集），任何线程都能够在有限的步骤内完成工作，无论执行速度是怎样的，或者其他线程的工作负载水平是怎样的。本文中基于 <em>fetch-and-add</em> 操作的第一个代码片段就是一个无等待算法实例：没有循环，没有重试，就是干净的业务流。还有，无等待算法是 <strong>容错的</strong>：任何其他线程的失败，或者执行速度的波动都不会使当前线程结束不了工作。这些特性使得无等待算法非常适合复杂的 <a href="https://en.wikipedia.org/wiki/Real-time_computing">实时系统</a>，因为这里并发代码的行为可预知是必要的。</p> 
  </div> 
  <div class="imageblock"> 
   <div class="content"> 
    <img src="https://www.reploop.org/blog/2020/02/images/lock-free-wait-free.png" alt="Lock-free" width="wait-free"> 
   </div> 
   <div class="title">
    Figure 3. 无等待算法是无锁算法的子集
   </div> 
  </div> 
  <div class="paragraph"> 
   <p>无等待是并发代码非常需要的，但是很难获得的特性。总而言之，无论你正在构建一个阻塞的，无锁的还是无等待的算法，黄金法则是你一定要做基准测试并且衡量测试结果。有时候旧时的互斥锁比时髦的同步原语性能要好，尤其是并发任务的复杂度非常高的时候。</p> 
  </div> 
 </div> 
</div> 
<div class="sect1"> 
 <h2 id="写到最后">写到最后</h2> 
 <div class="sectionbody"> 
  <div class="paragraph"> 
   <p>原子操作是无锁编码的必要组成，甚至在单处理器的机器上也是。没有原子性，一个线程可能在事务中途被中断，可能会导致不一致的数据状态。本文中，我仅仅是浅尝辄止：一旦你把多核/多线程考虑进去，就打开了新世界。<strong>顺序一致性</strong> 和 <strong>内存屏障</strong> 是非常关键的部分，如果要充分利用无锁算法，就不应该被忽视。我将在下一文章中讨论这些主题。</p> 
  </div> 
 </div> 
</div> 
<div class="sect1"> 
 <h2 id="参考">参考</h2> 
 <div class="sectionbody"> 
  <div class="ulist"> 
   <ul> 
    <li> <p>Preshing on Programming - <a href="https://preshing.com/20120612/an-introduction-to-lock-free-programming/">An Introduction to Lock-Free Programming</a></p> </li> 
    <li> <p>Preshing on Programming - <a href="https://preshing.com/20130618/atomic-vs-non-atomic-operations/">Atomic vs. Non-Atomic Operations</a></p> </li> 
    <li> <p>Preshing on Programming - <a href="https://preshing.com/20150402/you-can-do-any-kind-of-atomic-read-modify-write-operation/">You Can Do Any Kind of Atomic Read-Modify-Write Operation</a></p> </li> 
    <li> <p>StackOverflow - <a href="https://stackoverflow.com/questions/1525189/do-i-need-a-mutex-for-reading">Do I need a mutex for reading?</a></p> </li> 
    <li> <p>StackOverflow - <a href="https://stackoverflow.com/questions/39795265/will-atomic-operations-block-other-threads">Will atomic operations block other threads?</a></p> </li> 
    <li> <p>StackOverflow - <a href="https://stackoverflow.com/questions/38124337/spinlock-vs-busy-wait">Spinlock vs Busy wait</a></p> </li> 
    <li> <p>GCC Wiki - <a href="https://gcc.gnu.org/wiki/Atomic/GCCMM/AtomicTypes">Atomics</a></p> </li> 
    <li> <p>GCC Wiki - <a href="https://gcc.gnu.org/wiki/Atomic/GCCMM/AtomicSync">Memory model synchronization modes</a></p> </li> 
    <li> <p>Threading Building Blocks - <a href="https://www.threadingbuildingblocks.org/docs/help/tbb_userguide/Atomic_Operations.html">Atomic Operations</a></p> </li> 
    <li> <p>Just Software Solutions - <a href="https://www.justsoftwaresolutions.co.uk/threading/non_blocking_lock_free_and_wait_free.html">Definitions of Non-blocking, Lock-free and Wait-free</a></p> </li> 
    <li> <p>Wikipedia - <a href="https://en.wikipedia.org/wiki/Compare-and-swap">Compare-and-swap</a></p> </li> 
    <li> <p>Wikipedia - <a href="https://en.wikipedia.org/wiki/Read%E2%80%93modify%E2%80%93write">Read-modify-write</a></p> </li> 
    <li> <p>Wikipedia - <a href="https://en.wikipedia.org/wiki/Test-and-set">Test-and-set</a></p> </li> 
    <li> <p>Tyler Neely - <a href="https://medium.com/@tylerneely/fear-and-loathing-in-lock-free-programming-7158b1cdd50c">Fear and Loathing in Lock-Free Programming</a></p> </li> 
    <li> <p>Jason Gregory - <a href="https://www.ebooks.com/en-us/95912264/game-engine-architecture-third-edition/jason-gregory/">Game Engine Architecture, Third Edition</a></p> </li> 
    <li> <p>AA.VV. - <a href="https://spcl.inf.ethz.ch/Publications/.pdf/atomic-bench.pdf">Evaluating the Cost of Atomic Operations on Modern Architectures</a></p> </li> 
    <li> <p>Herb Sutter, CppCon 2014 - <a href="https://www.youtube.com/watch?v=c1gO9aB9nbs">Lock-Free Programming (or, Juggling Razor Blades), Part 1</a></p> </li> 
    <li> <p>Herb Sutter, CppCon 2014 - <a href="http://www.youtube.com/watch?v=CmxkPChOcvw">Lock-Free Programming (or, Juggling Razor Blades), Part 2</a></p> </li> 
    <li> <p>Maurice Herlihy - <a href="https://cs.brown.edu/~mph/Herlihy91/p124-herlihy.pdf">Wait-free synchronization</a></p> </li> 
    <li> <p>Fedor Pikus, CppCon 2014 - <a href="https://www.youtube.com/watch?v=rxQ5K9lo034">Read, Copy, Update, then what? RCU for non-kernel programmers</a></p> </li> 
    <li> <p>1024cores - <a href="http://www.1024cores.net/home/lock-free-algorithms">Lockfree Algorithms</a></p> </li> 
    <li> <p>Microsoft - <a href="https://docs.microsoft.com/en-us/windows/win32/dxtecharts/lockless-programming">Lockless Programming Considerations for Xbox 360 and Microsoft Windows</a></p> </li> 
    <li> <p>Brian Goetz, IBM - <a href="https://www.ibm.com/developerworks/java/library/j-jtp11234/">Going Atomic</a></p> </li> 
   </ul> 
  </div> 
  <div class="paragraph"> 
   <p>本文译自https://www.internalpointers.com/post/lock-free-multithreading-atomic-operations，英文读者可直接阅读原文。</p> 
  </div> 
 </div> 
</div></p>
  		<a href="blog/2020/02/introduction-to-thread-synchronization.html"><h1>线程同步: 多线程应用中最常见的并发控制方法之一</h1></a>
  		<p>
			<a href="/about.html"><strong>George Cao</strong></a>于2020年02月23日
					<span class="badge badge-dark">互斥锁</span>
					<span class="badge badge-dark">信号量</span>
					<span class="badge badge-dark">同步</span>
					<span class="badge badge-dark">多线程</span>
					<span class="badge badge-dark">条件变量</span>
					<span class="badge badge-dark">线程</span>
					<span class="badge badge-dark">并发</span>
		</p>
  		<p><div id="preamble"> 
 <div class="sectionbody"> 
  <div class="paragraph"> 
   <p>本文讨论的是多线程应用中最常见的并发控制方法之一。</p> 
  </div> 
  <div class="paragraph"> 
   <p>就像我<a href="https://www.reploop.org/blog/2020/02/a-gentle-introduction-to-multithreading.html">前一篇文章</a>所阐述的，开发并发代码需要技巧的。 会遇到两个大问题：数据竞争，当一个写线程在修改内存数据的同时一个读线程正在从中读取数据和竞争条件，当2个或以上的线程以不可预知的顺序执行任务的时候会发生。幸运的是我们有一些办法来避免这类错误：这篇文章我们就来看一个最常用的办法：<strong>同步(synchronization)</strong>。</p> 
  </div> 
  <div class="ulist"> 
   <div class="title">
    本系列中的其他文章
   </div> 
   <ul> 
    <li> <p><a href="https://www.reploop.org/blog/2020/02/a-gentle-introduction-to-multithreading.html">多线程简介</a> - 一步一步走进并发的世界</p> </li> 
    <li> <p><a href="https://www.reploop.org/blog/2020/02/lock-free-multithreading-with-atomic-operations.html">用原子操作实现无锁多线程</a> - 底层线程同步</p> </li> 
    <li> <p><a href="https://www.reploop.org/blog/2020/02/understanding-memory-reordering.html">理解内存重排序</a> - 为什写无锁多线程代码时它很重要</p> </li> 
   </ul> 
  </div> 
 </div> 
</div> 
<div class="sect1"> 
 <h2 id="什么是同步">什么是同步</h2> 
 <div class="sectionbody"> 
  <div class="paragraph"> 
   <p>同步是让2个或以上线程和平共处的技巧合集。更确切的说，同步能够帮你实现多线程程序中至少2个重要的特性：</p> 
  </div> 
  <div class="olist arabic"> 
   <ol class="arabic"> 
    <li> <p><strong>原子性</strong> - 如果你的代码包含多个线程操作共享数据的指令，不受控制的并发访问共享数据可触发数据竞争。包含此类指令的代码块称为关键区块。你要确保关键区块要原子执行：如前文所定义的，一个<a href="https://www.reploop.org/blog/2020/02/a-gentle-introduction-to-multithreading.html">原子操作</a>不能在细分为更小的操作了，因此当一个线程在执行原子代码块的时候，就不会受到其他线程的干扰；</p> </li> 
    <li> <p><strong>有序性</strong> - 有时候你需要2个或以上的线程按照可预测的顺序执行任务，或者限制访问某个资源的线程数。正常情况下你是不能控制这个的，这也可能是竞争条件发生的根本原因。有了同步之后，你就可以根据计划来编排多个线程的执行了。</p> </li> 
   </ol> 
  </div> 
  <div class="paragraph"> 
   <p>同步是通过支持多线程的操作系统或者编程语言提供的 <strong>同步原语(synchronization primitives)</strong> 来实现的。然后你就可以在代码中使用同步原语来保证多线程不会触发数据竞争、竞争条件或者全部。</p> 
  </div> 
  <div class="paragraph"> 
   <p>同步可以发生在硬件和软件，以及线程与操作系统进程之间。 这篇文章是关于软件线程同步：对应的硬件同步部分非常有趣，将会在后续的文章中介绍。</p> 
  </div> 
 </div> 
</div> 
<div class="sect1"> 
 <h2 id="常见同步原语">常见同步原语</h2> 
 <div class="sectionbody"> 
  <div class="paragraph"> 
   <p>最重要的同步原语是互斥锁，信号量和条件变量。这些关键字还没有官方的定义，所以在不同的书本或者实现中会有轻微的不同特征。</p> 
  </div> 
  <div class="paragraph"> 
   <p>操作系统原生支持他们。例如Linux和macOS支持 <strong>POSIX线程</strong>，也就是 <strong>pthreads</strong>，能够让你可以用这一组函数开发安全的多线程应用。Windows则用C运行时代码库（CRT）提供自己的同步工具：概念上和POSIX多线程功能相似但是不同的命名。</p> 
  </div> 
  <div class="paragraph"> 
   <p>除非你正在写非常底层的代码，通常你只要使用编程语言提供的同步原语就可以了。每个支持多线程的编程语言都提供了自己的同步原语工具箱，以及一些额外的线程处理功能。例如Java提供了 <code>java.util.concurrent</code> 包，现代C++有自己的线程库，C#提供 <code>System.Threading</code> 命名空间等等。当然所有这些功能和对象都是基于底层操作系统同步原语的。</p> 
  </div> 
  <div class="paragraph"> 
   <p>当然还有其他同步工具，但是本文只关注上面提到的3个，因为他们是构建复杂系统的基础。让我们进一步分析。</p> 
  </div> 
 </div> 
</div> 
<div class="sect1"> 
 <h2 id="互斥锁">互斥锁</h2> 
 <div class="sectionbody"> 
  <div class="paragraph"> 
   <p><strong>互斥锁</strong>(<strong>mut</strong>ual <strong>ex</strong>clusion)是一个同步原语，是为了避免数据竞争而给关键区增加限制的保护机制。 互斥锁通过同时只允许一个线程访问关键区来保证 <em>原子性</em>。</p> 
  </div> 
  <div class="paragraph"> 
   <p>严格来讲，互斥锁是应用中的一个全局对象，在多个线程之间共享，并且提供通常叫做 <code>加锁</code> 和 <code>解锁</code> 的2个功能函数。一个即将要进入关键区域的线程通过 <code>加锁</code> 操作锁定这个互斥锁，结束后，也就是关键区域结束之后，同样的线程调用 <code>解锁</code> 操作来释放这个互斥锁。互斥锁非常重要的特性是：只有锁定这个互斥锁的线程才能解锁。</p> 
  </div> 
  <div class="paragraph"> 
   <p>如果一个线程正在关键区，而另一个线程尝试锁定这个互斥锁，操作系统就让后面这个线程休眠，直到第一个线程任务结束并且释放了这个互斥锁。这样就只有1个线程可以访问关键区，任何其他线程都不能访问而且必须等待互斥锁的释放。基于这个原因，互斥锁也叫做锁机制。</p> 
  </div> 
  <div class="paragraph"> 
   <p>你可以用互斥锁保护比如一个共享变量的并发读和写操作，也可以保护更大、更复杂的操作，同时只允许一个线程执行的，比如写日志文件或者修改数据库。无论如何，互斥锁的加锁/解锁操作总是和关键区的边界是匹配的。</p> 
  </div> 
  <div class="sect2"> 
   <h3 id="递归互斥锁">递归互斥锁</h3> 
   <div class="paragraph"> 
    <p>任何常规的互斥锁实现中，一个线程两次加锁同一个互斥锁会引起错误。但是 <strong>递归互斥锁(recursive mutex)</strong> 允许此类操作：一个线程可以锁定一个递归互斥锁许多次而不需要先释放。尽管如此，其他线程只有等到第一个线程释放所有的递归互斥锁之后才能锁定这个锁。这个同步原语也叫做 <strong>可重入互斥锁(reentrant mutex)</strong>，这里的 <strong>可重入性(reentrancy)</strong> 是指在前一次调用结束之前可以多次调用同一个函数的能力。</p> 
   </div> 
   <div class="paragraph"> 
    <p>递归互斥锁很难用而且容易出错。你必须记录哪个线程锁定了哪个互斥锁多少次，而且要保证一个线程完全释放这个互斥锁。不然的话就会导致互斥锁没能释放而引起讨厌的后果。大多数时候正常的互斥锁就够用了。</p> 
   </div> 
  </div> 
  <div class="sect2"> 
   <h3 id="读写锁">读写锁</h3> 
   <div class="paragraph"> 
    <p>正如我们从前一篇文章中知道的，多个线程可以安全的并发读一个共享资源，只要没有线程修改该共享资源。所以如果一些线程是“只读”模式的，还有必要锁定一个互斥锁？例如一个并发数据库被多个线程频繁读取，同时另一个线程偶尔写入更新。你当然需要一个互斥锁来保护读/写访问，但是大多数情况下仅仅为了读操作而锁定一个互斥锁，也同时阻碍了其他读线程正常执行。</p> 
   </div> 
   <div class="paragraph"> 
    <p><strong>读/写互斥锁</strong> 允许多线程 <em>并发</em> 读和单线程 <em>排他</em> 写共享资源。这个互斥锁可以被锁定为 <em>读模式</em> 或者 <em>写模式</em>。为了修改资源，一个线程必须先获得排他写入锁。排他写入锁直到所有的读取锁全部释放之后才能获取。</p> 
   </div> 
  </div> 
 </div> 
</div> 
<div class="sect1"> 
 <h2 id="信号量">信号量</h2> 
 <div class="sectionbody"> 
  <div class="paragraph"> 
   <p><strong>信号量</strong> 是用来编排线程的同步原语：那个线程先启动，多少个线程可以访问一个资源等等。就像“红绿灯”调节交通一样，程序信号量规范多线程交互流程：基于这个原因，信号量也称为 <strong>信号机制</strong>。他可以被看做互斥锁的进化，因为他能同时保证 <em>有序性</em> 和 <em>原子性</em>。尽管如此，接下来的几段中我讲告诉你为什么仅仅为了原子性而使用信号量不是一个好选择。</p> 
  </div> 
  <div class="paragraph"> 
   <p>严格来讲，信号量是应用中的全局变量，多个线程间共享，还包含了一个 <em>计数器</em>，通过2个函数管理：一个增加计数器，另一个减少计数器。历史上，这两个操作分别叫做 <code>P</code> 操作和 <code>V</code> 操作，现代信号量的实现使用更友好的名字比如 <code>获取</code> 和 <code>释放</code>。</p> 
  </div> 
  <div class="paragraph"> 
   <p>信号量控制共享资源的访问：计数器决定了并行访问共享资源的最大线程数。程序启动的时候，也就是信号量被初始化的时候，你根据自己的需要选择这个最大线程数。然后一个想访问共享资源的线程调用 <code>获取</code> 函数：</p> 
  </div> 
  <div class="ulist"> 
   <ul> 
    <li> <p>如果计数器 <em>大于0</em> 就继续进行。计数器被立即减少1，然后当前线程可以开始操作了。结束后，当前线程调用 <code>释放</code> 函数，同时计数器加1.</p> </li> 
    <li> <p>如果计数器 <em>等于0</em> 则此线程不能继续进行：其他线程已经占用了可以空间。当前线程被操作系统休眠，只有等到信号量的计数器再次大于0（也就是有线程完成任务后调用了 <code>释放</code> 函数）的时候才会被唤醒。</p> </li> 
   </ul> 
  </div> 
  <div class="paragraph"> 
   <p>不像互斥锁，<em>任何线程可以释放信号量</em>，不仅仅是最先获取信号量的线程。</p> 
  </div> 
  <div class="paragraph"> 
   <p>单个信号量可以用来限制同时访问共享资源的线程数：例如为了控制多线程数据库的连接数，这其中的每个线程是连接到你的服务器的用户触发的。</p> 
  </div> 
  <div class="paragraph"> 
   <p>结合多个信号量一起，你就可以解决线程的有序性问题了：比如在浏览器中渲染网页的线程必须在通过互联网下载HTML文件的线程之后启动。线程A结束的时候会通知线程B，因此线程B可以被唤醒继续执行任务：这个也常被称为著名的 <a href="https://en.wikipedia.org/wiki/Producer%E2%80%93consumer_problem">生产者-消费者问题</a>。</p> 
  </div> 
  <div class="sect2"> 
   <h3 id="二元信号量">二元信号量</h3> 
   <div class="paragraph"> 
    <p>如果信号量的计数器只允许取值0和1，则称之为 <strong>二元信号量</strong>：也就是同时只允许一个线程访问共享资源。 等一下，这基本上就是互斥锁保护关键区的作用。你确实可以用二元信号量来实现互斥锁的行为。但是要时刻牢记以下2点：</p> 
   </div> 
   <div class="olist arabic"> 
    <ol class="arabic"> 
     <li> <p>互斥锁只能被加锁的线程解锁，但是信号量可以被任意线程释放。如果你仅仅需要一个锁机制的话，这会导致困惑和微妙的问题；</p> </li> 
     <li> <p>信号量是用来编排线程的信号机制，但是互斥锁是保护共享资源的锁机制。你不应改使用信号量来保护共享资源，也不应该将互斥锁用于信号机制：你的意图对你和你的代码读者会更明确。</p> </li> 
    </ol> 
   </div> 
  </div> 
 </div> 
</div> 
<div class="sect1"> 
 <h2 id="条件变量">条件变量</h2> 
 <div class="sectionbody"> 
  <div class="paragraph"> 
   <p>条件变量是另一个用来保证 <em>有序性</em> 的同步原语。他们是用来在不同线程之间发送唤醒信号的。条件变量往往配合互斥锁一起使用，单独使用条件变量没有意义。</p> 
  </div> 
  <div class="paragraph"> 
   <p>严格来讲，条件变量是应用中的全局对象，多个线程之间共享，提供3个函数，分别叫做：<code>wait</code>，<code>notify_one</code> 和 <code>notify_all</code>, 外加一个传递已知互斥锁给他配合工作的机制（具体方法依实现而定）。</p> 
  </div> 
  <div class="paragraph"> 
   <p>线程调用一个条件变量的 <code>wait</code> 操作会被操作系统休眠。然后其他的线程想要唤醒休眠线程的话就调用 <code>notify_one</code> 或者 <code>notify_all</code>。<code>notify_one</code> 和 <code>notify_all</code> 的不同之处是 <code>notify_one</code> 仅仅唤醒一个休眠线程，但是 <code>notify_all</code> 会唤醒所有因为调用了条件变量的等待操作而休眠的线程。条件变量内部使用互斥锁提供休眠/唤醒机制。</p> 
  </div> 
  <div class="paragraph"> 
   <p>条件变量是仅仅依靠 在线程之间发送信号的强大机制，仅仅依靠互斥锁是实现不了的。例如你也可以使用它解决生产者-消费者问题，线程A完成任务后产生一个信号，接着线程B就可以开始执行任务了。</p> 
  </div> 
 </div> 
</div> 
<div class="sect1"> 
 <h2 id="常见的同步问题">常见的同步问题</h2> 
 <div class="sectionbody"> 
  <div class="paragraph"> 
   <p>本文所述的所有同步原语有共同之处：都会让线程休眠。基于这个原因，他们也被叫做 <strong>阻塞机制</strong>。如果你想避免数据竞争或者竞争条件，阻塞机制是防止并发访问共享资源的好办法：休眠线程不会有任何害处。但是他能够触发不幸的副作用，我们来看看都有哪些。</p> 
  </div> 
  <div class="sect2"> 
   <h3 id="死锁">死锁</h3> 
   <div class="paragraph"> 
    <p><strong>死锁</strong> 发生在一个线程等待另一个线程持有的共享变量，而第二个线程在等待第一个线程持有的共享变量。这种情况通常在使用多个互斥锁的时候发生：2个线程在死循环中永久等待：线程A在等待线程B，线程B在等待线程A，而线程A又在等待线程B，如此往复。。。</p> 
   </div> 
  </div> 
  <div class="sect2"> 
   <h3 id="饥饿">饥饿</h3> 
   <div class="paragraph"> 
    <p>当线程没有得到足够的爱就进入 <strong>饥饿</strong> 模式：它永远卡在休眠模式等待访问共享资源，但是这个共享资源持续的给了其他线程。例如一个基于信号量的糟糕实现可能会忘记唤醒等待队列中的一些线程，这个可以通过给部分线程高优先级的方式实现。饥饿线程会永久等待而不能做任何有效的工作。</p> 
   </div> 
  </div> 
  <div class="sect2"> 
   <h3 id="无效唤醒">无效唤醒</h3> 
   <div class="paragraph"> 
    <p>这是一些操作系统中条件变量的具体实现方式带来的微妙问题。一个 <strong>无效唤醒</strong> 可能是线程没有收到条件变量的信号而被唤醒了。这也是多数同步原语中包含了检查唤醒信号是否真的来自线程正在等待的条件变量的方法的原因。</p> 
   </div> 
  </div> 
  <div class="sect2"> 
   <h3 id="优先级反转">优先级反转</h3> 
   <div class="paragraph"> 
    <p><strong>优先级反转</strong> 是一个执行高优先级任务的线程阻塞等待一个低优先级的线程释放资源，如互斥锁。例如输出音频到声卡的线程（高优先级）被显示界面的线程（低优先级）阻塞了，会导致扬声器严重的卡顿。</p> 
   </div> 
  </div> 
 </div> 
</div> 
<div class="sect1"> 
 <h2 id="下一步">下一步</h2> 
 <div class="sectionbody"> 
  <div class="paragraph"> 
   <p>这些同步问题被研究很多年了，也有很多技术和架构方面的解决方法。严谨的设计和一些实际经验能很大程度上预防问题的发生。鉴于多线程程序的<a href="https://www.reploop.org/blog/2020/02/a-gentle-introduction-to-multithreading.html">不确定性</a>(非常难的)性质，也有人开发出来在并发代码中检测错误和潜在缺陷的有趣工具。就像 <a href="https://github.com/google/sanitizers/wiki/ThreadSanitizerCppManual">Google的TSan</a>或者 <a href="http://valgrind.org/docs/manual/hg-manual.html">Helgrind</a>一样。</p> 
  </div> 
  <div class="paragraph"> 
   <p>尽管如此，有时候你可能在多线程应用中采用不同的方法，完全去掉阻塞机制。这意味着进入 <strong>非阻塞</strong> 领域：这是一个非常底层的领域，线程不会被操作系统休眠，并发是通过 <strong>原子操作</strong> 和 <strong>无锁数据结构</strong> 规范的。这是一个充满挑战的领域，并不总是有必要，但是它能够加速你的软件或者对他造成严重的破坏。不过这是下一篇文章的内容。</p> 
  </div> 
 </div> 
</div> 
<div class="sect1"> 
 <h2 id="参考">参考</h2> 
 <div class="sectionbody"> 
  <div class="ulist"> 
   <ul> 
    <li> <p>Wikipedia - <a href="https://en.wikipedia.org/wiki/Synchronization_%28computer_science%29#Thread_or_process_synchronization">Synchronization (computer science)</a></p> </li> 
    <li> <p>Wikipedia - <a href="https://en.wikipedia.org/wiki/Reentrant_mutex">Reentrant mutex</a></p> </li> 
    <li> <p>Wikipedia - <a href="https://en.wikipedia.org/wiki/Reentrancy_%28computing%29">Reentrancy (computing)</a></p> </li> 
    <li> <p>Wikipedia - <a href="https://en.wikipedia.org/wiki/Semaphore_%28programming%29">Semaphore (programming)</a></p> </li> 
    <li> <p>Wikipedia - <a href="https://en.wikipedia.org/wiki/Spurious_wakeup">Spurious Wakeup</a></p> </li> 
    <li> <p>Wikipedia - <a href="https://en.wikipedia.org/wiki/Priority_inversion">Priority inversion</a></p> </li> 
    <li> <p>Wikipedia - <a href="https://en.wikipedia.org/wiki/Deadlock">Deadlock</a></p> </li> 
    <li> <p>Wikipedia - <a href="https://en.wikipedia.org/wiki/Starvation_%28computer_science%29">Starvation (computer science)</a></p> </li> 
    <li> <p>Columbia Engineering - <a href="http://www.cs.columbia.edu/~hgs/os/sync.html">Synchronization primitives</a></p> </li> 
    <li> <p>StackOverflow - <a href="https://stackoverflow.com/questions/8017507/definition-of-synchronization-primitive">Definition of “synchronization primitive”</a></p> </li> 
    <li> <p>StackOverflow - <a href="https://stackoverflow.com/questions/2332765/lock-mutex-semaphore-whats-the-difference">Lock, mutex, semaphore… what’s the difference?</a></p> </li> 
    <li> <p>StackOverflow - <a href="https://stackoverflow.com/questions/11173532/why-is-locking-a-stdmutex-twice-undefined-behaviour">Why is locking a std::mutex twice 'Undefined Behaviour'?</a></p> </li> 
    <li> <p>Operating Systems: Three Easy Pieces - <a href="http://pages.cs.wisc.edu/~remzi/OSTEP/">Concurrency</a></p> </li> 
    <li> <p>Jaka’s Corner - <a href="http://jakascorner.com/blog/2016/01/data-races.html">Data race and mutex</a></p> </li> 
    <li> <p>Java 10 API specs - <a href="https://docs.oracle.com/javase/10/docs/api/java/util/concurrent/Semaphore.html">Class Semaphore</a></p> </li> 
    <li> <p>Oracle’s Multithreaded Programming Guide - <a href="https://docs.oracle.com/cd/E19455-01/806-5257/6je9h032t/index.html">Read-Write Lock Attributes</a></p> </li> 
    <li> <p>Oracle’s Multithreaded Programming Guide - <a href="https://docs.oracle.com/cd/E19455-01/806-5257/6je9h0347/index.html">Avoiding Deadlock</a></p> </li> 
    <li> <p>Just Software Solutions - <a href="https://www.justsoftwaresolutions.co.uk/threading/locks-mutexes-semaphores.html">Locks, Mutexes, and Semaphores: Types of Synchronization Objects</a></p> </li> 
    <li> <p>Just Software Solutions - <a href="https://www.justsoftwaresolutions.co.uk/threading/non_blocking_lock_free_and_wait_free.html">Definitions of Non-blocking, Lock-free and Wait-free</a></p> </li> 
    <li> <p>Cppreference - <a href="https://en.cppreference.com/w/cpp/thread/shared_mutex">std::shared_mutex</a></p> </li> 
    <li> <p>Cppreference - <a href="https://en.cppreference.com/w/cpp/thread/condition_variable">std::condition_variable</a></p> </li> 
    <li> <p>Quora - <a href="https://www.quora.com/What-is-the-difference-between-a-mutex-and-a-semaphore">What is the difference between a mutex and a semaphore?</a></p> </li> 
    <li> <p>gerald-fahrnholz.eu - <a href="http://www.gerald-fahrnholz.eu/sw/online_doc_multithreading/html/group___grp_condition_variable_safe_way.html">Using condition variables - the safe way</a></p> </li> 
    <li> <p>Politecnico di Milano - <a href="http://home.deib.polimi.it/loiacono/uploads/Teaching/CP/CP_04_Pthread_CondVar.pdf">Thread Posix: Condition Variables</a></p> </li> 
    <li> <p>SoftwareEngineering - <a href="https://softwareengineering.stackexchange.com/questions/186842/spurious-wakeups-explanation-sounds-like-a-bug-that-just-isnt-worth-fixing-is">Spurious wakeups explanation sounds like a bug that just isn’t worth fixing, is that right?</a></p> </li> 
    <li> <p>Android Open Source Project - <a href="https://source.android.com/devices/audio/avoiding_pi">Avoiding Priority Inversion</a></p> </li> 
   </ul> 
  </div> 
  <div class="paragraph"> 
   <p>本文译自https://www.internalpointers.com/post/introduction-thread-synchronization，英文读者可直接阅读原文。</p> 
  </div> 
 </div> 
</div></p>

	<hr />
	
	<p><a href="../archive.html">点击查看更多文章</a>.</p>

		</div>
		<div id="push"></div>
    </div>
    
    <div id="footer">
      <div class="container">
        <p class="muted credit">&copy; 2020 | Mixed with <a href="http://getbootstrap.com/">Bootstrap v3.1.1</a> | Baked with <a href="http://jbake.org">JBake v2.7.0.1</a></p>
      </div>
    </div>
    
    <!-- Le javascript
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="../js/jquery-1.11.1.min.js"></script>
    <script src="../js/bootstrap.min.js"></script>
    <script src="../js/prettify.js"></script>


<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  messageStyle: "none",
  tex2jax: {
    inlineMath: [["\\(", "\\)"]],
    displayMath: [["\\[", "\\]"]],
    ignoreClass: "nostem|nolatexmath"
  },
  asciimath2jax: {
    delimiters: [["\\$", "\\$"]],
    ignoreClass: "nostem|noasciimath"
  },
  TeX: { equationNumbers: { autoNumber: "none" } }
})
MathJax.Hub.Register.StartupHook("AsciiMath Jax Ready", function () {
  MathJax.InputJax.AsciiMath.postfilterHooks.Add(function (data, node) {
    if ((node = data.script.parentNode) && (node = node.parentNode) && node.classList.contains('stemblock')) {
      data.math.root.display = "block"
    }
    return data
  })
})
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_HTMLorMML"></script>
  </body>
</html>