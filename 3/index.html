<!DOCTYPE html>
<html lang="zh_CN">
  <head>
    <meta charset="utf-8"/>
    <title>REPLoop</title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="author" content="乔治">
    <meta name="keywords" content="REPL,REPLoop,George,乔治">
    <meta name="generator" content="JBake v2.7.0.1">
    <meta property=og:locale content=zh_CN>
    <!-- Le styles -->
    <link href="../css/bootstrap.min.css" rel="stylesheet">
    <link href="../css/asciidoctor.css" rel="stylesheet">
    <link href="../css/base.css" rel="stylesheet">
    <link href="../css/prettify.css" rel="stylesheet">

    <!-- HTML5 shim, for IE6-8 support of HTML5 elements -->
    <!--[if lt IE 9]>
      <script src="../js/html5shiv.min.js"></script>
    <![endif]-->

    <!-- Fav and touch icons -->
    <!--<link rel="apple-touch-icon-precomposed" sizes="144x144" href="../assets/ico/apple-touch-icon-144-precomposed.png">
    <link rel="apple-touch-icon-precomposed" sizes="114x114" href="../assets/ico/apple-touch-icon-114-precomposed.png">
    <link rel="apple-touch-icon-precomposed" sizes="72x72" href="../assets/ico/apple-touch-icon-72-precomposed.png">
    <link rel="apple-touch-icon-precomposed" href="../assets/ico/apple-touch-icon-57-precomposed.png">-->
    <link rel="shortcut icon" href="../img/favicon.svg">
    <script data-ad-client="ca-pub-2350040335860411" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  </head>
  <body onload="prettyPrint()">
    <div id="wrap">	
	<!-- Fixed navbar -->
    <div class="navbar navbar-default navbar-fixed-top" role="navigation">
      <div class="container">
        <div class="navbar-header">
          <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </button>
          <a class="navbar-brand" href="../">REPLoop</a>
        </div>
        <div class="navbar-collapse collapse">
          <ul class="nav navbar-nav">
            <li><a href="../index.html">博客</a></li>
            <li><a href="../archive.html">归档</a></li>
            <li><a href="../tags/index.html">标签</a></li>
            <li><a href="../about.html">关于</a></li>
            <li><a href="../feed.xml">订阅</a></li>
          </ul>
        </div><!--/.nav-collapse -->
      </div>
    </div>
    <div class="container">
  		<a href="blog/2020/03/how-https-works.html"><h1>HTTPS如何工作的？</h1></a>
  		<p>
			<a href="/about.html"><strong>George Cao</strong></a>于2020年03月28日
					<span class="badge badge-dark">HTTP</span>
					<span class="badge badge-dark">HTTPS</span>
					<span class="badge badge-dark">CA</span>
					<span class="badge badge-dark">RSA</span>
					<span class="badge badge-dark">信任链</span>
					<span class="badge badge-dark">非对称加密</span>
					<span class="badge badge-dark">证书</span>
					<span class="badge badge-dark">密钥对</span>
					<span class="badge badge-dark">证书链</span>
					<span class="badge badge-dark">数字签名</span>
		</p>
  		<p><div id="preamble"> 
 <div class="sectionbody"> 
  <div class="paragraph"> 
   <p>如今的HTTPS基本上已经占据了大部分流量,根据 <a href="https://transparencyreport.google.com/https/overview?hl=en">Google Chrome的统计</a>，截止2020年3月21日，有 <strong>96%</strong> 的请求是走HTTPS的。以Chrome浏览器的市场占有率，应该很能说明问题了。嗯，HTTPS在大部分场景下基本上是标配了。那弄懂HTTPS的工作机制就很有必要了。</p> 
  </div> 
  <div class="imageblock"> 
   <div class="content"> 
    <img src="https://www.reploop.org/blog/2020/03/images/https-by-chrome.png" alt="HTTPS Encryption by Chrome platform"> 
   </div> 
  </div> 
 </div> 
</div> 
<div class="sect1"> 
 <h2 id="从http到https">从HTTP到HTTPS</h2> 
 <div class="sectionbody"> 
  <div class="paragraph"> 
   <p>超文本传输协议（英语：HyperText Transfer Protocol，缩写：HTTP）是一种用于分布式、协作式和超媒体信息系统的应用层协议。HTTP是万维网的数据通信的基础。而HTTPS则可以称为安全版本的HTTP， HTTPS开发的主要目的，是提供对网站服务器的身份认证，保护交换数据的隐私与完整性。</p> 
  </div> 
 </div> 
</div> 
<div class="sect1"> 
 <h2 id="网站服务器身份认证">网站服务器身份认证</h2> 
 <div class="sectionbody"> 
  <div class="paragraph"> 
   <p>拿Facebook作为例子，当我们在浏览器地址栏输入http://www.facebook.com之后，我们怎么能确定访问的就是Facebook的网站呢? 大部分情况下应该是的，但是也有些钓鱼网站，DNS污染等等手段是能让我们访问到别有用心的其他网站。也就是说不管怎么样，我们不能100%的确信。为了能够确定我们访问的是真正的Facebook，我们是需要一种方法来确认服务器是Facebook的而不是其他网站的，也就是服务器的身份认证。如果能做到这个，我们就能判断出是否访问了攻击者仿冒的网站而不是真正的Facebook。</p> 
  </div> 
  <div class="paragraph"> 
   <p>幸运的是，使用非对称加密我们是可以做到的。具体就是Facebook需要有一对公钥和私钥，然后公布自己的公钥，但是把私钥安全保存在自己的服务器上。现在，你只要用Facebook的公钥加密自己的请求数据，根据加密知识，你知道只有Facebook的私钥才能解密这个数据。如果你访问的服务器能够正确的解密数据并且给你返回数据，你就能确信服务器有Facebook的私钥。</p> 
  </div> 
  <div class="paragraph"> 
   <p>只要Facebook能够保护好自己的私钥，确保不被其他人盗用，我们就解决了服务器的认证问题，简单。这样的话，尽管受到互联网本身特性的制约，我们还是设计了一种方法来验证网站的身份。事实上，我们刚刚描述的这个过程和真正的HTTPS是非常像的。当我们说一个服务器的HTTPS证书的时候，我们其实说的就是一个公钥。</p> 
  </div> 
  <div class="paragraph"> 
   <p>尽管如此，上述过程存在一个大问题，而这个问题HTTPS必须要解决的。这个问题就是你如何获取每个你想访问的网站的公钥呢？当然了，你有了Facebook的公钥就可以安全的访问Facebook了，但是，如果你想安全的访问Google，你需要Google的公钥。同样的，你想安全的访问Twitter，你需要Twitter的公钥。</p> 
  </div> 
  <div class="paragraph"> 
   <p>互联网上有成千上万的网站，而且还在不停的变化。所以就不太可能在你的个人电脑上保存一份全部网站的公钥，只能换一种思路了。现在，我们可以不用在电脑上一直维护这个巨大的公钥列表，而是在第一次访问网站的时候让网站发给我们她的公钥。不过这样就又回到开始的问题了：如果我们在不知情的情况下访问了恶意的第三方，那第三方可能会伪装并且发送她自己的公钥给我们。</p> 
  </div> 
  <div class="paragraph"> 
   <p>到这一步，你可能要泄气了。虽然我们使用了公钥和私钥，但是我们实际上又回到了最初的问题：我们需要一种让Facebook能够证明其身份的方法，然后我们才能信任他们的公钥。既然如此，公钥的真正的意义又是啥呢？</p> 
  </div> 
  <div class="sect2"> 
   <h3 id="证书和证书颁发机构">证书和证书颁发机构</h3> 
   <div class="paragraph"> 
    <p>还有一个问题是互联网上的某个网站不能对每个访问者验证其公钥的有效性，因为现今互联网的规模大到这么做是不经济的。想象一下Facebook <a href="https://www.statista.com/statistics/490424/number-of-worldwide-facebook-users/">16.9亿</a>用户，每个用户至少得发起一次请求，鉴于HTTP的无状态特性，每次请求都要验证一下这个公钥的有效性，这个规模是非常大的。为了解决这个问题，我们使用证书机构或者简称CA。</p> 
   </div> 
   <div class="paragraph"> 
    <p>证书机构(CA)能正确工作的前提是我们首先得信任他。这听起来有很多顾虑，但是实践中却工作的很好。CA是依靠信任的，所以当CA做了一些可疑的事情，浏览器马上就不再信任这些CA，这些CA也就该倒闭了。即使是CA方面的简单错误也足以永久破坏其声誉。</p> 
   </div> 
   <div class="paragraph"> 
    <p>那CA是如何解决我们的身份认证问题的呢？CA收钱为网站提供这种身份认证服务。DigiCert是一家有名的CA，同时也是Facebook使用的CA，我们就用她作为CA的例子。Facebook想证明她的公钥的有效身份，从而让用户安全的访问。所以她就花钱请DigiCert确认她就是真正的Facebook，一旦做了这个，DigiCert就会知道哪个公钥真的就是Facebook的。现在当你访问Facebook的时候，你就不需要Facebook证明她自己的身份了，你只需要Facebook证明DigiCert已经验证过她的身份就可以了。DigiCert为许多网站提供这种服务，你不需要弄清楚如何信任某个网站，你只需要信任DigiCert就可以了。如果你信任DigiCert，而DigiCert信任Facebook，那么理论上你就可以信任Facebook了。我们叫这个信任链。</p> 
   </div> 
   <div class="paragraph"> 
    <p>从抽象的高度看，这就是HTTPS的工作原理了。但是，我们需要弄清楚该过程的中的两个具体细节，才能理解详细的工作原理。</p> 
   </div> 
   <div class="ulist"> 
    <ul> 
     <li> <p>你怎么知道你正在使用DigiCert，而不是仿冒的DigiCert？</p> </li> 
    </ul> 
   </div> 
   <div class="paragraph"> 
    <p>这看起来又回到问题的起点了。如果我们拥有DigiCert的公钥，则可以验证其身份。但是我们需要以某种方式确保我们拥有DigiCert的公钥，而不是别人的。这里的解决办法是什么呢？其实是我们使用的操作系统或浏览器已经存储了DigiCert的公钥。现如今，我们信任很多CA，只不过她们是众所周知的，才能让现代操作系统或者浏览器存储她们的公钥。这部分公钥存储在计算机的“受信任的根证书颁发机构存储区(Trusted Root Certificate Authority Store)”中。存储的密钥数量似乎很多，但这总比为互联网上的每个网站存储一个公钥要容易多了。</p> 
   </div> 
   <div class="ulist"> 
    <ul> 
     <li> <p>Facebook如何证明DigiCert对其进行了验证？</p> </li> 
    </ul> 
   </div> 
   <div class="paragraph"> 
    <p>一旦DigiCert验证过Facebook就是Facebook之后，DigiCert就知道了Facebook的真正公钥，然后使用自己的私钥对Facebook的公钥进行数字签名，并且将这个签名后的公钥给Facebook。这种交互完全发生在Facebook和DigiCert之间，而且远远早于用户连接到Facebook的时间，一般网站上线之前就发生了。现在，当你连接到Facebook时，Facebook会给你发送一个已由DigiCert的私钥签名的公钥。然后你可以使用操作系统存储的公钥来验证DigiCert对Facebook的公钥进行了签名。</p> 
   </div> 
   <div class="paragraph"> 
    <p>整个过程中有两对公钥和私钥，一对是网站的，一对是CA的。双方都对外公布自己的公钥，并安全保存自己的私钥。网站的公钥先是给了CA，被签名之后间接的最终还是给了用户，这个公钥在协商阶段还会用到。而CA的公钥则直接被操作系统或者浏览器存储下来了，也相当于给了用户。CA用自己的私钥对网站的公钥进行数字签名，发给网站，这就是服务器的证书。当用户连接到服务器的握手环节，服务器发送证书给用户，用户通过本地的CA的公钥来解密网站发来的证书(CA私钥签名过的网站公钥)，如果成功则完成了验证问题。</p> 
   </div> 
  </div> 
 </div> 
</div> 
<div class="sect1"> 
 <h2 id="保护交换数据的隐私与完整性">保护交换数据的隐私与完整性</h2> 
 <div class="sectionbody"> 
  <div class="paragraph"> 
   <p>使用非对称加密完成了网站服务器的身份认证，接下来的保护交换数据的隐私与完整性则最终使用了对称加密手段。过程非常复杂，HTTPS的握手环节还进了用户与服务器之间一系列的加密算法，对称加密密码等等协商之后就可以进行安全的访问了。HTTPS完整的握手环节可以通过 <a href="https://tls13.ulfheim.net/">这里</a>查看，详细到每个字节，同时也解释了协议并且图形化描述了整个过程。</p> 
  </div> 
 </div> 
</div> 
<div class="sect1"> 
 <h2 id="参考">参考</h2> 
 <div class="sectionbody"> 
  <div class="olist arabic"> 
   <ol class="arabic"> 
    <li> <p>Google Transparency Report - <a href="https://transparencyreport.google.com/https/overview?hl=en">HTTPS encryption on the web</a></p> </li> 
    <li> <p>www.youdzone.com - <a href="http://www.youdzone.com/signature.html">What is a Digital Signature?</a></p> </li> 
    <li> <p>ulfheim.net - <a href="https://tls13.ulfheim.net/">The New Illustrated TLS Connection</a></p> </li> 
    <li> <p>dnsimple.com - <a href="https://support.dnsimple.com/articles/what-is-ssl-certificate-chain/">What is the SSL Certificate Chain?</a></p> </li> 
   </ol> 
  </div> 
 </div> 
</div></p>
  		<a href="blog/2020/02/understanding-memory-reordering.html"><h1>理解内存重排序以及为什写无锁多线程代码时很重要</h1></a>
  		<p>
			<a href="/about.html"><strong>George Cao</strong></a>于2020年02月29日
					<span class="badge badge-dark">内存模型</span>
					<span class="badge badge-dark">多线程</span>
					<span class="badge badge-dark">原子性</span>
					<span class="badge badge-dark">多线程</span>
					<span class="badge badge-dark">内存重排序</span>
		</p>
  		<p><div id="preamble"> 
 <div class="sectionbody"> 
  <div class="paragraph"> 
   <p>此系列前一篇文章中，<a href="https://www.reploop.org/blog/2020/02/lock-free-multithreading-with-atomic-operations.html">用原子操作实现无锁多线程</a>，我介绍了无锁多线程：并发软件中线程同步的底层机制。</p> 
  </div> 
  <div class="paragraph"> 
   <p>基于 <strong>原子操作</strong>，也就是CPU直接执行的不能细分为更小步骤的机器指令，相比传统的同步原语如<a href="https://www.reploop.org/blog/2020/02/introduction-to-thread-synchronization.html">互斥锁和信号量</a>，无锁多线程提供了更快和更细粒度控制的同步机制。</p> 
  </div> 
  <div class="paragraph"> 
   <p>一如既往的，能力越大，责任越大。无锁编码中你更接近本质，因此理解机器是如何工作的以及机器的特性是非常有益的。</p> 
  </div> 
  <div class="paragraph"> 
   <p>本文中我会介绍一些硬件（和软件）对无锁代码产生的非常重要的副作用。这也是惊叹计算机内部小型世界的复杂性的机会。</p> 
  </div> 
  <div class="ulist"> 
   <div class="title">
    本系列中的其他文章
   </div> 
   <ul> 
    <li> <p><a href="https://www.reploop.org/blog/2020/02/a-gentle-introduction-to-multithreading.html">多线程简介</a> - 一步一步走进并发的世界</p> </li> 
    <li> <p><a href="https://www.reploop.org/blog/2020/02/introduction-to-thread-synchronization.html">线程同步简介</a> - 多线程应用中最常见的并发控制方法之一</p> </li> 
    <li> <p><a href="https://www.reploop.org/blog/2020/02/lock-free-multithreading-with-atomic-operations.html">用原子操作实现无锁多线程</a> - 底层线程同步</p> </li> 
   </ul> 
  </div> 
 </div> 
</div> 
<div class="sect1"> 
 <h2 id="内存重排序或者不愉快的惊喜">内存重排序或者不愉快的惊喜</h2> 
 <div class="sectionbody"> 
  <div class="paragraph"> 
   <p>现有编程课程首先要教你的是计算机如何 <strong>顺序</strong> 执行用源代码写出的指令。一段程序就是文本文件中的一系列操作，处理器会从上到下执行这些操作。</p> 
  </div> 
  <div class="paragraph"> 
   <p>意外的，这常常是一个谎言：你的机器有能力按需调整 <em>一些</em> 底层指令的执行顺序，尤其是内存读取的时候。这个诡异的修改，叫做 <strong>内存重排序</strong>，会发生在硬件和软件层面，且经常是因为性能的原因。</p> 
  </div> 
  <div class="paragraph"> 
   <p>内存重排序开发出来旨在利用那些原本要浪费掉的指令周期。这个技巧能大幅度提升你程序的执行速度；另一方面，它可能对无锁多线程造成严重破坏。我们马上能看到为啥。</p> 
  </div> 
  <div class="paragraph"> 
   <p>我们先来仔细看一下内存重排序这种不可预知的行为存在的原因。</p> 
  </div> 
 </div> 
</div> 
<div class="sect1"> 
 <h2 id="内存重排序总结">内存重排序总结</h2> 
 <div class="sectionbody"> 
  <div class="paragraph"> 
   <p>程序想要执行，必须加载进 <strong>主内存</strong>。CPU的任务就是执行存储在那的指令，同时在必要的时候读数据或者写数据。</p> 
  </div> 
  <div class="paragraph"> 
   <p>随着时间的推移，这种类型的内存和处理器比起来变得非常慢。例如，一个现代的CPU一个纳秒内能够执行10个指令，但是需要纳秒的许多倍时间从此内存中读取数据！工程师们不喜欢时间就这样浪费了，所以他们给CPU配上了容量很小但是速度非常快的特殊内存，我们称之为 <strong>缓存</strong>。</p> 
  </div> 
  <div class="paragraph"> 
   <p>缓存是处理为了避免和慢速主内存交互，用来存储CPU最常用的数据的。如果CPU需要从主内存读取或者写入主内存，它首先检测缓存看是不是有所需数据的副本。如果有，处理器就直接从缓存读取或者写入缓存而不会等待相比较慢的主内存的响应。</p> 
  </div> 
  <div class="paragraph"> 
   <p>现代CPU有多个核心组成的，<strong>核心(core)</strong> 是真正执行计算的组件。每个核心拥有自己的独立缓存，如下图所示：</p> 
  </div> 
  <div class="imageblock"> 
   <div class="content"> 
    <img src="https://www.reploop.org/blog/2020/02/images/cpu-cache-main-memory.png" alt="CPU" width="cache and main memory"> 
   </div> 
   <div class="title">
    Figure 1. 多个核心通过缓存和主内存交互的简化模型。这也叫做共享内存系统，因为主内存被多个实体访问。
   </div> 
  </div> 
  <div class="paragraph"> 
   <p>总而言之，缓存能让计算机运行更快。更准确的说，缓存通过让处理器总是繁忙和高效来帮助处理器不要因为等待主内存响应而浪费宝贵的时间。</p> 
  </div> 
  <div class="sect2"> 
   <h3 id="内存重排序作为优化技巧">内存重排序作为优化技巧</h3> 
   <div class="paragraph"> 
    <p>很明显缓存机制增加了多核场景下系统的复杂性。现在你需要详细的规则来决定数据如何在不同的缓存间流动，来保证每个核心有最新版本的数据，称之为 <strong>缓存一致性协议</strong>，他可能引发非常大的性能下降。所以工程师们就设想用内存重排序来充分发挥每个核心的作用。</p> 
   </div> 
   <div class="paragraph"> 
    <p>内存重排序为什么会发生的理由有很多个。比如，考虑2个核心同时访问同样的内存块。核心A从内存读取数据，核心B写入数据到内存。内存一致性协议可能会强制核心A等待核心B将本地修改的数据写回到主内存，这样核心A就能读到最新的数据。等待的核心可以选择提前执行其他内存指令，而不是浪费珍贵的指令周期啥也不做，即使这个和你在程序中明确的代码顺序不一样。</p> 
   </div> 
   <div class="paragraph"> 
    <p>当特定的优化开启了，编译器和虚拟机也会自用重排序指令。这些变化发生在编译时，可以通过汇编码或者字节码很容易的看到。软件内存重排序是充分利用底层硬件可能提供的特性来让你的代码运行的更快。</p> 
   </div> 
  </div> 
 </div> 
</div> 
<div class="sect1"> 
 <h2 id="硬件内存重排序的具体样例">硬件内存重排序的具体样例</h2> 
 <div class="sectionbody"> 
  <div class="paragraph"> 
   <p>考虑下面用硬件伪代码写的样例。程序的每一个步骤都对应一个处理器指令：</p> 
  </div> 
  <div class="listingblock"> 
   <div class="content"> 
    <pre class="prettyprint highlight"><code data-lang="c">x = 0
v = false

thread_one():
    while load(v) == false:
        continue
    print(load(x))

thread_two():
    store(x, 1)
    store(v, true)</code></pre> 
   </div> 
  </div> 
  <div class="paragraph"> 
   <p>上面的代码片段中2个线程并发运行在2个不同的核心上。第1个线程等待第2个线程将 <code>v</code> 设置为 <code>true</code>。让我们假设 <code>store()</code> 和 <code>load()</code> 都是读取内存的原子的CPU指令。</p> 
  </div> 
  <div class="paragraph"> 
   <p>你预计第1个线程在屏幕上打印出什么？如果他在线程2之前启动（ <a href="https://internalpointers.com/post/gentle-introduction-multithreading#race-conditions">并不总是这样的</a>），就没有正确的答案了。如果没有重排序发生，你可能会看到1。尽管如此，如果第2个线程中的存储指令发生重排序，<code>v</code> 的更新也可能发生在 <code>x</code> 之前，打印语句可能打印出 <code>0</code>。相似的，内存重排序也可能发生在第1个线程中，也就是 <code>x</code> 的加载可能发生在 <code>v</code> 的检测之前。</p> 
  </div> 
 </div> 
</div> 
<div class="sect1"> 
 <h2 id="内存重排序对多线程的影响">内存重排序对多线程的影响</h2> 
 <div class="sectionbody"> 
  <div class="paragraph"> 
   <p>硬件内存重排序在单核计算机上没有问题，因为线程是操作系统控制的软件结构。CPU就是收到连续的内存指令流。指令还是可以被重新排序，不过要符合一个基本规则：给定内核的内存访问看上去就像和代码写的一样。所以，内存重排序可能会发生，但是只在不影响最终结果的前提下。</p> 
  </div> 
  <div class="paragraph"> 
   <p>这个规则也适用于多核场景下的每个单核，但不适用于不同操作同时跑在独立的硬件上的情况（ <a href="https://internalpointers.com/post/gentle-introduction-multithreading#what-threads-are-used-for">真并行(true parallelism)</a>）。让你的线程跑在两个物理内核上，你就会碰到上面样例中的各种诡异问题，更不用说让编译器和虚拟机执行重排序了。</p> 
  </div> 
  <div class="paragraph"> 
   <p>常规的如互斥锁和信号量等<a href="https://www.reploop.org/blog/2020/02/introduction-to-thread-synchronization.html">锁同步机制</a>是设计用来处理硬件和软件层面的内存重排序的。毕竟他们是上层技术。</p> 
  </div> 
  <div class="paragraph"> 
   <p>不过，应用无锁方案的多线程程序更接近底层：就像<a href="https://www.reploop.org/blog/2020/02/lock-free-multithreading-with-atomic-operations.html">上一篇文章</a>看到的，它利用存储和加载原子指令来同步线程。 搞笑的是这些操作可能被重排序，从而破坏了你的严谨计划。</p> 
  </div> 
 </div> 
</div> 
<div class="sect1"> 
 <h2 id="如何解决内存重排序的问题">如何解决内存重排序的问题</h2> 
 <div class="sectionbody"> 
  <div class="paragraph"> 
   <p>你肯定不会基于一些随机变化的东西构建你的同步机制。这个问题可以通过引入 <strong>内存屏障</strong> 的方式来解决。内存屏障是强制处理器按照可预知的方式访问内存的CPU指令。内存屏障的工作方式类似路障：内存屏障之前的指令保证先于内存屏障之后的指令执行。</p> 
  </div> 
  <div class="paragraph"> 
   <p>内存屏障是硬件层面的：你得直接和CPU交互。这是一个底层的解决方案，且不利用程序的可移植性。解决这个问题最好的方式是软件层次，利用操作系统，编译器或虚拟机提供的工具。</p> 
  </div> 
  <div class="paragraph"> 
   <p>尽管如此，软件工具也仅仅是中间阶段。为了构建一个此问题的清晰的全景图，我们首先全局看一下所有可能在硬件或者软件系统中的内存场景。<strong>内存模型</strong> 在这个过程中发挥重要作用。</p> 
  </div> 
 </div> 
</div> 
<div class="sect1"> 
 <h2 id="内存模型">内存模型</h2> 
 <div class="sectionbody"> 
  <div class="paragraph"> 
   <p>内存模型是抽象的方式描述系统中涉及到访问和重排序内存可能或者不可能发生的事情。处理器和编程语言会实现一个，尤其是利用多线程技术的时候：内存模型同时适用于硬件和软件层面。</p> 
  </div> 
  <div class="paragraph"> 
   <p>当系统对改变内存操作顺序非常谨慎，我们说系统遵循 <strong>强内存模型</strong>。相反的，<strong>弱内存模型</strong> 中你可能碰到各种各样的重排序。比如，x86系列的处理器属于前一类，而ARM和PowerPC处理器则属于后一类。软件层面又是怎么样的呢？</p> 
  </div> 
  <div class="sect2"> 
   <h3 id="软件内存模型的好处">软件内存模型的好处</h3> 
   <div class="paragraph"> 
    <p>硬件内存模型存在的原因很明显，而对应的软件内存模型让你能够按需重排内存访问顺序。这个特性在你写无锁多线程代码的代码能帮很大的忙。</p> 
   </div> 
   <div class="paragraph"> 
    <p>例如，为了避免同步机制中不受欢迎的原子操作的重排序，编译器可以编译出遵循强内存模型的机器码。当底层硬件实现的是弱内存模型的时候，编译器会通过加入正确的内存屏障指令来最大限度的提供你需要的内存模型。编译器也负责软件层面的内存重排序指令。使用软件内存模型可以解耦硬件细节。</p> 
   </div> 
   <div class="paragraph"> 
    <p>基本上，所有的编程语言都会实现一种内存模型，某种意义上说，他们都遵循特定的规则来处理内存。一些编程语言也就到此为止了，因为他们不直接处理多线程。其他的比如 <a href="https://docs.oracle.com/javase/9/docs/api/java/lang/invoke/VarHandle.html">Java</a>， <a href="https://doc.rust-lang.org/nomicon/atomics.html">Rust</a>和 <a href="https://en.cppreference.com/w/cpp/atomic/memory_order">C++</a>等也会提供上述的控制内存重排序行为的工具。</p> 
   </div> 
  </div> 
 </div> 
</div> 
<div class="sect1"> 
 <h2 id="细粒度内存模型">细粒度内存模型</h2> 
 <div class="sectionbody"> 
  <div class="paragraph"> 
   <p>强和弱内存模型是对内存操作如何重排序的理论上的分类。具体到真实的编码，大多数支持原子操作的编程语言会提供3种控制内存重排序的方式。我们仔细看一下。</p> 
  </div> 
  <div class="sect2"> 
   <h3 id="1顺序一致">1）顺序一致</h3> 
   <div class="paragraph"> 
    <p>较少干扰的内存重排序方式就是根本不重排序。这是强内存模型的一种形式，称之为顺序一致：这正是解决上面提到的所有无锁多线程问题所需要的。禁用重排序能让你的多线程程序容易理解：源代码是按照书写顺序执行的。</p> 
   </div> 
   <div class="paragraph"> 
    <p>顺序一致给并行代码执行加了另外一个重要特性：它强制了所有线程中的所有内存原子操作的 <strong>整体顺序</strong>。为了更好理解这句话，考虑如下的硬件伪代码样例：</p> 
   </div> 
   <div class="listingblock"> 
    <div class="content"> 
     <pre class="prettyprint highlight"><code data-lang="c">x = 0
y = 0

thread_A:
    store(x, 1)

thread_B:
    store(y, 1)

thread_C:
    assert(load(x) == 1 &amp;&amp; load(y) == 0)

thread_D:
    assert(load(x) == 0 &amp;&amp; load(y) == 1)</code></pre> 
    </div> 
   </div> 
   <div class="paragraph"> 
    <p>我们暂时不考虑单个线程内的内存重排序，看一下全局情况。如果线程按照A-C-B-D的顺序运行，线程C能看到 <code>x == 1</code> 和 <code>y == 0</code>，这是因为线程C是在线程A和线程B之间运行的，因此线程C的断言不会失败。但是这也是问题所在：顺序一致强加的全局顺序迫使线程D看到与线程C一样的事件，因此线程D的断言会失败。线程D不可能看到和线程C不一样的存储顺序。换句话说，线性一致下，所有的线程都看到同样的东西。</p> 
   </div> 
   <div class="paragraph"> 
    <p>就像前面说过的，这是一个非常直观和自然的思考多线程执行的方式。尽管如此，顺序一致也取消了内存重排序带来的任何硬件或者软件优化：这通常会引起严重性能瓶颈。顺序一致有些时候是必要的，比如多生产者-多消费者情况下消费者必须按照生产者的生产顺序消费。</p> 
   </div> 
  </div> 
  <div class="sect2"> 
   <h3 id="2获取_释放顺序">2）获取-释放顺序</h3> 
   <div class="paragraph"> 
    <p><strong>获取-释放</strong> 是强和弱内存模型的中间状态。首先，获取-释放和顺序一致工作方式相似，除了没有全局执行顺序。我们在看一下上面的那个例子：在获取-释放情况下，线程D是允许看到不同于线程C的事件，因此线程D的断言有可能会通过。</p> 
   </div> 
   <div class="paragraph"> 
    <p>全局顺序的缺失其实是个副作用。获取-释放是针对 <em>特定</em> 共享原子变量在 <em>多个线程之间</em> 同步的。也就是说，你在线程A和线程C之间同步共享变量 <code>x</code>，使得线程C只能在线程A完成写入之后才读取。这种情况下，<code>y</code> 并没有考虑进去，所以你可碰到任何针对它的重排序。</p> 
   </div> 
   <div class="paragraph"> 
    <p>具体来说，支持这种有序性的编程语言允许你将内存访问标记为获取或者释放。当线程B触发某共享变量上标记为获取的原子加载操作，线程A中的同一个共享变量上标记为释放的原子存储可确保线程B将看到线程A执行的完整且不是重新排序的内存事件序列。我知道这比较烧脑，不过这是互斥锁的基础：关键区和它保护的区域就是用这个构建的（获取-释放名字来源于互斥锁术语，也就是获取和释放互斥锁）。</p> 
   </div> 
   <div class="paragraph"> 
    <p>获取-释放允许更多的优化机会，因为仅有部分内存重排序不被允许。换句话说，你的程序更不容易推理分析了。</p> 
   </div> 
  </div> 
  <div class="sect2"> 
   <h3 id="3松散顺序">3）松散顺序</h3> 
   <div class="paragraph"> 
    <p>还有一种弱内存模型的形式。<strong>松散顺序</strong> 的情况下，你写程序的时候根本不关心内存重排序。编译器和处理器可以尽可能的优化程序执行。当然了内存操作的原子特性是保留下来了：这在增加共享计数器的时候非常有用，这种情况下操作必须是原子的才能让其他线程不能看到未完成的中间状态。</p> 
   </div> 
   <div class="paragraph"> 
    <p>松散有序性不保证任何特定的内存重排序，所以这不是可以安全使用的线程同步工具。另一方面，这也允许使用任何内存技巧来提升你的多线程程序的性能。</p> 
   </div> 
  </div> 
 </div> 
</div> 
<div class="sect1"> 
 <h2 id="下一步">下一步？</h2> 
 <div class="sectionbody"> 
  <div class="paragraph"> 
   <p>这篇文章中，我想对内存重排序问题以及其存在的原因和它对无锁多线程的影响有一个全面的了解。接下来我会写一些使用原子操作的C++代码来实践一下。</p> 
  </div> 
  <div class="paragraph"> 
   <p>为什么是C++ ？因为C++语言近期引入了 <a href="https://en.cppreference.com/w/cpp/language/memormodel">非常详细的内存模型</a>，使得你能够细粒度的控制C++原子对象的内存重排序操作。我相信这是一个很好的方式去看顺序一致，获取-释放和松散有序在真实的场景下是如何一起工作的。祝我好运吧:)。</p> 
  </div> 
 </div> 
</div> 
<div class="sect1"> 
 <h2 id="参考">参考</h2> 
 <div class="sectionbody"> 
  <div class="ulist"> 
   <ul> 
    <li> <p>AA.VV. - <a href="https://www.morganclaypool.com/doi/abs/10.2200/S00346ED1V01Y201104CAC016">A Primer on Memory Consistency and Cache Coherence</a></p> </li> 
    <li> <p>AA. VV. - <a href="https://books.google.it/books?id=MMNiDwAAQBAJ">C++ Reactive Programming</a></p> </li> 
    <li> <p>Paul E. McKenney - <a href="http://www.puppetmastertrading.com/images/hwViewForSwHackers.pdf">Memory Barriers: a Hardware View for Software Hackers</a></p> </li> 
    <li> <p>cppreference.com - <a href="https://en.cppreference.com/w/cpp/atomic/memory_order">std::memory_order</a></p> </li> 
    <li> <p>GCC Wiki - <a href="https://gcc.gnu.org/wiki/Atomic/GCCMM/AtomicSync">Memory model synchronization modes</a></p> </li> 
    <li> <p>doc.rust-lang.org - <a href="https://doc.rust-lang.org/nomicon/atomics.html">Atomics</a></p> </li> 
    <li> <p>Herb Sutter - <a href="https://youtu.be/A8eCGOqgvH4?t=3419">Atomic Weapons 1 of 2</a></p> </li> 
    <li> <p>The ryg blog - <a href="https://fgiesen.wordpress.com/2014/07/07/cache-coherency/">Cache coherency primer</a></p> </li> 
    <li> <p>The ryg blog - <a href="https://fgiesen.wordpress.com/2014/08/18/atomics-and-contention/">Atomic operations and contention</a></p> </li> 
    <li> <p>Bartosz Milewski - <a href="https://bartoszmilewski.com/2008/12/01/c-atomics-and-memory-ordering/">C++ atomics and memory ordering</a></p> </li> 
    <li> <p>Bartosz Milewski - <a href="https://bartoszmilewski.com/2008/11/11/who-ordered-sequential-consistency/">Who ordered sequential consistency?</a></p> </li> 
    <li> <p>StackOverflow - <a href="https://stackoverflow.com/questions/30958375/memory-barriers-force-cache-coherency">Memory barriers force cache coherency?</a></p> </li> 
    <li> <p>StackOverflow - <a href="https://stackoverflow.com/questions/25345440/how-does-the-cache-coherency-protocol-enforce-atomicity">How does the cache coherency protocol enforce atomicity?</a></p> </li> 
    <li> <p>StackOverflow - <a href="https://stackoverflow.com/questions/42746793/does-a-memory-barrier-ensure-that-the-cache-coherence-has-been-completed">Does a memory barrier ensure that the cache coherence has been completed?</a></p> </li> 
    <li> <p>StackOverflow - <a href="https://stackoverflow.com/questions/6319146/c11-introduced-a-standardized-memory-model-what-does-it-mean-and-how-is-it-g">C11 introduced a standardized memory model. What does it mean? And how is it going to affect C programming?</a></p> </li> 
    <li> <p>StackOverflow - <a href="https://stackoverflow.com/questions/12340773/how-do-memory-order-seq-cst-and-memory-order-acq-rel-differ">How do memory_order_seq_cst and memory_order_acq_rel differ?</a></p> </li> 
    <li> <p>StackOverflow - <a href="https://stackoverflow.com/questions/12346487/what-do-each-memory-order-mean">What do each memory_order mean?</a></p> </li> 
    <li> <p>Just Software Solutions - <a href="https://www.justsoftwaresolutions.co.uk/threading/memory_models_and_synchronization.html">Memory Models and Synchronization</a></p> </li> 
    <li> <p>Wikipedia - <a href="https://en.wikipedia.org/wiki/CPU_cache">CPU cache</a></p> </li> 
    <li> <p>Wikipedia - <a href="https://en.wikipedia.org/wiki/Cache_coherence">Cache coherence</a></p> </li> 
    <li> <p>Wikipedia - <a href="https://en.wikipedia.org/wiki/Memory_barrier">Memory barrier</a></p> </li> 
    <li> <p>Wikipedia - <a href="https://en.wikipedia.org/wiki/Memory_ordering">Memory ordering</a></p> </li> 
    <li> <p>James Bornholt - <a href="https://www.cs.utexas.edu/~bornholt/post/memory-models.html">Memory Consistency Models: A Tutorial</a></p> </li> 
    <li> <p>Preshing on Programming - <a href="https://preshing.com/20120625/memory-ordering-at-compile-time/">Memory Ordering at Compile Time</a></p> </li> 
    <li> <p>Preshing on Programming - <a href="https://preshing.com/20120710/memory-barriers-are-like-source-control-operations/">Memory Barriers Are Like Source Control Operations</a></p> </li> 
    <li> <p>Linux Journal - <a href="https://www.linuxjournal.com/article/8211">Memory Ordering in Modern Microprocessors, Part I</a></p> </li> 
    <li> <p>Doug Lea - <a href="http://gee.cs.oswego.edu/dl/html/j9mm.html">Using JDK 9 Memory Order Modes</a></p> </li> 
   </ul> 
  </div> 
  <div class="paragraph"> 
   <p>本文译自https://www.internalpointers.com/post/understanding-memory-ordering，英文读者可直接阅读原文。</p> 
  </div> 
 </div> 
</div></p>
  		<a href="blog/2020/02/lock-free-multithreading-with-atomic-operations.html"><h1>用原子操作实现无锁多线程：底层线程同步</h1></a>
  		<p>
			<a href="/about.html"><strong>George Cao</strong></a>于2020年02月27日
					<span class="badge badge-dark">原子指令</span>
					<span class="badge badge-dark">多线程</span>
					<span class="badge badge-dark">无锁</span>
					<span class="badge badge-dark">无等待</span>
					<span class="badge badge-dark">并发</span>
					<span class="badge badge-dark">算法</span>
		</p>
  		<p><div id="preamble"> 
 <div class="sectionbody"> 
  <div class="paragraph"> 
   <p>本文经 <a href="https://it.linkedin.com/in/federicarinaldi">Federica Rinaldi</a>仔细审阅过，谢谢。</p> 
  </div> 
  <div class="paragraph"> 
   <p>"atom"在希腊语中拾不可再分割的意思。在计算机中一个任务被称为原子的是指他不能再细分了：它不能再拆分为更小的执行步骤了。</p> 
  </div> 
  <div class="paragraph"> 
   <p><em>原子性</em> 是多线程操作的一个重要特征：因为原子操作是不可在细分的，所以一个线程是不可能干扰另一个正在并发执行原子操作的线程的。例如，当一个线程原子写入共享数据，其他线程是没有办法读取到未完成的数据。相反的，当一个线程原子读取共享数据，这个数据就像是单个时间点上的数据。换句话说，就是没有<a href="https://www.reploop.org/blog/2020/02/a-gentle-introduction-to-multithreading.html">数据竞争</a>的风险。</p> 
  </div> 
  <div class="ulist"> 
   <div class="title">
    本系列中的其他文章
   </div> 
   <ul> 
    <li> <p><a href="https://www.reploop.org/blog/2020/02/a-gentle-introduction-to-multithreading.html">多线程简介</a> - 一步一步走进并发的世界</p> </li> 
    <li> <p><a href="https://www.reploop.org/blog/2020/02/introduction-to-thread-synchronization.html">线程同步简介</a> - 多线程应用中最常见的并发控制方法之一</p> </li> 
    <li> <p><a href="https://www.reploop.org/blog/2020/02/understanding-memory-reordering.html">理解内存重排序</a> - 为什写无锁多线程代码时它很重要</p> </li> 
   </ul> 
  </div> 
  <div class="paragraph"> 
   <p>在<a href="https://www.reploop.org/blog/2020/02/introduction-to-thread-synchronization.html">上一篇文章</a>中，我介绍了所谓的 <strong>同步原语</strong>，也就是最常用的线程同步工具。他们是用来为多线程间处理共享数据的操作提供原子性的。怎么做到的呢？其实就是直接让单个线程执行并发任务，同时操作系统阻塞了其他线程直到第一个线程完成它的工作。这么做的原因是一个被阻塞的线程对其他线程是无害的。考虑到阻塞线程的能力，同步原语也称为 <strong>阻塞机制</strong>。</p> 
  </div> 
  <div class="paragraph"> 
   <p>上一篇文章中的任意一种阻塞机制对大多数应用来说能够很好的工作。如果能够正确的使用，他们也是快速的和可靠的。尽管如此，他们还是有一些你可能需要考虑的缺点：</p> 
  </div> 
  <div class="olist arabic"> 
   <ol class="arabic"> 
    <li> <p>他们会阻塞其他线程 - 休眠的线程什么也不做，单纯的等待唤醒信号：这可能会浪费宝贵的时间；</p> </li> 
    <li> <p>他们会卡死你的应用 - 如果一个持有同步原语锁的线程不管什么原因崩溃了，这个锁就永远不会释放了，等待这个锁的线程就永远卡住了；</p> </li> 
    <li> <p>你对休眠哪个线程没什么控制 - 通常是操作系统选择阻塞哪个线程。这会引发一个被称之为 <strong>优先级反转</strong> 的不幸结果： 一个执行非常重要任务的高优先级线程被一个低优先级线程阻塞了。</p> </li> 
   </ol> 
  </div> 
  <div class="paragraph"> 
   <p>大多数时候你不会关注这些问题，因为他们不影响你应用程序的正确性。另一方面，有时候使线程一直运行是需要的，特别是你想发挥多处理器/多核硬件的能力。或者你就是不能容忍系统被一个崩溃的线程拖死，或者优先级反转的问题不容忽视。</p> 
  </div> 
 </div> 
</div> 
<div class="sect1"> 
 <h2 id="无锁编程来救场">无锁编程来救场</h2> 
 <div class="sectionbody"> 
  <div class="paragraph"> 
   <p>好消息：还有另一种控制多线程应用中并发任务的方法，为了避免上面提到的1）,2）和3）点问题，称之为 <strong>无锁编程</strong>，这是一种不用加锁和解锁就可以安全的在多线程之间共享变化数据的技术。</p> 
  </div> 
  <div class="paragraph"> 
   <p>坏消息：这是非常底层的东西。比传统的同步原语比如互斥锁和信号量还底层多了：这次我们会更接近本质。尽管如此，我发现无锁编程是一个很好的思想挑战，也是一个非常好的更好理解计算机如何工作的机会。</p> 
  </div> 
  <div class="paragraph"> 
   <p>无锁编程依赖 <strong>原子指令</strong>，这是CPU直接执行的原子操作。原子指令作为无锁编程的基础，我将在本文剩下的部分首先介绍，然后展示如何利用它做并发控制。</p> 
  </div> 
 </div> 
</div> 
<div class="sect1"> 
 <h2 id="什么是原子指令">什么是原子指令？</h2> 
 <div class="sectionbody"> 
  <div class="paragraph"> 
   <p>思考计算中执行的任何操作，比如在屏幕上展示一张图片。这个操作是由许多更小的操作构成的：将文件读入内存，解压缩图片，点亮屏幕上的像素等等。如果你不停的细分这些更小的操作，也就是分为更小更小的操作，你最终会不能在分了。此时得到的处理器执行的肉眼可见的最小操作称之为 <strong>机器指令</strong>，也就是硬件可直接执行的命令。</p> 
  </div> 
  <div class="imageblock"> 
   <div class="content"> 
    <img src="https://www.reploop.org/blog/2020/02/images/software-hardware-layers.png" alt="Software - hardware layers"> 
   </div> 
   <div class="title">
    Figure 1. 计算机程序的不同层次。虚线代表软件层次，实线代表硬件层次。
   </div> 
  </div> 
  <div class="paragraph"> 
   <p>取决于不同的CPU架构，一些机器指令是原子的，也就是单个的，不能切分的，不会被中断的。一些其他的指令则不是原子的：处理器私底下以更小的操作的方式做了更多的工作，这些操作称之为 <strong><a href="https://en.wikipedia.org/wiki/Micro-operation">微指令</a></strong>。让我们给出更正式的分类：原子指令是不能在细分的CPU指令。更确切的说，原子指令可以被归为2个主要类型：<strong>存储与加载</strong> 和 <strong>读取-修改-写入（RMW）</strong>。</p> 
  </div> 
  <div class="sect2"> 
   <h3 id="存储与加载原子指令">存储与加载原子指令</h3> 
   <div class="paragraph"> 
    <p>存储和加载是处理器都需要的：用来写入（<strong>存储</strong>）和读取（<strong>加载</strong>）内存数据。在某些情况下，许多CPU架构保证这些操作是天然原子的。例如，实现了 <a href="https://en.wikipedia.org/wiki/X86">x86架构</a>的处理器使用 <strong>MOV</strong> 指令从内存中读取数据并交给CPU。这个操作如果处理的是 <a href="https://www.ibm.com/support/knowledgecenter/en/SSUFAU_1.0.0/com.ibm.ent.pl1.zos.doc/lr/alnmnt.html">对齐</a>的数据就能保证是原子的，对齐的数据是指能让CPU一次性读取出来的方式存储的数据。</p> 
   </div> 
  </div> 
  <div class="sect2"> 
   <h3 id="读取_修改_写入rmw原子指令">读取-修改-写入(RMW)原子指令</h3> 
   <div class="paragraph"> 
    <p>一些更复杂的操作不能够单独用一些简单存储和加载指令来完成。例如，增加存储中的数值需要至少3个原子的加载和存储指令，这就使的增加内存中数值这个操作不是原子的。<strong>读取-修改-写入（RMW）</strong> 指令可以做到这个，也就有了通过一个原子操作完成多个操作的能力。除了RMW，还有非常多此类的指令。一些CPU架构全部提供，一些则提供一部分，下面列举一些：</p> 
   </div> 
   <div class="ulist"> 
    <ul> 
     <li> <p><a href="https://en.wikipedia.org/wiki/Test-and-set">测试并设置</a> - 一个原子操作完成往内存中写入1并且返回赋值之前的值；</p> </li> 
     <li> <p><a href="https://en.wikipedia.org/wiki/Fetch-and-add">获取并增加</a> - 一个原子操作完成增加内存中的数值并且返回增加之前的值；</p> </li> 
     <li> <p><a href="https://en.wikipedia.org/wiki/Compare-and-swap">比较并交换（CAS）</a> - 比较内存中的数据和提供的数据，如果他们是相同的，将提供的另一个数据写入该内存中。</p> </li> 
    </ul> 
   </div> 
   <div class="paragraph"> 
    <p>以上这些操作都是一个原子操作完成多个操作。这是一个非常重要的特性，使得读取-修改-写入指令适合无锁多线程操作。我们很快就会看到为什么适合了。</p> 
   </div> 
  </div> 
 </div> 
</div> 
<div class="sect1"> 
 <h2 id="原子指令的三个层次">原子指令的三个层次</h2> 
 <div class="sectionbody"> 
  <div class="paragraph"> 
   <p>以上所有这些指令都属于硬件层面的：他们直接和CPU交互。这种工作方式是非常困难并且不可移植，因为一些指令可能在不同得架构下叫不同得名字，一些指令在不同的处理器模型上则根本不存在！因此，你也不太可能用到这些，除非你在针对特定得机器写非常底层得代码。</p> 
  </div> 
  <div class="paragraph"> 
   <p>上到软件层面，许多操作系统提供了各自的原子指令。姑且称之为 <strong>原子操作(atomic operations)</strong>，因为我们正在抽象出物理机器指令对应得原子操作。 例如， Windows系统上可能会用到 <a href="https://docs.microsoft.com/en-us/windows/desktop/sync/interlocked-variable-access">Interlocked API</a>，这是一组原子方式处理变量得函数。 MacOS则用 <a href="https://developer.apple.com/documentation/kernel/osatomic_h?language=objc">OSAtomc.h</a>头文件提供的函数做同样的事情。他们肯定是隐藏了硬件的具体实现，但是你还是受限于他们特定的环境。</p> 
  </div> 
  <div class="paragraph"> 
   <p>实现可移植原子操作的最好办法是使用你所选择的编程语言提供的原子操作。比如Java语言中有 <strong>java.util.concurrent.atomic</strong> 包；C++提供了 <strong>std::atomic</strong> 头文件； Haskell有 <strong>Data.Atomics</strong> 包等等。一般来讲，如果一个编程语言能处理多线程，那就很有可能会提供原子操作的支持。这样的话就是编译器（如果是编译语言）或者虚拟机（如果是解析语言）负责从底层操作系统API或者硬件中找到最合适的指令来实现原子操作。</p> 
  </div> 
  <div class="imageblock"> 
   <div class="content"> 
    <img src="https://www.reploop.org/blog/2020/02/images/atomics-levels.png" alt="Three levels of atomic instructions"> 
   </div> 
   <div class="title">
    Figure 2. 原子指令和操作的层级。虚线代表软件层次，实线代表硬件层次。
   </div> 
  </div> 
  <div class="paragraph"> 
   <p>例如，C++ 的编译器GCC通常是直接将 C++语言的原子操作和对象对应到机器指令。如果不能直接映射到硬件上，它也会利用其他可用的原子操作来实现特定操作。最坏情况下，在一个不提供原子操作的平台上，它可能利用其他阻塞策略来实现了，当然了这肯定不是无锁的实现。</p> 
  </div> 
 </div> 
</div> 
<div class="sect1"> 
 <h2 id="在多线程中使用原子操作">在多线程中使用原子操作</h2> 
 <div class="sectionbody"> 
  <div class="paragraph"> 
   <p>我们现在看看原子操作是如何使用的。 考虑增加一个简单的变量，这本来就不是原子操作，因为此操作由3个不同的步骤构成：读取数值，给数值加1，将结果写回。 一般来说，你可能会使用互斥锁来正确实现这个操作（伪代码）：</p> 
  </div> 
  <div class="listingblock"> 
   <div class="content"> 
    <pre class="prettyprint highlight"><code data-lang="c">mutex = initialize_mutex()
x     = 0

reader_thread()
    mutex.lock()
    print(x)
    mutex.unlock()

writer_thread()
    mutex.lock()
    x++
    mutex.unlock()</code></pre> 
   </div> 
  </div> 
  <div class="paragraph"> 
   <p>首先获得互斥锁的线程会继续执行，而其他线程则等待第一个线程执行完毕。</p> 
  </div> 
  <div class="paragraph"> 
   <p>相反的，无锁方案使用了不同的模式：通过原子操作，线程可以随意执行而不用阻塞，例如：</p> 
  </div> 
  <div class="listingblock"> 
   <div class="content"> 
    <pre class="prettyprint highlight"><code data-lang="c">x = 0

reader_thread()
    print(load(x))

writer_thread()
    fetch_and_add(x, 1)</code></pre> 
   </div> 
  </div> 
  <div class="paragraph"> 
   <p>我假设了 <code>fetch_and_add()</code> 和 <code>load()</code> 是基于相应的硬件指令的原子操作。 你可能已经发现了，这里并没有使用锁。 并发调用这些函数的多个线程都可以继续执行。<code>load()</code> 函数的原子性将保证不会有读线程读取到未完成修改的数据，同时因为 <code>fetch_and_add()</code> 的原子性，也不会有写线程能够部分修改数据。</p> 
  </div> 
  <div class="sect2"> 
   <h3 id="现实世界中的原子操作">现实世界中的原子操作</h3> 
   <div class="paragraph"> 
    <p>现在，上面这个例子显示了原子操作的一个重要特性：他们仅针对原子类型，如boolean型，字符串，整数等。但是真的程序是需要使用同步技术来实现更复杂的数据结构，比如数组，向量，对象，数据向量，对象里包含数据等等。如何用基于原子类型的简单操作来保证负责数据的原子性？</p> 
   </div> 
   <div class="paragraph"> 
    <p>无锁编程迫使你跳出常规的同步原语来思考问题。你不直接用原子操作保护共享资源，而是用互斥锁或者信号量。同样的，你会基于原子操作构建 <strong>无锁算法</strong> 或者 <strong>无锁数据结构</strong> 来确定多个线程如何访问你的数据。</p> 
   </div> 
   <div class="paragraph"> 
    <p>例如，上面看到的 <em>fetch-and-add</em> 操作可以用来实现一个基本的信号量，而这个信号量就可以用来协调多个线程。毫无意外，所有传统的阻塞同步工具都是基于原子操作的实现的。</p> 
   </div> 
   <div class="paragraph"> 
    <p>人们写了很多个无锁数据结构，比如Folly的 <a href="https://github.com/facebook/folly/blob/master/folly/AtomicHashMap.h">AtomicHashMap</a>， <a href="https://www.boost.org/doc/libs/1_70_0/doc/html/lockfree.html">Boost.Lockfree类库</a>，多生产者/多消费者， <a href="https://github.com/cameron314/concurrentqueue">先进先出队列</a>(FIFO)，或者诸如 <a href="https://www.youtube.com/watch?v=rxQ5K9lo034">读取-复制-更新（RCU）</a>和 <a href="https://en.wikipedia.org/wiki/Shadow_paging">影子分页</a>(Shadow Paging)等一些算法。从头开始写这些原子工具很困难，更不用说让他们正确工作。这也是大多数时候你可能会使用已经存在的，实战检验过得算法与数据结构，而不是使用自己实现的。</p> 
   </div> 
  </div> 
  <div class="sect2"> 
   <h3 id="比较并交换cas循环">比较并交换(CAS)循环</h3> 
   <div class="paragraph"> 
    <p>具体到实际应用，<strong>比较并交换循环</strong>(<strong>CAS loop</strong>)可能是无锁编程中最常用的技巧，无论你是使用现成的数据结构或者从头开始实现算法。这是基于对应的 <em>比较并交换</em> 原子操作（CAS）而且有一个很好的特点：他能支持多个写线程。这是用到复杂系统中的并发算法的一个重要特征。</p> 
   </div> 
   <div class="paragraph"> 
    <p>CAS循环非常有趣是因为他在无锁代码中引入了重复模式，同时引入了用于推理的理论概念。我们进一步看一下。</p> 
   </div> 
  </div> 
  <div class="sect2"> 
   <h3 id="cas循环实现">CAS循环实现</h3> 
   <div class="paragraph"> 
    <p>操作系统或者编程语言提供的CAS函数可能是这样的：</p> 
   </div> 
   <div class="listingblock"> 
    <div class="content"> 
     <pre class="prettyprint highlight"><code data-lang="c">boolean compare_and_swap(shared_data, expected_value, new_value);</code></pre> 
    </div> 
   </div> 
   <div class="paragraph"> 
    <p>他的入参有共享数据的引用/指针，预期共享数据当前的值以及将要赋值的新值。这个函数只有在 <code>shared_date.value == expected_value</code> 的情况下才会使用新数据替换原始数据，并且只有数据改变的情况下才返回 <code>true</code>。</p> 
   </div> 
   <div class="paragraph"> 
    <p>CAS循环的思路是不停的尝试比较和交换，直到操作成功。每一次尝试都需要给CAS函数传递共享数据的引用/指针，预期的数据和将要赋值的数据。这是和其他并发写线程配合的必要条件：如果其他线程在同步修改数据，也就是共享数据和预期数据不再匹配了，CAS函数就会失败。这样就支持了多个写线程。</p> 
   </div> 
   <div class="paragraph"> 
    <p>假设我们用CAS来实现前面代码片段实现的 <code>fetch-and-add</code> 算法，实现起来可能是这样的（伪代码）：</p> 
   </div> 
   <div class="listingblock"> 
    <div class="content"> 
     <pre class="prettyprint highlight"><code data-lang="c">x = 0

reader_thread()
    print(load(x))

writer_thread()
    temp = load(x)                              // (1)
    while(!compare_and_swap(x, temp, temp + 1)) // (2)</code></pre> 
    </div> 
   </div> 
   <div class="paragraph"> 
    <p>第（1）行代码加载共享数据，然后尝试和新的数据进行交换，直到交换成功返回 <code>true</code>（2）。</p> 
   </div> 
  </div> 
  <div class="sect2"> 
   <h3 id="交换范式">交换范式</h3> 
   <div class="paragraph"> 
    <p>正如前面说的，CAS循环在许多无锁算法中引入了重复模式:</p> 
   </div> 
   <div class="olist arabic"> 
    <ol class="arabic"> 
     <li> <p>创建共享数据的 <em>本地副本</em>；</p> </li> 
     <li> <p>按需修改本地副本；</p> </li> 
     <li> <p>合适的时候，通过 <em>交换</em> 更新后的数据与之前创建的副本数据来更新共享数据。</p> </li> 
    </ol> 
   </div> 
   <div class="paragraph"> 
    <p>第3）点是关键：交换是通过原子操作来保证原子性的。本地写线程针对副本数据做了大部分的脏活累活，等到合适的时候才发布更新到共享数据。这样的话，其他线程只能看到这个共享数据的2种状态：未修改的数据和修改后的数据。由于原子交换，看不到修改过程中的中间状态，或者出错的更新。</p> 
   </div> 
   <div class="paragraph"> 
    <p>这也是哲学上不同于加锁方案的：无锁算法中，多线程仅仅在执行交换的时候才需要交互，其他时候都不被打扰的运行，也感知不到其他线程的存在。多线程之间的交互点缩小了并且被限制在执行原子操作的期间。</p> 
   </div> 
  </div> 
  <div class="sect2"> 
   <h3 id="一种轻量级加锁形式">一种轻量级加锁形式</h3> 
   <div class="paragraph"> 
    <p>上面看到的 <em>循环直到成功</em> 的策略在许多无锁算法中用到了，被称之为 <strong>自旋锁(spinlock)</strong>：一个简单的循环，线程不停的尝试执行操作直到成功。这是一种轻量级的加锁形式，此时线程是实时活跃运行的，不会被操作系统休眠，尽管这个循环成功之前工作不会有进展。相比之下，互斥锁或者信号量中用到的常规锁代价非常高，因为一个挂起/唤醒周期需要大量的底层工作。</p> 
   </div> 
  </div> 
  <div class="sect2"> 
   <h3 id="aba问题">ABA问题</h3> 
   <div class="paragraph"> 
    <p>行（1）和（2）所示指令虽然有所不同，但不是连续的。另一个线程可能插入中间，再（1）读取完成之后修改共享数据。更确切的说，另一个线程可以将初始数据，假设为A，修改为B，然后在（2）所示的比较并交换操作执行之前再修改回A。执行CAS操作的线程不会发现数据的变化而成功执行交换操作。这就是所谓的ABA问题：有时候你可以简单的直接忽略，如果你的算法就像上面那个一样简单，而有时候你就需要避免此问题，因为这会给你的应用程序引入非常难以发现的问题。幸运的是有 <a href="https://en.wikipedia.org/wiki/Compare-and-swap#ABA_problem">几种方式</a> 可以绕过这个问题。</p> 
   </div> 
  </div> 
  <div class="sect2"> 
   <h3 id="cas循环可以交换任意的事情">CAS循环可以交换任意的事情</h3> 
   <div class="paragraph"> 
    <p>CAS循环经常用来交换指针，这也是 <em>比较并交换</em> 操作支持的类型之一。当你需要修改复杂的诸如对象或者数组的数据集的时候非常有用：创建本地数据副本，按需修改这个副本，合适的时候交换本地副本数据和全局共享数据的指针。这样的话全局共享数据就指向了本地副本数据在内存中指针，其他线程就会看到更新后的最新数据。</p> 
   </div> 
   <div class="paragraph"> 
    <p>这个技术允许你同步非原始数据实体(primitive entities)，尽管要做到这个也有一定的难度。比如交换完成之后，一个读线程还在读取老的指针？如何安全的删除之前的数据副本而不引起非常危险的野指针问题？工程师们再一次的找到了很多解决方案，比如使用支持内存自动 <a href="https://en.wikipedia.org/wiki/Garbage_collection_(computer_science)">垃圾回收</a>的语言，或者一些深奥的技术如 <a href="https://aturon.github.io/blog/2015/08/27/epoch/">分代内存回收</a>， <a href="https://en.wikipedia.org/wiki/Hazard_pointer">冒险指针</a>或者 <a href="https://en.wikipedia.org/wiki/Reference_counting">引用计数</a>。</p> 
   </div> 
  </div> 
 </div> 
</div> 
<div class="sect1"> 
 <h2 id="无锁和无等待">无锁和无等待</h2> 
 <div class="sectionbody"> 
  <div class="paragraph"> 
   <p>每个基于原子操作的算法或者数据结构都可以归为2类：<strong>无锁的</strong> 或者 <strong>无等待的</strong>。当你要评估基于原子操作的类库对你应用程序性能的影响时，这是一个非常重要的不同点。</p> 
  </div> 
  <div class="paragraph"> 
   <p>无锁算法允许其他线程继续执行有用的工作，尽管有一个线程正在忙等。换句话说，至少有一个线程是可以继续执行的。CAS循环是一个非常好的无锁算法例子，因为循环的过程中如果有一些交换尝试失败了，一定是因为另一个线程成功修改了共享数据。尽管如此，无锁算法可能会在无法预知的时间内不停的忙等，尤其是有许多个线程在同时竞争同一个共享数据：更确切的说，当 <strong>竞争</strong> 非常激烈的时候。极端情况下，一个无锁算法的CPU资源效率可能远远不及让阻塞线程休眠的互斥锁。</p> 
  </div> 
  <div class="paragraph"> 
   <p>相比之下，在无等待算法中（无锁算法的子集），任何线程都能够在有限的步骤内完成工作，无论执行速度是怎样的，或者其他线程的工作负载水平是怎样的。本文中基于 <em>fetch-and-add</em> 操作的第一个代码片段就是一个无等待算法实例：没有循环，没有重试，就是干净的业务流。还有，无等待算法是 <strong>容错的</strong>：任何其他线程的失败，或者执行速度的波动都不会使当前线程结束不了工作。这些特性使得无等待算法非常适合复杂的 <a href="https://en.wikipedia.org/wiki/Real-time_computing">实时系统</a>，因为这里并发代码的行为可预知是必要的。</p> 
  </div> 
  <div class="imageblock"> 
   <div class="content"> 
    <img src="https://www.reploop.org/blog/2020/02/images/lock-free-wait-free.png" alt="Lock-free" width="wait-free"> 
   </div> 
   <div class="title">
    Figure 3. 无等待算法是无锁算法的子集
   </div> 
  </div> 
  <div class="paragraph"> 
   <p>无等待是并发代码非常需要的，但是很难获得的特性。总而言之，无论你正在构建一个阻塞的，无锁的还是无等待的算法，黄金法则是你一定要做基准测试并且衡量测试结果。有时候旧时的互斥锁比时髦的同步原语性能要好，尤其是并发任务的复杂度非常高的时候。</p> 
  </div> 
 </div> 
</div> 
<div class="sect1"> 
 <h2 id="写到最后">写到最后</h2> 
 <div class="sectionbody"> 
  <div class="paragraph"> 
   <p>原子操作是无锁编码的必要组成，甚至在单处理器的机器上也是。没有原子性，一个线程可能在事务中途被中断，可能会导致不一致的数据状态。本文中，我仅仅是浅尝辄止：一旦你把多核/多线程考虑进去，就打开了新世界。<strong>顺序一致性</strong> 和 <strong>内存屏障</strong> 是非常关键的部分，如果要充分利用无锁算法，就不应该被忽视。我将在下一文章中讨论这些主题。</p> 
  </div> 
 </div> 
</div> 
<div class="sect1"> 
 <h2 id="参考">参考</h2> 
 <div class="sectionbody"> 
  <div class="ulist"> 
   <ul> 
    <li> <p>Preshing on Programming - <a href="https://preshing.com/20120612/an-introduction-to-lock-free-programming/">An Introduction to Lock-Free Programming</a></p> </li> 
    <li> <p>Preshing on Programming - <a href="https://preshing.com/20130618/atomic-vs-non-atomic-operations/">Atomic vs. Non-Atomic Operations</a></p> </li> 
    <li> <p>Preshing on Programming - <a href="https://preshing.com/20150402/you-can-do-any-kind-of-atomic-read-modify-write-operation/">You Can Do Any Kind of Atomic Read-Modify-Write Operation</a></p> </li> 
    <li> <p>StackOverflow - <a href="https://stackoverflow.com/questions/1525189/do-i-need-a-mutex-for-reading">Do I need a mutex for reading?</a></p> </li> 
    <li> <p>StackOverflow - <a href="https://stackoverflow.com/questions/39795265/will-atomic-operations-block-other-threads">Will atomic operations block other threads?</a></p> </li> 
    <li> <p>StackOverflow - <a href="https://stackoverflow.com/questions/38124337/spinlock-vs-busy-wait">Spinlock vs Busy wait</a></p> </li> 
    <li> <p>GCC Wiki - <a href="https://gcc.gnu.org/wiki/Atomic/GCCMM/AtomicTypes">Atomics</a></p> </li> 
    <li> <p>GCC Wiki - <a href="https://gcc.gnu.org/wiki/Atomic/GCCMM/AtomicSync">Memory model synchronization modes</a></p> </li> 
    <li> <p>Threading Building Blocks - <a href="https://www.threadingbuildingblocks.org/docs/help/tbb_userguide/Atomic_Operations.html">Atomic Operations</a></p> </li> 
    <li> <p>Just Software Solutions - <a href="https://www.justsoftwaresolutions.co.uk/threading/non_blocking_lock_free_and_wait_free.html">Definitions of Non-blocking, Lock-free and Wait-free</a></p> </li> 
    <li> <p>Wikipedia - <a href="https://en.wikipedia.org/wiki/Compare-and-swap">Compare-and-swap</a></p> </li> 
    <li> <p>Wikipedia - <a href="https://en.wikipedia.org/wiki/Read%E2%80%93modify%E2%80%93write">Read-modify-write</a></p> </li> 
    <li> <p>Wikipedia - <a href="https://en.wikipedia.org/wiki/Test-and-set">Test-and-set</a></p> </li> 
    <li> <p>Tyler Neely - <a href="https://medium.com/@tylerneely/fear-and-loathing-in-lock-free-programming-7158b1cdd50c">Fear and Loathing in Lock-Free Programming</a></p> </li> 
    <li> <p>Jason Gregory - <a href="https://www.ebooks.com/en-us/95912264/game-engine-architecture-third-edition/jason-gregory/">Game Engine Architecture, Third Edition</a></p> </li> 
    <li> <p>AA.VV. - <a href="https://spcl.inf.ethz.ch/Publications/.pdf/atomic-bench.pdf">Evaluating the Cost of Atomic Operations on Modern Architectures</a></p> </li> 
    <li> <p>Herb Sutter, CppCon 2014 - <a href="https://www.youtube.com/watch?v=c1gO9aB9nbs">Lock-Free Programming (or, Juggling Razor Blades), Part 1</a></p> </li> 
    <li> <p>Herb Sutter, CppCon 2014 - <a href="http://www.youtube.com/watch?v=CmxkPChOcvw">Lock-Free Programming (or, Juggling Razor Blades), Part 2</a></p> </li> 
    <li> <p>Maurice Herlihy - <a href="https://cs.brown.edu/~mph/Herlihy91/p124-herlihy.pdf">Wait-free synchronization</a></p> </li> 
    <li> <p>Fedor Pikus, CppCon 2014 - <a href="https://www.youtube.com/watch?v=rxQ5K9lo034">Read, Copy, Update, then what? RCU for non-kernel programmers</a></p> </li> 
    <li> <p>1024cores - <a href="http://www.1024cores.net/home/lock-free-algorithms">Lockfree Algorithms</a></p> </li> 
    <li> <p>Microsoft - <a href="https://docs.microsoft.com/en-us/windows/win32/dxtecharts/lockless-programming">Lockless Programming Considerations for Xbox 360 and Microsoft Windows</a></p> </li> 
    <li> <p>Brian Goetz, IBM - <a href="https://www.ibm.com/developerworks/java/library/j-jtp11234/">Going Atomic</a></p> </li> 
   </ul> 
  </div> 
  <div class="paragraph"> 
   <p>本文译自https://www.internalpointers.com/post/lock-free-multithreading-atomic-operations，英文读者可直接阅读原文。</p> 
  </div> 
 </div> 
</div></p>

	<hr />
	
	<p><a href="../archive.html">点击查看更多文章</a>.</p>

		</div>
		<div id="push"></div>
    </div>
    
    <div id="footer">
      <div class="container">
        <p class="muted credit">&copy; 2020 | Mixed with <a href="http://getbootstrap.com/">Bootstrap v3.1.1</a> | Baked with <a href="http://jbake.org">JBake v2.7.0.1</a></p>
      </div>
    </div>
    
    <!-- Le javascript
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="../js/jquery-1.11.1.min.js"></script>
    <script src="../js/bootstrap.min.js"></script>
    <script src="../js/prettify.js"></script>


<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  messageStyle: "none",
  tex2jax: {
    inlineMath: [["\\(", "\\)"]],
    displayMath: [["\\[", "\\]"]],
    ignoreClass: "nostem|nolatexmath"
  },
  asciimath2jax: {
    delimiters: [["\\$", "\\$"]],
    ignoreClass: "nostem|noasciimath"
  },
  TeX: { equationNumbers: { autoNumber: "none" } }
})
MathJax.Hub.Register.StartupHook("AsciiMath Jax Ready", function () {
  MathJax.InputJax.AsciiMath.postfilterHooks.Add(function (data, node) {
    if ((node = data.script.parentNode) && (node = node.parentNode) && node.classList.contains('stemblock')) {
      data.math.root.display = "block"
    }
    return data
  })
})
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_HTMLorMML"></script>
  </body>
</html>