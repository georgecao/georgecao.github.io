<!DOCTYPE html>
<html lang="zh_CN">
<head>
    <meta charset="utf-8"/>
    <title>REPLoop</title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="author" content="乔治">
    <meta name="keywords"
          content="REPL,REPLoop,George,乔治">
    <meta name="generator" content="JBake v2.7.0.8">
    <meta property=og:locale content=zh_CN>
    <meta property="og:title"
          content="REPLoop"/>
    <meta property="og:type" content="article"/>
    <meta property="og:image" content="../img/favicon.svg"/>
    <!-- Le styles -->
    <link href="../css/bootstrap.min.css" rel="stylesheet">
    <link href="../css/asciidoctor.css" rel="stylesheet">
    <link href="../css/base.css" rel="stylesheet">
    <link href="../css/prettify.css" rel="stylesheet">

    <!-- HTML5 shim, for IE6-8 support of HTML5 elements -->
    <!--[if lt IE 9]>
    <script src="../js/html5shiv.min.js"></script>
    <![endif]-->

    <!-- Fav and touch icons -->
    <!--<link rel="apple-touch-icon-precomposed" sizes="144x144" href="../assets/ico/apple-touch-icon-144-precomposed.png">
    <link rel="apple-touch-icon-precomposed" sizes="114x114" href="../assets/ico/apple-touch-icon-114-precomposed.png">
    <link rel="apple-touch-icon-precomposed" sizes="72x72" href="../assets/ico/apple-touch-icon-72-precomposed.png">
    <link rel="apple-touch-icon-precomposed" href="../assets/ico/apple-touch-icon-57-precomposed.png">-->
    <link rel="shortcut icon" href="../img/favicon.svg">
    <script data-ad-client="ca-pub-2350040335860411" async
            src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
</head>
<body onload="prettyPrint()">
    <div id="wrap">	
	<!-- Fixed navbar -->
    <div class="navbar navbar-default navbar-fixed-top" role="navigation">
      <div class="container">
        <div class="navbar-header">
          <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </button>
          <a class="navbar-brand" href="../">REPLoop</a>
        </div>
        <div class="navbar-collapse collapse">
          <ul class="nav navbar-nav">
            <li><a href="../index.html">博客</a></li>
            <li><a href="../archive.html">归档</a></li>
            <li><a href="../tags/index.html">标签</a></li>
            <li><a href="../about.html">关于</a></li>
            <li><a href="../feed.xml">订阅</a></li>
          </ul>
        </div><!--/.nav-collapse -->
      </div>
    </div>
    <div class="container">
  		<a href="blog/2020/02/lock-free-multithreading-with-atomic-operations.html"><h1>用原子操作实现无锁多线程：底层线程同步</h1></a>
  		<p>
			<a href="/about.html"><strong>George Cao</strong></a>于2020年02月27日
					<span class="badge badge-dark">原子指令</span>
					<span class="badge badge-dark">多线程</span>
					<span class="badge badge-dark">无锁</span>
					<span class="badge badge-dark">无等待</span>
					<span class="badge badge-dark">并发</span>
					<span class="badge badge-dark">算法</span>
		</p>
  		<p><div id="preamble"> 
 <div class="sectionbody"> 
  <div class="paragraph"> 
   <p>本文英文版经<span class="underline"><a href="https://it.linkedin.com/in/federicarinaldi">Federica Rinaldi</a></span>仔细审阅过，谢谢。</p> 
  </div> 
  <div class="paragraph"> 
   <p>"atom"在希腊语中拾不可再分割的意思。在计算机中一个任务被称为原子的是指他不能再细分了：它不能再拆分为更小的执行步骤了。</p> 
  </div> 
  <div class="paragraph"> 
   <p><em>原子性</em> 是多线程操作的一个重要特征：因为原子操作是不可在细分的，所以一个线程是不可能干扰另一个正在并发执行原子操作的线程的。例如，当一个线程原子写入共享数据，其他线程是没有办法读取到未完成的数据。相反的，当一个线程原子读取共享数据，这个数据就像是单个时间点上的数据。换句话说，就是没有<a href="https://www.reploop.org/blog/2020/02/a-gentle-introduction-to-multithreading.html">数据竞争</a>的风险。</p> 
  </div> 
  <div class="ulist"> 
   <div class="title">
    本系列中的其他文章
   </div> 
   <ul> 
    <li> <p><a href="https://www.reploop.org/blog/2020/02/a-gentle-introduction-to-multithreading.html">多线程简介</a> - 一步一步走进并发的世界</p> </li> 
    <li> <p><a href="https://www.reploop.org/blog/2020/02/introduction-to-thread-synchronization.html">线程同步简介</a> - 多线程应用中最常见的并发控制方法之一</p> </li> 
    <li> <p><a href="https://www.reploop.org/blog/2020/02/understanding-memory-reordering.html">理解内存重排序</a> - 为什写无锁多线程代码时它很重要</p> </li> 
   </ul> 
  </div> 
  <div class="paragraph"> 
   <p>在<a href="https://www.reploop.org/blog/2020/02/introduction-to-thread-synchronization.html">上一篇文章</a>中，我介绍了所谓的<strong>同步原语</strong>，也就是最常用的线程同步工具。他们是用来为多线程间处理共享数据的操作提供原子性的。怎么做到的呢？其实就是直接让单个线程执行并发任务，同时操作系统阻塞了其他线程直到第一个线程完成它的工作。这么做的原因是一个被阻塞的线程对其他线程是无害的。考虑到阻塞线程的能力，同步原语也称为<strong>阻塞机制</strong>。</p> 
  </div> 
  <div class="paragraph"> 
   <p>上一篇文章中的任意一种阻塞机制对大多数应用来说能够很好的工作。如果能够正确的使用，他们也是快速的和可靠的。尽管如此，他们还是有一些你可能需要考虑的缺点：</p> 
  </div> 
  <div class="olist arabic"> 
   <ol class="arabic"> 
    <li> <p>他们会阻塞其他线程 - 休眠的线程什么也不做，单纯的等待唤醒信号：这可能会浪费宝贵的时间；</p> </li> 
    <li> <p>他们会卡死你的应用 - 如果一个持有同步原语锁的线程不管什么原因崩溃了，这个锁就永远不会释放了，等待这个锁的线程就永远卡住了；</p> </li> 
    <li> <p>你对休眠哪个线程没什么控制 - 通常是操作系统选择阻塞哪个线程。这会引发一个被称之为<strong>优先级反转</strong>的不幸结果： 一个执行非常重要任务的高优先级线程被一个低优先级线程阻塞了。</p> </li> 
   </ol> 
  </div> 
  <div class="paragraph"> 
   <p>大多数时候你不会关注这些问题，因为他们不影响你应用程序的正确性。另一方面，有时候使线程一直运行是有必要的，特别是你想发挥多处理器/多核硬件的能力，或者你就是不能容忍系统被一个崩溃的线程拖死，或者优先级反转的问题是不容忽视的。</p> 
  </div> 
 </div> 
</div> 
<div class="sect1"> 
 <h2 id="无锁编程来救场">无锁编程来救场</h2> 
 <div class="sectionbody"> 
  <div class="paragraph"> 
   <p>好消息：还有另一种控制多线程应用中并发任务的方法，为了避免上面提到的1）,2）和3）点问题，称之为<strong>无锁编程</strong>，这是一种不用加锁和解锁就可以安全的在多线程之间共享变化数据的技术。</p> 
  </div> 
  <div class="paragraph"> 
   <p>坏消息：这是非常底层的东西。比传统的同步原语比如互斥锁和信号量还底层多了：这次我们会更接近本质。尽管如此，我发现无锁编程是一个很好的思想挑战，也是一个非常好的更好理解计算机如何工作的机会。</p> 
  </div> 
  <div class="paragraph"> 
   <p>无锁编程依赖<strong>原子指令</strong>，这是CPU直接执行的原子操作。原子指令作为无锁编程的基础，我将在本文剩下的部分首先介绍，然后展示如何利用它做并发控制。</p> 
  </div> 
 </div> 
</div> 
<div class="sect1"> 
 <h2 id="什么是原子指令">什么是原子指令？</h2> 
 <div class="sectionbody"> 
  <div class="paragraph"> 
   <p>思考计算中执行的任何操作，比如在屏幕上展示一张图片。这个操作是由许多更小的操作构成的：将文件读入内存，解压缩图片，点亮屏幕上的像素等等。如果你不停的细分这些更小的操作，也就是分为更小更小的操作，你最终会不能在分了。此时得到的处理器执行的肉眼可见的最小操作称之为<strong>机器指令</strong>，也就是硬件可直接执行的命令。</p> 
  </div> 
  <div class="imageblock"> 
   <div class="content"> 
    <img src="https://www.reploop.org/blog/2020/02/images/software-hardware-layers.png" alt="Software - hardware layers"> 
   </div> 
   <div class="title">
    Figure 1. 计算机程序的不同层次。虚线代表软件层次，实线代表硬件层次。
   </div> 
  </div> 
  <div class="paragraph"> 
   <p>取决于不同的CPU架构，一些机器指令是原子的，也就是单个的，不能切分的，不会被中断的。一些其他的指令则不是原子的：处理器私底下以更小的操作的方式做了更多的工作，这些操作称之为<strong><a href="https://en.wikipedia.org/wiki/Micro-operation">微指令</a></strong>。让我们给出更正式的分类：原子指令是不能在细分的CPU指令。更确切的说，原子指令可以被归为2个主要类型：<strong>存储与加载</strong> 和<strong>读取-修改-写入（RMW）</strong>。</p> 
  </div> 
  <div class="sect2"> 
   <h3 id="存储与加载原子指令">存储与加载原子指令</h3> 
   <div class="paragraph"> 
    <p>存储和加载是处理器都需要的：用来写入（<strong>存储</strong>）和读取（<strong>加载</strong>）内存数据。在某些情况下，许多CPU架构保证这些操作是天然原子的。例如，实现了<span class="underline"><a href="https://en.wikipedia.org/wiki/X86">x86架构</a></span>的处理器使用<strong>MOV</strong>指令从内存中读取数据并交给CPU。这个操作如果处理的是<span class="underline"><a href="https://www.ibm.com/support/knowledgecenter/en/SSUFAU_1.0.0/com.ibm.ent.pl1.zos.doc/lr/alnmnt.html">对齐</a></span>的数据就能保证是原子的，对齐的数据是指能让CPU一次性读取出来的方式存储的数据。</p> 
   </div> 
  </div> 
  <div class="sect2"> 
   <h3 id="读取_修改_写入rmw原子指令">读取-修改-写入(RMW)原子指令</h3> 
   <div class="paragraph"> 
    <p>一些更复杂的操作不能够单独用一些简单存储和加载指令来完成。例如，增加存储中的数值需要至少3个原子的加载和存储指令，这就使的增加内存中数值这个操作不是原子的。<strong>读取-修改-写入（RMW）</strong> 指令可以做到这个，也就有了通过一个原子操作完成多个操作的能力。除了RMW，还有非常多此类的指令。一些CPU架构全部提供，一些则提供一部分，下面列举一些：</p> 
   </div> 
   <div class="ulist"> 
    <ul> 
     <li> <p><a href="https://en.wikipedia.org/wiki/Test-and-set">测试并设置</a> - 一个原子操作完成往内存中写入1并且返回赋值之前的值；</p> </li> 
     <li> <p><a href="https://en.wikipedia.org/wiki/Fetch-and-add">获取并增加</a> - 一个原子操作完成增加内存中的数值并且返回增加之前的值；</p> </li> 
     <li> <p><a href="https://en.wikipedia.org/wiki/Compare-and-swap">比较并交换（CAS）</a> - 比较内存中的数据和提供的数据，如果他们是相同的，将提供的另一个数据写入该内存中。</p> </li> 
    </ul> 
   </div> 
   <div class="paragraph"> 
    <p>以上这些操作都是一个原子操作完成多个操作。这是一个非常重要的特性，使得读取-修改-写入指令适合无锁多线程操作。我们很快就会看到为什么适合了。</p> 
   </div> 
  </div> 
 </div> 
</div> 
<div class="sect1"> 
 <h2 id="原子指令的三个层次">原子指令的三个层次</h2> 
 <div class="sectionbody"> 
  <div class="paragraph"> 
   <p>以上所有这些指令都属于硬件层面的：他们直接和CPU交互。这种工作方式是非常困难并且不可移植，因为一些指令可能在不同得架构下叫不同得名字，一些指令在不同的处理器模型上则根本不存在！因此，你也不太可能用到这些，除非你在针对特定得机器写非常底层得代码。</p> 
  </div> 
  <div class="paragraph"> 
   <p>上到软件层面，许多操作系统提供了各自的原子指令。姑且称之为<strong>原子操作(atomic operations)</strong>，因为我们正在抽象出物理机器指令对应得原子操作。 例如， Windows系统上可能会用到<span class="underline"><a href="https://docs.microsoft.com/en-us/windows/desktop/sync/interlocked-variable-access">Interlocked API</a></span>，这是一组原子方式处理变量得函数。 MacOS则用<span class="underline"><a href="https://developer.apple.com/documentation/kernel/osatomic_h?language=objc">OSAtomc.h</a></span>头文件提供的函数做同样的事情。他们肯定是隐藏了硬件的具体实现，但是你还是受限于他们特定的环境。</p> 
  </div> 
  <div class="paragraph"> 
   <p>实现可移植原子操作的最好办法是使用你所选择的编程语言提供的原子操作。比如Java语言中有<strong>java.util.concurrent.atomic</strong>包；C++提供了<strong>std::atomic</strong>头文件； Haskell有<strong>Data.Atomics</strong>包等等。一般来讲，如果一个编程语言能处理多线程，那就很有可能会提供原子操作的支持。这样的话就是编译器（如果是编译语言）或者虚拟机（如果是解析语言）负责从底层操作系统API或者硬件中找到最合适的指令来实现原子操作。</p> 
  </div> 
  <div class="imageblock"> 
   <div class="content"> 
    <img src="https://www.reploop.org/blog/2020/02/images/atomics-levels.png" alt="Three levels of atomic instructions"> 
   </div> 
   <div class="title">
    Figure 2. 原子指令和操作的层级。虚线代表软件层次，实线代表硬件层次。
   </div> 
  </div> 
  <div class="paragraph"> 
   <p>例如，C++ 的编译器GCC通常是直接将 C++语言的原子操作和对象对应到机器指令。如果不能直接映射到硬件上，它也会利用其他可用的原子操作来实现特定操作。最坏情况下，在一个不提供原子操作的平台上，它可能利用其他阻塞策略来实现了，当然了这肯定不是无锁的实现。</p> 
  </div> 
 </div> 
</div> 
<div class="sect1"> 
 <h2 id="在多线程中使用原子操作">在多线程中使用原子操作</h2> 
 <div class="sectionbody"> 
  <div class="paragraph"> 
   <p>我们现在看看原子操作是如何使用的。 考虑增加一个简单的变量，这本来就不是原子操作，因为此操作由3个不同的步骤构成：读取数值，给数值加1，将结果写回。 一般来说，你可能会使用互斥锁来正确实现这个操作（伪代码）：</p> 
  </div> 
  <div class="listingblock"> 
   <div class="content"> 
    <pre class="highlight"><code class="language-c" data-lang="c">mutex = initialize_mutex()
x     = 0

reader_thread()
    mutex.lock()
    print(x)
    mutex.unlock()

writer_thread()
    mutex.lock()
    x++
    mutex.unlock()</code></pre> 
   </div> 
  </div> 
  <div class="paragraph"> 
   <p>首先获得互斥锁的线程会继续执行，而其他线程则等待第一个线程执行完毕。</p> 
  </div> 
  <div class="paragraph"> 
   <p>相反的，无锁方案使用了不同的模式：通过原子操作，线程可以随意执行而不用阻塞，例如：</p> 
  </div> 
  <div class="listingblock"> 
   <div class="content"> 
    <pre class="highlight"><code class="language-c" data-lang="c">x = 0

reader_thread()
    print(load(x))

writer_thread()
    fetch_and_add(x, 1)</code></pre> 
   </div> 
  </div> 
  <div class="paragraph"> 
   <p>我假设了<code>fetch_and_add()</code>和<code>load()</code>是基于相应的硬件指令的原子操作。 你可能已经发现了，这里并没有使用锁。 并发调用这些函数的多个线程都可以继续执行。<code>load()</code> 函数的原子性将保证不会有读线程读取到未完成修改的数据，同时因为<code>fetch_and_add()</code>的原子性，也不会有写线程能够部分修改数据。</p> 
  </div> 
  <div class="sect2"> 
   <h3 id="现实世界中的原子操作">现实世界中的原子操作</h3> 
   <div class="paragraph"> 
    <p>现在，上面这个例子显示了原子操作的一个重要特性：他们仅针对原子类型，如boolean型，字符串，整数等。但是真的程序是需要使用同步技术来实现更复杂的数据结构，比如数组，向量，对象，数据向量，对象里包含数据等等。如何用基于原子类型的简单操作来保证复杂数据的原子性？</p> 
   </div> 
   <div class="paragraph"> 
    <p>无锁编程迫使你跳出常规的同步原语来思考问题。你不直接用原子操作保护共享资源，而是用互斥锁或者信号量。同样的，你会基于原子操作构建<strong>无锁算法</strong>或者<strong>无锁数据结构</strong>来确定多个线程如何访问你的数据。</p> 
   </div> 
   <div class="paragraph"> 
    <p>例如，上面看到的<em>fetch-and-add</em>操作可以用来实现一个基本的信号量，而这个信号量就可以用来协调多个线程。毫无意外，所有传统的阻塞同步工具都是基于原子操作的实现的。</p> 
   </div> 
   <div class="paragraph"> 
    <p>人们写了很多个无锁数据结构，比如Folly的<span class="underline"><a href="https://github.com/facebook/folly/blob/master/folly/AtomicHashMap.h">AtomicHashMap</a></span>， <a href="https://www.boost.org/doc/libs/1_70_0/doc/html/lockfree.html">Boost.Lockfree类库</a>，多生产者/多消费者， <a href="https://github.com/cameron314/concurrentqueue">先进先出队列</a>(FIFO)，或者诸如<span class="underline"><a href="https://www.youtube.com/watch?v=rxQ5K9lo034">读取-复制-更新（RCU）</a></span>和<span class="underline"><a href="https://en.wikipedia.org/wiki/Shadow_paging">影子分页</a></span>(Shadow Paging)等一些算法。从头开始写这些原子工具很困难，更不用说让他们正确工作。这也是大多数时候你可能会使用已经存在的，实战检验过得算法与数据结构，而不是使用自己实现的。</p> 
   </div> 
  </div> 
  <div class="sect2"> 
   <h3 id="比较并交换cas循环">比较并交换(CAS)循环</h3> 
   <div class="paragraph"> 
    <p>具体到实际应用，<strong>比较并交换循环</strong>(<strong>CAS loop</strong>)可能是无锁编程中最常用的技巧，无论你是使用现成的数据结构或者从头开始实现算法。这是基于对应的<em>比较并交换</em>原子操作（CAS）而且有一个很好的特点：他能支持多个写线程。这是用到复杂系统中的并发算法的一个重要特征。</p> 
   </div> 
   <div class="paragraph"> 
    <p>CAS循环非常有趣是因为他在无锁代码中引入了重复模式，同时引入了用于推理的理论概念。我们进一步看一下。</p> 
   </div> 
  </div> 
  <div class="sect2"> 
   <h3 id="cas循环实现">CAS循环实现</h3> 
   <div class="paragraph"> 
    <p>操作系统或者编程语言提供的CAS函数可能是这样的：</p> 
   </div> 
   <div class="listingblock"> 
    <div class="content"> 
     <pre class="highlight"><code class="language-c" data-lang="c">boolean compare_and_swap(shared_data, expected_value, new_value);</code></pre> 
    </div> 
   </div> 
   <div class="paragraph"> 
    <p>他的入参有共享数据的引用/指针，预期共享数据当前的值以及将要赋值的新值。这个函数只有在<code>shared_date.value == expected_value</code>的情况下才会使用新数据替换原始数据，并且只有数据改变的情况下才返回<code>true</code>。</p> 
   </div> 
   <div class="paragraph"> 
    <p>CAS循环的思路是不停的尝试比较和交换，直到操作成功。每一次尝试都需要给CAS函数传递共享数据的引用/指针，预期的数据和将要赋值的数据。这是和其他并发写线程配合的必要条件：如果其他线程在同步修改数据，也就是共享数据和预期数据不再匹配了，CAS函数就会失败。这样就支持了多个写线程。</p> 
   </div> 
   <div class="paragraph"> 
    <p>假设我们用CAS来实现前面代码片段实现的<code>fetch-and-add</code>算法，实现起来可能是这样的（伪代码）：</p> 
   </div> 
   <div class="listingblock"> 
    <div class="content"> 
     <pre class="highlight"><code class="language-c" data-lang="c">x = 0

reader_thread()
    print(load(x))

writer_thread()
    temp = load(x)                              <i class="conum" data-value="1"></i><b>(1)</b>
    while(!compare_and_swap(x, temp, temp + 1)) <i class="conum" data-value="2"></i><b>(2)</b></code></pre> 
    </div> 
   </div> 
   <div class="paragraph"> 
    <p>第（1）行代码加载共享数据，然后尝试和新的数据进行交换，直到交换成功返回<code>true</code>（2）。</p> 
   </div> 
  </div> 
  <div class="sect2"> 
   <h3 id="交换范式">交换范式</h3> 
   <div class="paragraph"> 
    <p>正如前面说的，CAS循环在许多无锁算法中引入了重复模式:</p> 
   </div> 
   <div class="olist arabic"> 
    <ol class="arabic"> 
     <li> <p>创建共享数据的<em>本地副本</em>；</p> </li> 
     <li> <p>按需修改本地副本；</p> </li> 
     <li> <p>合适的时候，通过<em>交换</em>更新后的数据与之前创建的副本数据来更新共享数据。</p> </li> 
    </ol> 
   </div> 
   <div class="paragraph"> 
    <p>第3）点是关键：交换是通过原子操作来保证原子性的。本地写线程针对副本数据做了大部分的脏活累活，等到合适的时候才发布更新到共享数据。这样的话，其他线程只能看到这个共享数据的2种状态：未修改的数据和修改后的数据。由于原子交换，看不到修改过程中的中间状态，或者出错的更新。</p> 
   </div> 
   <div class="paragraph"> 
    <p>这也是哲学上不同于加锁方案的：无锁算法中，多线程仅仅在执行交换的时候才需要交互，其他时候都不被打扰的运行，也感知不到其他线程的存在。多线程之间的交互点缩小了并且被限制在执行原子操作的期间。</p> 
   </div> 
  </div> 
  <div class="sect2"> 
   <h3 id="一种轻量级加锁形式">一种轻量级加锁形式</h3> 
   <div class="paragraph"> 
    <p>上面看到的<em>循环直到成功</em>的策略在许多无锁算法中用到了，被称之为<strong>自旋锁(spinlock)</strong>：一个简单的循环，线程不停的尝试执行操作直到成功。这是一种轻量级的加锁形式，此时线程是实时活跃运行的，不会被操作系统休眠，尽管这个循环成功之前工作不会有进展。相比之下，互斥锁或者信号量中用到的常规锁代价非常高，因为一个挂起/唤醒周期需要大量的底层工作。</p> 
   </div> 
  </div> 
  <div class="sect2"> 
   <h3 id="aba问题">ABA问题</h3> 
   <div class="paragraph"> 
    <p>行（1）和（2）所示指令虽然有所不同，但不是连续的。另一个线程可能插入中间，再（1）读取完成之后修改共享数据。更确切的说，另一个线程可以将初始数据，假设为A，修改为B，然后在（2）所示的比较并交换操作执行之前再修改回A。执行CAS操作的线程不会发现数据的变化而成功执行交换操作。这就是所谓的ABA问题：有时候你可以简单的直接忽略，如果你的算法就像上面那个一样简单，而有时候你就需要避免此问题，因为这会给你的应用程序引入非常难以发现的问题。幸运的是有<span class="underline"><a href="https://en.wikipedia.org/wiki/Compare-and-swap#ABA_problem">几种方式</a></span> 可以绕过这个问题。</p> 
   </div> 
  </div> 
  <div class="sect2"> 
   <h3 id="cas循环可以交换任意的事情">CAS循环可以交换任意的事情</h3> 
   <div class="paragraph"> 
    <p>CAS循环经常用来交换指针，这也是<em>比较并交换</em>操作支持的类型之一。当你需要修改复杂的诸如对象或者数组的数据集的时候非常有用：创建本地数据副本，按需修改这个副本，合适的时候交换本地副本数据和全局共享数据的指针。这样的话全局共享数据就指向了本地副本数据在内存中指针，其他线程就会看到更新后的最新数据。</p> 
   </div> 
   <div class="paragraph"> 
    <p>这个技术允许你同步非基本数据实体(primitive entities)，尽管要做到这个也有一定的难度。比如交换完成之后，一个读线程还在读取老的指针？如何安全的删除之前的数据副本而不引起非常危险的野指针问题？工程师们再一次的找到了很多解决方案，比如使用支持内存自动<span class="underline"><a href="https://en.wikipedia.org/wiki/Garbage_collection_(computer_science)">垃圾回收</a></span>的语言，或者一些深奥的技术如<span class="underline"><a href="https://aturon.github.io/blog/2015/08/27/epoch/">分代内存回收</a></span>， <a href="https://en.wikipedia.org/wiki/Hazard_pointer">冒险指针</a>或者<span class="underline"><a href="https://en.wikipedia.org/wiki/Reference_counting">引用计数</a></span>。</p> 
   </div> 
  </div> 
 </div> 
</div> 
<div class="sect1"> 
 <h2 id="无锁和无等待">无锁和无等待</h2> 
 <div class="sectionbody"> 
  <div class="paragraph"> 
   <p>每个基于原子操作的算法或者数据结构都可以归为2类：<strong>无锁的</strong> 或者<strong>无等待的</strong>。当你要评估基于原子操作的类库对你应用程序性能的影响时，这是一个非常重要的不同点。</p> 
  </div> 
  <div class="paragraph"> 
   <p>无锁算法允许其他线程继续执行有用的工作，尽管有一个线程正在忙等。换句话说，至少有一个线程是可以继续执行的。CAS循环是一个非常好的无锁算法例子，因为循环的过程中如果有一些交换尝试失败了，一定是因为另一个线程成功修改了共享数据。尽管如此，无锁算法可能会在无法预知的时间内不停的忙等，尤其是有许多个线程在同时竞争同一个共享数据：更确切的说，当<strong>竞争</strong>非常激烈的时候。极端情况下，一个无锁算法的CPU资源效率可能远远不及让线程阻塞休眠的互斥锁。</p> 
  </div> 
  <div class="paragraph"> 
   <p>相比之下，在无等待算法中（无锁算法的子集），任何线程都能够在有限的步骤内完成工作，无论执行速度是怎样的，或者其他线程的工作负载水平是怎样的。本文中基于<em>fetch-and-add</em>操作的第一个代码片段就是一个无等待算法实例：没有循环，没有重试，就是干净的业务流。还有，无等待算法是<strong>容错的</strong>：任何其他线程的失败，或者执行速度的波动都不会使当前线程结束不了工作。这些特性使得无等待算法非常适合复杂的<span class="underline"><a href="https://en.wikipedia.org/wiki/Real-time_computing">实时系统</a></span>，因为这里并发代码的行为可预知是必要的。</p> 
  </div> 
  <div class="imageblock"> 
   <div class="content"> 
    <img src="https://www.reploop.org/blog/2020/02/images/lock-free-wait-free.png" alt="Lock-free" width="wait-free"> 
   </div> 
   <div class="title">
    Figure 3. 无等待算法是无锁算法的子集
   </div> 
  </div> 
  <div class="paragraph"> 
   <p>无等待是并发代码非常需要的，但也是很难获得的特性。总而言之，无论你正在构建一个阻塞的，无锁的还是无等待的算法，黄金法则是你一定要做基准测试并且衡量测试结果。有时候旧时的互斥锁比时髦的同步原语性能要好，尤其是并发任务的复杂度非常高的时候。</p> 
  </div> 
 </div> 
</div> 
<div class="sect1"> 
 <h2 id="写到最后">写到最后</h2> 
 <div class="sectionbody"> 
  <div class="paragraph"> 
   <p>原子操作是无锁编码的必要组成，甚至在单处理器的机器上也是。没有原子性，一个线程可能在事务中途被中断，可能会导致不一致的数据状态。本文中，我仅仅是浅尝辄止：一旦你把多核/多线程考虑进去，就打开了新世界。<strong>顺序一致性</strong> 和<strong>内存屏障</strong>是非常关键的部分，如果要充分利用无锁算法，就不应该被忽视。我将在下一文章中讨论这些主题。</p> 
  </div> 
 </div> 
</div> 
<div class="sect1"> 
 <h2 id="参考">参考</h2> 
 <div class="sectionbody"> 
  <div class="ulist"> 
   <ul> 
    <li> <p>Preshing on Programming - <a href="https://preshing.com/20120612/an-introduction-to-lock-free-programming/">An Introduction to Lock-Free Programming</a></p> </li> 
    <li> <p>Preshing on Programming - <a href="https://preshing.com/20130618/atomic-vs-non-atomic-operations/">Atomic vs. Non-Atomic Operations</a></p> </li> 
    <li> <p>Preshing on Programming - <a href="https://preshing.com/20150402/you-can-do-any-kind-of-atomic-read-modify-write-operation/">You Can Do Any Kind of Atomic Read-Modify-Write Operation</a></p> </li> 
    <li> <p>StackOverflow - <a href="https://stackoverflow.com/questions/1525189/do-i-need-a-mutex-for-reading">Do I need a mutex for reading?</a></p> </li> 
    <li> <p>StackOverflow - <a href="https://stackoverflow.com/questions/39795265/will-atomic-operations-block-other-threads">Will atomic operations block other threads?</a></p> </li> 
    <li> <p>StackOverflow - <a href="https://stackoverflow.com/questions/38124337/spinlock-vs-busy-wait">Spinlock vs Busy wait</a></p> </li> 
    <li> <p>GCC Wiki - <a href="https://gcc.gnu.org/wiki/Atomic/GCCMM/AtomicTypes">Atomics</a></p> </li> 
    <li> <p>GCC Wiki - <a href="https://gcc.gnu.org/wiki/Atomic/GCCMM/AtomicSync">Memory model synchronization modes</a></p> </li> 
    <li> <p>Threading Building Blocks - <a href="https://www.threadingbuildingblocks.org/docs/help/tbb_userguide/Atomic_Operations.html">Atomic Operations</a></p> </li> 
    <li> <p>Just Software Solutions - <a href="https://www.justsoftwaresolutions.co.uk/threading/non_blocking_lock_free_and_wait_free.html">Definitions of Non-blocking, Lock-free and Wait-free</a></p> </li> 
    <li> <p>Wikipedia - <a href="https://en.wikipedia.org/wiki/Compare-and-swap">Compare-and-swap</a></p> </li> 
    <li> <p>Wikipedia - <a href="https://en.wikipedia.org/wiki/Read%E2%80%93modify%E2%80%93write">Read-modify-write</a></p> </li> 
    <li> <p>Wikipedia - <a href="https://en.wikipedia.org/wiki/Test-and-set">Test-and-set</a></p> </li> 
    <li> <p>Tyler Neely - <a href="https://medium.com/@tylerneely/fear-and-loathing-in-lock-free-programming-7158b1cdd50c">Fear and Loathing in Lock-Free Programming</a></p> </li> 
    <li> <p>Jason Gregory - <a href="https://www.ebooks.com/en-us/95912264/game-engine-architecture-third-edition/jason-gregory/">Game Engine Architecture, Third Edition</a></p> </li> 
    <li> <p>AA.VV. - <a href="https://spcl.inf.ethz.ch/Publications/.pdf/atomic-bench.pdf">Evaluating the Cost of Atomic Operations on Modern Architectures</a></p> </li> 
    <li> <p>Herb Sutter, CppCon 2014 - <a href="https://www.youtube.com/watch?v=c1gO9aB9nbs">Lock-Free Programming (or, Juggling Razor Blades), Part 1</a></p> </li> 
    <li> <p>Herb Sutter, CppCon 2014 - <a href="http://www.youtube.com/watch?v=CmxkPChOcvw">Lock-Free Programming (or, Juggling Razor Blades), Part 2</a></p> </li> 
    <li> <p>Maurice Herlihy - <a href="https://cs.brown.edu/~mph/Herlihy91/p124-herlihy.pdf">Wait-free synchronization</a></p> </li> 
    <li> <p>Fedor Pikus, CppCon 2014 - <a href="https://www.youtube.com/watch?v=rxQ5K9lo034">Read, Copy, Update, then what? RCU for non-kernel programmers</a></p> </li> 
    <li> <p>1024cores - <a href="http://www.1024cores.net/home/lock-free-algorithms">Lockfree Algorithms</a></p> </li> 
    <li> <p>Microsoft - <a href="https://docs.microsoft.com/en-us/windows/win32/dxtecharts/lockless-programming">Lockless Programming Considerations for Xbox 360 and Microsoft Windows</a></p> </li> 
    <li> <p>Brian Goetz, IBM - <a href="https://www.ibm.com/developerworks/java/library/j-jtp11234/">Going Atomic</a></p> </li> 
   </ul> 
  </div> 
  <div class="paragraph"> 
   <p>本文译自https://www.internalpointers.com/post/lock-free-multithreading-atomic-operations，英文读者可直接阅读原文。</p> 
  </div> 
 </div> 
</div></p>
  		<a href="blog/2020/02/introduction-to-thread-synchronization.html"><h1>线程同步: 多线程应用中最常见的并发控制方法之一</h1></a>
  		<p>
			<a href="/about.html"><strong>George Cao</strong></a>于2020年02月23日
					<span class="badge badge-dark">互斥锁</span>
					<span class="badge badge-dark">信号量</span>
					<span class="badge badge-dark">同步</span>
					<span class="badge badge-dark">多线程</span>
					<span class="badge badge-dark">条件变量</span>
					<span class="badge badge-dark">线程</span>
					<span class="badge badge-dark">并发</span>
		</p>
  		<p><div id="preamble"> 
 <div class="sectionbody"> 
  <div class="paragraph"> 
   <p>本文讨论的是多线程应用中最常见的并发控制方法之一。</p> 
  </div> 
  <div class="paragraph"> 
   <p>就像我<a href="https://www.reploop.org/blog/2020/02/a-gentle-introduction-to-multithreading.html">前一篇文章</a>所阐述的，开发并发代码需要技巧的。 会遇到两个大问题：数据竞争，当一个写线程在修改内存数据的同时一个读线程正在从中读取数据和竞争条件，当2个或以上的线程以不可预知的顺序执行任务的时候会发生。幸运的是我们有一些办法来避免这类错误：这篇文章我们就来看一个最常用的办法：<strong>同步(synchronization)</strong>。</p> 
  </div> 
  <div class="ulist"> 
   <div class="title">
    本系列中的其他文章
   </div> 
   <ul> 
    <li> <p><a href="https://www.reploop.org/blog/2020/02/a-gentle-introduction-to-multithreading.html">多线程简介</a> - 一步一步走进并发的世界</p> </li> 
    <li> <p><a href="https://www.reploop.org/blog/2020/02/lock-free-multithreading-with-atomic-operations.html">用原子操作实现无锁多线程</a> - 底层线程同步</p> </li> 
    <li> <p><a href="https://www.reploop.org/blog/2020/02/understanding-memory-reordering.html">理解内存重排序</a> - 为什写无锁多线程代码时它很重要</p> </li> 
   </ul> 
  </div> 
 </div> 
</div> 
<div class="sect1"> 
 <h2 id="什么是同步">什么是同步</h2> 
 <div class="sectionbody"> 
  <div class="paragraph"> 
   <p>同步是让2个或以上线程和平共处的技巧合集。更确切的说，同步能够帮你实现多线程程序中至少2个重要的特性：</p> 
  </div> 
  <div class="olist arabic"> 
   <ol class="arabic"> 
    <li> <p><strong>原子性</strong> - 如果你的代码包含多个线程操作共享数据的指令，不受控制的并发访问共享数据可触发数据竞争。包含此类指令的代码块称为关键区块。你要确保关键区块要原子执行：如前文所定义的，一个<a href="https://www.reploop.org/blog/2020/02/a-gentle-introduction-to-multithreading.html">原子操作</a>不能在细分为更小的操作了，因此当一个线程在执行原子代码块的时候，就不会受到其他线程的干扰；</p> </li> 
    <li> <p><strong>有序性</strong> - 有时候你需要2个或以上的线程按照可预测的顺序执行任务，或者限制访问某个资源的线程数。正常情况下你是不能控制这个的，这也可能是竞争条件发生的根本原因。有了同步之后，你就可以根据计划来编排多个线程的执行了。</p> </li> 
   </ol> 
  </div> 
  <div class="paragraph"> 
   <p>同步是通过支持多线程的操作系统或者编程语言提供的<strong>同步原语(synchronization primitives)</strong>来实现的。然后你就可以在代码中使用同步原语来保证多线程不会触发数据竞争、竞争条件或者全部。</p> 
  </div> 
  <div class="paragraph"> 
   <p>同步可以发生在硬件和软件，以及线程与操作系统进程之间。 这篇文章是关于软件线程同步：对应的硬件同步部分非常有趣，将会在后续的文章中介绍。</p> 
  </div> 
 </div> 
</div> 
<div class="sect1"> 
 <h2 id="常见同步原语">常见同步原语</h2> 
 <div class="sectionbody"> 
  <div class="paragraph"> 
   <p>最重要的同步原语是互斥锁，信号量和条件变量。这些关键字还没有官方的定义，所以在不同的书本或者实现中会有轻微的不同特征。</p> 
  </div> 
  <div class="paragraph"> 
   <p>这3个同步原语是操作系统是原生支持的。例如Linux和macOS支持<strong>POSIX线程</strong>，也就是<strong>pthreads</strong>，能够让你可以用这一组函数开发安全的多线程应用。Windows则用C运行时代码库（CRT）提供自己的同步工具：概念上和POSIX多线程功能相似但是不同的命名。</p> 
  </div> 
  <div class="paragraph"> 
   <p>除非你正在写非常底层的代码，通常你只要使用编程语言提供的同步原语就可以了。每个支持多线程的编程语言都提供了自己的同步原语工具箱，以及一些额外的线程处理功能。例如Java提供了<code>java.util.concurrent</code>包，现代C++有自己的线程库，C#提供<code>System.Threading</code>命名空间等等。当然所有这些功能和对象都是基于底层操作系统同步原语的。</p> 
  </div> 
  <div class="paragraph"> 
   <p>除此之外还有其他同步工具，但是本文只关注上面提到的3个，因为他们是构建复杂系统的基础。让我们进一步分析。</p> 
  </div> 
 </div> 
</div> 
<div class="sect1"> 
 <h2 id="互斥锁">互斥锁</h2> 
 <div class="sectionbody"> 
  <div class="paragraph"> 
   <p><strong>互斥锁</strong>(<strong>mut</strong>ual<strong>ex</strong>clusion)是一个同步原语，是为了避免数据竞争而给关键区增加限制的保护机制。 互斥锁通过同时只允许一个线程访问关键区来保证<em>原子性</em>。</p> 
  </div> 
  <div class="paragraph"> 
   <p>严格来讲，互斥锁是应用中的一个全局对象，在多个线程之间共享，并且提供通常叫做<code>加锁</code>和<code>解锁</code>的2个功能函数。一个即将要进入关键区域的线程通过<code>加锁</code>操作锁定这个互斥锁，结束后，也就是关键区域结束之后，同样的线程调用<code>解锁</code>操作来释放这个互斥锁。互斥锁非常重要的特性是：只有锁定这个互斥锁的线程才能解锁。</p> 
  </div> 
  <div class="paragraph"> 
   <p>如果一个线程正在关键区，而另一个线程尝试锁定这个互斥锁，操作系统就让后面这个线程休眠，直到第一个线程任务结束并且释放了这个互斥锁。这样就只有1个线程可以访问关键区，任何其他线程都不能访问而且必须等待互斥锁的释放。基于这个原因，互斥锁也叫做锁机制。</p> 
  </div> 
  <div class="paragraph"> 
   <p>你可以用互斥锁保护比如一个共享变量的并发读和写操作，也可以保护更大、更复杂的操作，同时只允许一个线程执行的，比如写日志文件或者修改数据库。无论如何，互斥锁的加锁/解锁操作总是和关键区的边界是匹配的。</p> 
  </div> 
  <div class="paragraph"> 
   <p>互斥锁保护的是关键区域，也就是操作，而不是数据本身。如果在关键区域之外的代码也能读写数据，互斥锁就有失效的风险。所以所有对数据有读写的代码都需要作为关键区用互斥锁保护起来才能避免数据竞争。</p> 
  </div> 
  <div class="sect2"> 
   <h3 id="递归互斥锁">递归互斥锁</h3> 
   <div class="paragraph"> 
    <p>许多常规的互斥锁实现中，一个线程两次加锁同一个互斥锁会引起错误。但是<strong>递归互斥锁(recursive mutex)</strong>允许此类操作：一个线程可以锁定一个递归互斥锁许多次而不需要先释放。尽管如此，其他线程只有等到第一个线程释放所有的递归互斥锁之后才能锁定这个锁。这个同步原语也叫做<strong>可重入互斥锁(reentrant mutex)</strong>，这里的<strong>可重入性(reentrancy)</strong>是指在前一次调用结束之前可以多次调用同一个函数的能力。</p> 
   </div> 
   <div class="paragraph"> 
    <p>递归互斥锁很难用而且容易出错。你必须记录哪个线程锁定了哪个互斥锁多少次，而且要保证一个线程完全释放这个互斥锁。不然的话就会导致互斥锁没能释放而引起讨厌的后果。大多数时候正常的互斥锁就够用了。</p> 
   </div> 
  </div> 
  <div class="sect2"> 
   <h3 id="读写锁">读写锁</h3> 
   <div class="paragraph"> 
    <p>正如我们从前一篇文章中知道的，多个线程可以安全的并发读一个共享资源，只要没有线程修改该共享资源。所以如果一些线程是“只读”模式的，还有必要锁定一个互斥锁？例如一个并发数据库被多个线程频繁读取，同时另一个线程偶尔写入更新。你当然需要一个互斥锁来保护读/写访问，但是大多数情况下仅仅为了读操作而锁定一个互斥锁，也同时阻碍了其他读线程正常执行。</p> 
   </div> 
   <div class="paragraph"> 
    <p><strong>读/写互斥锁</strong> 允许多线程<em>并发</em>读和单线程<em>排他</em>写共享资源。这个互斥锁可以被锁定为<em>读模式</em>或者<em>写模式</em>。为了修改资源，一个线程必须先获得排他写入锁。排他写入锁直到所有的读取锁全部释放之后才能获取。</p> 
   </div> 
  </div> 
 </div> 
</div> 
<div class="sect1"> 
 <h2 id="信号量">信号量</h2> 
 <div class="sectionbody"> 
  <div class="paragraph"> 
   <p><strong>信号量</strong> 是用来编排线程的同步原语：那个线程先启动，多少个线程可以访问一个资源等等。就像“红绿灯”调节交通一样，程序信号量规范多线程交互流程：基于这个原因，信号量也称为<strong>信号机制</strong>。他可以被看做互斥锁的进化，因为他能同时保证<em>有序性</em>和<em>原子性</em>。尽管如此，接下来的几段中我讲告诉你为什么仅仅为了原子性而使用信号量不是一个好选择。</p> 
  </div> 
  <div class="paragraph"> 
   <p>严格来讲，信号量是应用中的全局变量，多个线程间共享，还包含了一个<em>计数器</em>，通过2个函数管理：一个增加计数器，另一个减少计数器。历史上，这两个操作分别叫做<code>P</code>操作和<code>V</code>操作，现代信号量的实现使用更友好的名字比如<code>获取</code>和<code>释放</code>。</p> 
  </div> 
  <div class="paragraph"> 
   <p>信号量控制共享资源的访问：计数器决定了并行访问共享资源的最大线程数。程序启动的时候，也就是信号量被初始化的时候，你根据自己的需要选择这个最大线程数。然后一个想访问共享资源的线程调用<code>获取</code>函数：</p> 
  </div> 
  <div class="ulist"> 
   <ul> 
    <li> <p>如果计数器<em>大于0</em>就继续进行。计数器被立即减少1，然后当前线程可以开始操作了。结束后，当前线程调用<code>释放</code>函数，同时计数器加1.</p> </li> 
    <li> <p>如果计数器<em>等于0</em>则此线程不能继续进行：其他线程已经占用了可以空间。当前线程被操作系统休眠，只有等到信号量的计数器再次大于0（也就是有线程完成任务后调用了<code>释放</code>函数）的时候才会被唤醒。</p> </li> 
   </ul> 
  </div> 
  <div class="paragraph"> 
   <p>不像互斥锁，<em>任何线程可以释放信号量</em>，不仅仅是最先获取信号量的线程。</p> 
  </div> 
  <div class="paragraph"> 
   <p>单个信号量可以用来限制同时访问共享资源的线程数：例如为了控制多线程数据库的连接数，这其中的每个线程是连接到你的服务器的用户触发的。</p> 
  </div> 
  <div class="paragraph"> 
   <p>结合多个信号量一起，你就可以解决线程的有序性问题了：比如在浏览器中渲染网页的线程必须在通过互联网下载HTML文件的线程之后启动。线程A结束的时候会通知线程B，因此线程B可以被唤醒继续执行任务：这个也常被称为著名的<span class="underline"><a href="https://en.wikipedia.org/wiki/Producer%E2%80%93consumer_problem">生产者-消费者问题</a></span>。</p> 
  </div> 
  <div class="sect2"> 
   <h3 id="二元信号量">二元信号量</h3> 
   <div class="paragraph"> 
    <p>如果信号量的计数器只允许取值0和1，则称之为<strong>二元信号量</strong>：也就是同时只允许一个线程访问共享资源。 等一下，这基本上就是互斥锁保护关键区的作用。你确实可以用二元信号量来实现互斥锁的行为。但是要时刻牢记以下2点：</p> 
   </div> 
   <div class="olist arabic"> 
    <ol class="arabic"> 
     <li> <p>互斥锁只能被加锁的线程解锁，但是信号量可以被任意线程释放。如果你仅仅需要一个锁机制的话，这会导致困惑和微妙的问题；</p> </li> 
     <li> <p>信号量是用来编排线程的信号机制，但是互斥锁是保护共享资源的锁机制。你不应改使用信号量来保护共享资源，也不应该将互斥锁用于信号机制：这样你的意图对你和你的代码读者会更明确。</p> </li> 
    </ol> 
   </div> 
  </div> 
 </div> 
</div> 
<div class="sect1"> 
 <h2 id="条件变量">条件变量</h2> 
 <div class="sectionbody"> 
  <div class="paragraph"> 
   <p>条件变量是另一个用来保证<em>有序性</em>的同步原语。他们是用来在不同线程之间发送唤醒信号的。条件变量往往配合互斥锁一起使用，单独使用条件变量没有意义。</p> 
  </div> 
  <div class="paragraph"> 
   <p>严格来讲，条件变量是应用中的全局对象，多个线程之间共享，提供3个函数，分别叫做：<code>wait</code>，<code>notify_one</code> 和<code>notify_all</code>, 外加一个传递已知互斥锁给他配合工作的机制（具体方法依实现而定）。</p> 
  </div> 
  <div class="paragraph"> 
   <p>线程调用一个条件变量的<code>wait</code>操作会被操作系统休眠。然后其他的线程想要唤醒休眠线程的话就调用<code>notify_one</code>或者<code>notify_all</code>。<code>notify_one</code> 和<code>notify_all</code>的不同之处是<code>notify_one</code>仅仅唤醒一个休眠线程，但是<code>notify_all</code>会唤醒所有因为调用了条件变量的等待操作而休眠的线程。条件变量内部使用互斥锁提供休眠/唤醒机制。</p> 
  </div> 
  <div class="paragraph"> 
   <p>条件变量是仅靠互斥锁实现不了的在线程之间发送信号的强大机制。例如你也可以使用它解决生产者-消费者问题，线程A完成任务后产生一个信号，接着线程B就可以开始执行任务了。</p> 
  </div> 
 </div> 
</div> 
<div class="sect1"> 
 <h2 id="常见的同步问题">常见的同步问题</h2> 
 <div class="sectionbody"> 
  <div class="paragraph"> 
   <p>本文所述的所有同步原语有共同之处：都会让线程休眠。基于这个原因，他们也被叫做<strong>阻塞机制</strong>。如果你想避免数据竞争或者竞争条件，阻塞机制是防止并发访问共享资源的好办法：休眠线程不会有任何害处。但是他能够触发不幸的副作用，我们来看看都有哪些。</p> 
  </div> 
  <div class="sect2"> 
   <h3 id="死锁">死锁</h3> 
   <div class="paragraph"> 
    <p><strong>死锁</strong> 发生在一个线程等待另一个线程持有的共享变量，而第二个线程在等待第一个线程持有的共享变量。这种情况通常在使用多个互斥锁的时候发生：2个线程在死循环中永久等待：线程A在等待线程B，线程B在等待线程A，而线程A又在等待线程B，如此往复。。。</p> 
   </div> 
  </div> 
  <div class="sect2"> 
   <h3 id="饥饿线程">饥饿线程</h3> 
   <div class="paragraph"> 
    <p>当线程没有得到足够的爱就进入<strong>饥饿</strong>模式：它永远卡在休眠模式等待访问共享资源，但是这个共享资源持续的给了其他线程。例如一个基于信号量的糟糕实现可能会忘记唤醒等待队列中的一些线程，这个可以通过给部分线程高优先级的方式实现。饥饿线程会永久等待而不能做任何有效的工作。</p> 
   </div> 
  </div> 
  <div class="sect2"> 
   <h3 id="无效唤醒">无效唤醒</h3> 
   <div class="paragraph"> 
    <p>这是一些操作系统中条件变量的具体实现方式带来的微妙问题。一个<strong>无效唤醒</strong>可能是线程没有收到条件变量的信号而被唤醒了。这也是多数同步原语中包含了检查唤醒信号是否真的来自线程正在等待的条件变量的方法的原因。</p> 
   </div> 
  </div> 
  <div class="sect2"> 
   <h3 id="优先级反转">优先级反转</h3> 
   <div class="paragraph"> 
    <p><strong>优先级反转</strong> 是一个执行高优先级任务的线程阻塞等待一个低优先级的线程释放资源，如互斥锁。例如输出音频到声卡的线程（高优先级）被显示界面的线程（低优先级）阻塞了，会导致扬声器严重的卡顿。</p> 
   </div> 
  </div> 
 </div> 
</div> 
<div class="sect1"> 
 <h2 id="下一步">下一步</h2> 
 <div class="sectionbody"> 
  <div class="paragraph"> 
   <p>这些同步问题被研究很多年了，也有很多技术和架构方面的解决方法。严谨的设计和一些实际经验能很大程度上预防问题的发生。鉴于多线程程序的<a href="https://www.reploop.org/blog/2020/02/a-gentle-introduction-to-multithreading.html">不确定性</a>(非常难的)性质，也有人开发出来在并发代码中检测错误和潜在缺陷的有趣工具。就像<span class="underline"><a href="https://github.com/google/sanitizers/wiki/ThreadSanitizerCppManual">Google的TSan</a></span>或者<span class="underline"><a href="http://valgrind.org/docs/manual/hg-manual.html">Helgrind</a></span>一样。</p> 
  </div> 
  <div class="paragraph"> 
   <p>尽管如此，有时候你可能在多线程应用中采用不同的方法，完全去掉阻塞机制。这意味着进入<strong>非阻塞</strong>领域：这是一个非常底层的领域，线程不会被操作系统休眠，并发是通过<strong>原子操作</strong>和<strong>无锁数据结构</strong>规范的。这是一个充满挑战的领域，并不总是有必要，但是它能够加速你的软件或者对他造成严重的破坏。不过这是下一篇文章的内容。</p> 
  </div> 
 </div> 
</div> 
<div class="sect1"> 
 <h2 id="参考">参考</h2> 
 <div class="sectionbody"> 
  <div class="ulist"> 
   <ul> 
    <li> <p>Wikipedia - <a href="https://en.wikipedia.org/wiki/Synchronization_%28computer_science%29#Thread_or_process_synchronization">Synchronization (computer science)</a></p> </li> 
    <li> <p>Wikipedia - <a href="https://en.wikipedia.org/wiki/Reentrant_mutex">Reentrant mutex</a></p> </li> 
    <li> <p>Wikipedia - <a href="https://en.wikipedia.org/wiki/Reentrancy_%28computing%29">Reentrancy (computing)</a></p> </li> 
    <li> <p>Wikipedia - <a href="https://en.wikipedia.org/wiki/Semaphore_%28programming%29">Semaphore (programming)</a></p> </li> 
    <li> <p>Wikipedia - <a href="https://en.wikipedia.org/wiki/Spurious_wakeup">Spurious Wakeup</a></p> </li> 
    <li> <p>Wikipedia - <a href="https://en.wikipedia.org/wiki/Priority_inversion">Priority inversion</a></p> </li> 
    <li> <p>Wikipedia - <a href="https://en.wikipedia.org/wiki/Deadlock">Deadlock</a></p> </li> 
    <li> <p>Wikipedia - <a href="https://en.wikipedia.org/wiki/Starvation_%28computer_science%29">Starvation (computer science)</a></p> </li> 
    <li> <p>Columbia Engineering - <a href="http://www.cs.columbia.edu/~hgs/os/sync.html">Synchronization primitives</a></p> </li> 
    <li> <p>StackOverflow - <a href="https://stackoverflow.com/questions/8017507/definition-of-synchronization-primitive">Definition of “synchronization primitive”</a></p> </li> 
    <li> <p>StackOverflow - <a href="https://stackoverflow.com/questions/2332765/lock-mutex-semaphore-whats-the-difference">Lock, mutex, semaphore… what’s the difference?</a></p> </li> 
    <li> <p>StackOverflow - <a href="https://stackoverflow.com/questions/11173532/why-is-locking-a-stdmutex-twice-undefined-behaviour">Why is locking a std::mutex twice 'Undefined Behaviour'?</a></p> </li> 
    <li> <p>Operating Systems: Three Easy Pieces - <a href="http://pages.cs.wisc.edu/~remzi/OSTEP/">Concurrency</a></p> </li> 
    <li> <p>Jaka’s Corner - <a href="http://jakascorner.com/blog/2016/01/data-races.html">Data race and mutex</a></p> </li> 
    <li> <p>Java 10 API specs - <a href="https://docs.oracle.com/javase/10/docs/api/java/util/concurrent/Semaphore.html">Class Semaphore</a></p> </li> 
    <li> <p>Oracle’s Multithreaded Programming Guide - <a href="https://docs.oracle.com/cd/E19455-01/806-5257/6je9h032t/index.html">Read-Write Lock Attributes</a></p> </li> 
    <li> <p>Oracle’s Multithreaded Programming Guide - <a href="https://docs.oracle.com/cd/E19455-01/806-5257/6je9h0347/index.html">Avoiding Deadlock</a></p> </li> 
    <li> <p>Just Software Solutions - <a href="https://www.justsoftwaresolutions.co.uk/threading/locks-mutexes-semaphores.html">Locks, Mutexes, and Semaphores: Types of Synchronization Objects</a></p> </li> 
    <li> <p>Just Software Solutions - <a href="https://www.justsoftwaresolutions.co.uk/threading/non_blocking_lock_free_and_wait_free.html">Definitions of Non-blocking, Lock-free and Wait-free</a></p> </li> 
    <li> <p>Cppreference - <a href="https://en.cppreference.com/w/cpp/thread/shared_mutex">std::shared_mutex</a></p> </li> 
    <li> <p>Cppreference - <a href="https://en.cppreference.com/w/cpp/thread/condition_variable">std::condition_variable</a></p> </li> 
    <li> <p>Quora - <a href="https://www.quora.com/What-is-the-difference-between-a-mutex-and-a-semaphore">What is the difference between a mutex and a semaphore?</a></p> </li> 
    <li> <p>gerald-fahrnholz.eu - <a href="http://www.gerald-fahrnholz.eu/sw/online_doc_multithreading/html/group___grp_condition_variable_safe_way.html">Using condition variables - the safe way</a></p> </li> 
    <li> <p>Politecnico di Milano - <a href="http://home.deib.polimi.it/loiacono/uploads/Teaching/CP/CP_04_Pthread_CondVar.pdf">Thread Posix: Condition Variables</a></p> </li> 
    <li> <p>SoftwareEngineering - <a href="https://softwareengineering.stackexchange.com/questions/186842/spurious-wakeups-explanation-sounds-like-a-bug-that-just-isnt-worth-fixing-is">Spurious wakeups explanation sounds like a bug that just isn’t worth fixing, is that right?</a></p> </li> 
    <li> <p>Android Open Source Project - <a href="https://source.android.com/devices/audio/avoiding_pi">Avoiding Priority Inversion</a></p> </li> 
   </ul> 
  </div> 
  <div class="paragraph"> 
   <p>本文译自https://www.internalpointers.com/post/introduction-thread-synchronization，英文读者可直接阅读原文。</p> 
  </div> 
 </div> 
</div></p>
  		<a href="blog/2020/02/a-gentle-introduction-to-multithreading.html"><h1>多线程简介: 一步一步走进并发的世界</h1></a>
  		<p>
			<a href="/about.html"><strong>George Cao</strong></a>于2020年02月20日
					<span class="badge badge-dark">并行</span>
					<span class="badge badge-dark">并发</span>
					<span class="badge badge-dark">多线程</span>
					<span class="badge badge-dark">进程</span>
					<span class="badge badge-dark">线程</span>
		</p>
  		<p><div id="preamble"> 
 <div class="sectionbody"> 
  <div class="paragraph"> 
   <p>现代计算机有同时执行多个任务的能力。在高级硬件和更智能的操作系统的支持下，计算机的这个能力能够让你的程序在执行时间和响应速度两方面体现的更快。</p> 
  </div> 
  <div class="paragraph"> 
   <p>开发利用这个能力的软件是既有趣又需要技巧：它要求你理解计算机的底层细节。在本系列的第一篇文章中，我尝试浅显介绍一下<strong>线程（thread）</strong>。操作系统为做到同时执行多个任务提供了很多工具，线程是其一。</p> 
  </div> 
  <div class="ulist"> 
   <div class="title">
    本系列中的其他文章
   </div> 
   <ul> 
    <li> <p><a href="https://www.reploop.org/blog/2020/02/introduction-to-thread-synchronization.html">线程同步简介</a> - 多线程应用中最常见的并发控制方法之一</p> </li> 
    <li> <p><a href="https://www.reploop.org/blog/2020/02/lock-free-multithreading-with-atomic-operations.html">用原子操作实现无锁多线程</a> - 底层线程同步</p> </li> 
    <li> <p><a href="https://www.reploop.org/blog/2020/02/understanding-memory-reordering.html">理解内存重排序</a> - 为什写无锁多线程代码时它很重要</p> </li> 
   </ul> 
  </div> 
 </div> 
</div> 
<div class="sect1"> 
 <h2 id="进程与线程用正确的方式命名">进程与线程：用正确的方式命名</h2> 
 <div class="sectionbody"> 
  <div class="paragraph"> 
   <p>现代操作系统能够同时执行多个程序。这就是你在用浏览器（一个程序）看这篇文章的同时还能够用多媒体播放器（另一个程序）听音乐的原因。每个程序就是一个正在被执行的<strong>进程（process）</strong>。操作系统知道许多软件层面的技巧，或者利用底层硬件使得多个程序并行执行。不管那种方式，最终结果就是你<em>感觉</em>到所有的程序就是同时运行的。</p> 
  </div> 
  <div class="paragraph"> 
   <p>在操作系统中运行多个进程不是同时执行多个任务的唯一办法。每个进程内部可以同时运行多个子任务，称之为<strong>线程</strong>。你可以把线程看作是进程的一部分。 每个进程在启动时会至少会创建1个线程，这个线程叫做<strong>主线程(main thread)</strong>。然后，根据程序或者程序员的需要，更多的线程会被启动或者中止。<strong>多线程技术(Multithreading)</strong> 是指在一个进程内运行多个线程。</p> 
  </div> 
  <div class="paragraph"> 
   <p>例如，多媒体播放器可能是多线程的：1个线程负责绘制界面（通常是主线程），另1个线程则负责播放音乐，如此类推。</p> 
  </div> 
  <div class="paragraph"> 
   <p>你可以把操作系统看作是包含了多个进程的容器。而每个进程则是包含了多个线程的容器。这篇文章中，我只会将重点放在线程上，但是整个主题是非常有趣的，在未来的文章会会有更深入的分析。</p> 
  </div> 
  <div class="imageblock"> 
   <div class="content"> 
    <img src="https://www.reploop.org/blog/2020/02/images/processes-threads.png" alt="Processes vs Threads"> 
   </div> 
   <div class="title">
    Figure 1. 操作系统可看作高包含多个进程的盒子，而进程则是包含了至少一个线程的盒子
   </div> 
  </div> 
  <div class="sect2"> 
   <h3 id="进程与线程的不同之处">进程与线程的不同之处</h3> 
   <div class="paragraph"> 
    <p>每个进程都有操作系统为其分配的内存块。默认情况下，进程的内存块不能够和其他进程共享：你的浏览器是不能访问分配给多媒体播放器的内存块的，反之亦然。如果你运行一个程序的两个<strong>实例(instances)</strong>，规则也是一样的。比如你打开2个浏览器。操作系统把每个实例看作是一个新的拥有独立内存块的进程。所以，默认情况下，2个或者更多的进程之间没法共享数据，除非使用高级的技巧，也就是所谓的<strong>进程间通信(<a href="https://en.wikipedia.org/wiki/Inter-process_communication">IPC</a>)</strong>。</p> 
   </div> 
   <div class="paragraph"> 
    <p>不像进程，线程则共享了操作系统分配给其所在进程的内存块：多媒体播放器的音频引擎可很容易的访问播放器界面上的数据，反之亦然。因此线程间通信要比进程间通信容易多了。更重要的是，线程通常比进程轻量：线程占用较少的资源并且创建速度更快，这也是线程被称为<strong>轻量级进程(lightweight processes)</strong>的原因。</p> 
   </div> 
   <div class="paragraph"> 
    <p>线程是同时执行多个操作的更方便的办法。没有线程，你需要为每个任务写一个程序，然后按进程运行并且通过操作系统来同步这些进程。这样会更难（IPC需要技巧）而且慢（进程比线程更重量级）。</p> 
   </div> 
  </div> 
  <div class="sect2"> 
   <h3 id="绿色线程或纤程">绿色线程，或纤程</h3> 
   <div class="paragraph"> 
    <p>到目前为止，线程是操作系统级别的：一个进程启动一个线程需要和操作系统交互。但是并不是每种操作系统都原生支持线程。<strong>绿色线程(Green threads)</strong>，也称为<strong>纤程(fibers)</strong>是一种在不支持线程的环境下通过软件模拟的多线程从而使得多线程程序能够工作。比如一个虚拟机可能会实现绿色线程以防底层依赖的操作系统不支持原生的线程。</p> 
   </div> 
   <div class="paragraph"> 
    <p>绿色线程能够更快的创建和管理，因为绿色线程完全绕过了操作系统。但是也有其不足之处。我会在后续的文章中写这个主题。</p> 
   </div> 
   <div class="paragraph"> 
    <p>『绿色线程』的名字是指90年代太阳微系统公司的内最初设计Java线程库的『绿色团队』。今天Java不在使用绿色线程了，2000年的时候Java从绿色线程切换到操作系统原生线程了。有部分其他语言（随便举几个例子Go，Haskell或者Rust）实现了原生线程对应的绿色线程。</p> 
   </div> 
  </div> 
 </div> 
</div> 
<div class="sect1"> 
 <h2 id="线程用来干什么的">线程用来干什么的</h2> 
 <div class="sectionbody"> 
  <div class="paragraph"> 
   <p>为啥一个进程要使用多个线程？ 如前所述，并行做事能够很大程度上加快速度。比如你准备用电影编辑器渲染一部电源，电影编辑器能够智能的把渲染任务分散到多个线程，每个线程处理这部电影的一部分。那么如果单线程执行这个任务要话1小时，用2个线程可能只需要30分钟，用4个线程可能只需要15分钟，依此类推。</p> 
  </div> 
  <div class="paragraph"> 
   <p>真的如此简单吗？有3个重要的点要考虑：</p> 
  </div> 
  <div class="olist arabic"> 
   <ol class="arabic"> 
    <li> <p>并不是每个程序都需要多线程运行。如果你的程序执行串行操作或者经常等待用户做一些事情，多线程可能并不会有多大好处；</p> </li> 
    <li> <p>你不能不停的创建线程来让他运行更快：每个子任务都要仔细的思考和设计，才能执行并行操作。</p> </li> 
    <li> <p>不能百分百的保证所有的线程是真正的平行执行的。也就是在<strong>同一时刻</strong>，是否真的并行取决于底层硬件。</p> </li> 
   </ol> 
  </div> 
  <div class="paragraph"> 
   <p>最后一点比较关键：如果你的计算机不支持同时执行多个操作，那么操作系统就要模拟多线程。我们马上就会看到如何做了。 目前而言，让我们把<strong>并发(concurrency)</strong>认为是我们感觉多个任务在同时执行，而把<strong>真正的并行(true parallelism)</strong>认为是多个任务真正的同时执行。</p> 
  </div> 
  <div class="imageblock"> 
   <div class="content"> 
    <img src="https://www.reploop.org/blog/2020/02/images/concurrency-parallelism.png" alt="Concurrency vs Parallelism"> 
   </div> 
   <div class="title">
    Figure 2. 并行是并发的子集。
   </div> 
  </div> 
 </div> 
</div> 
<div class="sect1"> 
 <h2 id="并发和并行的背后原理">并发和并行的背后原理</h2> 
 <div class="sectionbody"> 
  <div class="paragraph"> 
   <p>计算机中的中央处理单元(CPU)是真正负责运行程序的。它有几部分构成，主要部分就是所谓的<strong>核（core）</strong>：所有的计算都是在核上执行的。一个核一次只能执行一个操作。</p> 
  </div> 
  <div class="paragraph"> 
   <p>这当然也是一个主要缺点。 由于这个原因，操作系统发展出许多高级的技术才让用户能够一次运行多个进程（或者线程），特别是图形界面环境甚至是单核机器上。最重要的一个是<strong>抢占式多任务(preemptive multitasking)</strong>技术。其中<strong>抢占式(preemption)</strong>是指操作系统能够中断当前正在运行的任务，切换到另一个任务并且一段时间之后还能够继续执行之前被中断的程序。</p> 
  </div> 
  <div class="paragraph"> 
   <p>所以如果你的CPU是单核的，操作系统的部分工作就是将单核的算力分配给多个进程或者线程，这些进程或者线程是一个接着一个的不停执行的。这个操作会让你有个幻觉至少2个程序在并行运行，或者某个程序在同时做多个事情（如果是多线程程序的话）。并发是满足了，但是真正的平行，也就是<em>同时</em>运行多个进程的能力还是缺失的。</p> 
  </div> 
  <div class="paragraph"> 
   <p>今天现代CPU有不止1个核，而且同一时刻，每个核都可以独立的执行操作。 拥有2个或者更多的核心意味着真正的并行是可能的。例如，我的Intel Core i7是4核的：也就是说在某个时刻，它可以同时运行4个不同的进程或者线程。</p> 
  </div> 
  <div class="paragraph"> 
   <p>操作系统能够检测到CPU的核数并且分配进程或者线程给每个单独的核。操作系统可以调度自己喜欢的任意的核给一个线程，并且这种类型的调度对正在运行的程序是完全透明的。除此之外，抢占式多线程技术也可能在所有的核心都被占用的情况下生效。这能够让你运行多于机器实际拥有的核心数的程序。</p> 
  </div> 
  <div class="sect2"> 
   <h3 id="多线程应用程序跑在单核上有意义吗">多线程应用程序跑在单核上：有意义吗？</h3> 
   <div class="paragraph"> 
    <p>在单核机器上是不可能实现真正的并行的。 不过如果你的应用程序能从中获益的话，写一个多线程程序仍然是有意义的。当一个应用程序使用了多线程，抢占式多任务技术能够让该应用跑起来，那怕是其中有些线程执行的是很慢的或者阻塞的任务。</p> 
   </div> 
   <div class="paragraph"> 
    <p>比如你正在开发一个桌面应用程序从非常慢的磁盘上读出数据。如果你仅仅用单线程写这个程序，整个应用就会卡死，直到磁盘操作完成：被分配给唯一线程的CPU再等待磁盘唤醒的过程中完全浪费了。当然操作系统可以运行除此之外的其他程序，但是你的这个应用程序不会有任何响应了。</p> 
   </div> 
   <div class="paragraph"> 
    <p>我们来用多线程重新考虑这个应用。 线程A负责磁盘读取，同时线程B负责主界面。如果线程A卡在等待很慢的设备，线程B仍然再运行主界面，这就能保证你的应用程序有响应。这是因为有2个线程的话，操作系统可以在2个线程之间切换CPU资源，这样就不用卡在那个慢的上。</p> 
   </div> 
  </div> 
 </div> 
</div> 
<div class="sect1"> 
 <h2 id="线程越多问题越多">线程越多，问题越多</h2> 
 <div class="sectionbody"> 
  <div class="paragraph"> 
   <p>如我们所知，线程会共享所在进程的内存块。这极大的简化了一个进程中2个或者多个线程之间交换数据。例如；一个电影编辑器可能持有了共享内存中包含视频时间线的一大部分。这部分共享内存会被多个用于渲染影片的工作线程访问。所有这些线程仅仅需要内存的一个句柄（比如指针）来读取数据并且将渲染后的帧写到磁盘上。</p> 
  </div> 
  <div class="paragraph"> 
   <p>只要所有的线程都从内存中<em>读取</em>数据，程序就能够平滑运行。但是只要有一个线程<em>写入</em>共享内存，同时其他线程读取共享内存就会引起问题。在这种情况下会产生两种问题:</p> 
  </div> 
  <div class="ulist"> 
   <ul> 
    <li> <p><strong>数据竞争</strong> - 当一个写线程在修改内存的时候， 一个读线程可能正在读内存。 如果写线程没有完成写入， 读线程就会得的损坏的数据；</p> </li> 
    <li> <p><strong>竞争条件</strong> - 一个读线程只有在写线程写入数据之后才应该读数据。如果顺序反过来会怎样？比数据竞争更难理解，竞争条件是指2个或以上的线程以不可预知的顺序执行，事实上这些操作需要按照合适的顺序执行才能得到正确的结果。你的程序可触发竞争条件，即使是它已经有数据竞争保护。</p> </li> 
   </ul> 
  </div> 
  <div class="sect2"> 
   <h3 id="线程安全性的概念">线程安全性的概念</h3> 
   <div class="paragraph"> 
    <p>我们说一段程序是线程安全的，是说这段程序能够正确工作，即使多个线程同时执行，也没有数据竞争或者竞争条件。你可能已经发现了一些程序类库声称自己是线程安全的：如果你正在写一个多线程程序，你要确保任何第三方函数可以在多个线程间调用而不会触发并发问题。</p> 
   </div> 
  </div> 
 </div> 
</div> 
<div class="sect1"> 
 <h2 id="数据竞争的根本原因">数据竞争的根本原因</h2> 
 <div class="sectionbody"> 
  <div class="paragraph"> 
   <p>我们知道一个CPU核某一时刻只能执行一条机器指令。 这种指令是<strong>原子的(atomic)</strong>，因为他不能再细分了：它不能再细分为更小的操作了。『atom』在希腊语中是<em>不可再分割</em>的意思。</p> 
  </div> 
  <div class="paragraph"> 
   <p>不能再细分的性质使得原子操作是天然的线程安全的。当一个线程执行一个原子写数据操作，没有其他线程能够读到未完成修改的数据。相反的，当一个线程执行一个原子读操作，它能读出完整的数据。线程是不能干扰一次原子操作的，因此也不会有数据竞争发生。</p> 
  </div> 
  <div class="paragraph"> 
   <p>坏消息是大部分操作都不是原子的。即使一个简单的赋值操作如<code>x = 1</code>在一些硬件上也可能是由多个原子机器指令组成的，这就造成了这个赋值语句本身不是一个原子操作。当一个线程读取<code>x</code>的值而另一个现在正在赋值就会触发数据竞争。</p> 
  </div> 
 </div> 
</div> 
<div class="sect1"> 
 <h2 id="竞争条件的根本原因">竞争条件的根本原因</h2> 
 <div class="sectionbody"> 
  <div class="paragraph"> 
   <p>抢占式多任务技术给了操作系统对线程管理的完全控制：根据高级调度算法，它可以启动，停止和暂停线程。作为程序员是控制不了程序执行的时间或者顺序的。事实上，没有任何保证如下这段简单的程序：</p> 
  </div> 
  <div class="listingblock"> 
   <div class="content"> 
    <pre class="highlight"><code class="language-c" data-lang="c">writer_thread.start()
reader_thread.start()</code></pre> 
   </div> 
  </div> 
  <div class="paragraph"> 
   <p>能够按照书写顺序依次启动2个线程。多运行几次这段程序，你就会发现每次执行之间的不同表现：有时候写线程先启动，有时候确实读线程先启动。如果你的程序需要写线程总是先于读线程启动，这就一定会碰到竞争条件。</p> 
  </div> 
  <div class="paragraph"> 
   <p>这个行为称为<strong>不确定性(non-deterministic)</strong>：每次执行的结果是变化的而且你不能预测到。调试竞争条件相关的程序是非常讨厌的，因为你不能用受控的方式每次都重现此问题。</p> 
  </div> 
 </div> 
</div> 
<div class="sect1"> 
 <h2 id="让线程和平共处并发控制">让线程和平共处：并发控制</h2> 
 <div class="sectionbody"> 
  <div class="paragraph"> 
   <p>数据竞争和竞争条件都是真实世界中的问题：一些人甚至是<span class="underline"><a href="https://en.wikipedia.org/wiki/Therac-25">因此而丧命</a></span>。协调2个或者更多并发线程的技术叫<strong>并发控制(concurrency control)</strong>：操作系统和编程语言提供了处理并发控制的一些解决方案。最重要的一些方案如下：</p> 
  </div> 
  <div class="ulist"> 
   <ul> 
    <li> <p><strong>同步</strong> - 保证资源某一时刻只能被一个线程使用的方法。同步方法将特定代码块保护起来，使得2个或者更多的并发线程不能同时执行它，否则就会损坏你的共享数据；</p> </li> 
    <li> <p><strong>原子操作</strong> - 由于操作系统提供了一些特殊的指令，使得一批非原子操作（如上文提到的赋值操作）可以被转化为原子操作。这样的话共享数据总是有效的状态，不论其他线程如何访问它。</p> </li> 
    <li> <p><strong>不可变数据</strong> - 共享数据被标记为不可变的，谁都不能修改它：线程只允许读数据，消除了根本原因。 就像我们所知的，线程可以安全的从同样的内存读数据，只要这个数据不会被修改。这也是<span class="underline"><a href="https://en.wikipedia.org/wiki/Functional_programming">函数式编程</a></span>背后的主要哲学。</p> </li> 
   </ul> 
  </div> 
  <div class="paragraph"> 
   <p>我会在这个关于并发的迷你系列的后续文章中讨论这些有趣的主题，保持关注。</p> 
  </div> 
 </div> 
</div> 
<div class="sect1"> 
 <h2 id="参考">参考</h2> 
 <div class="sectionbody"> 
  <div class="ulist"> 
   <ul> 
    <li> <p>8 bit avenue - <a href="https://www.8bitavenue.com/difference-between-multiprogramming-multitasking-multithreading-and-multiprocessing/">Difference between Multiprogramming, Multitasking, Multithreading and Multiprocessing</a></p> </li> 
    <li> <p>Wikipedia - <a href="https://en.wikipedia.org/wiki/Inter-process_communication">Inter-process communication</a></p> </li> 
    <li> <p>Wikipedia - <a href="https://en.wikipedia.org/wiki/Process_%28computing%29">Process (computing)</a></p> </li> 
    <li> <p>Wikipedia - <a href="https://en.wikipedia.org/wiki/Concurrency_%28computer_science%29">Concurrency (computer science)</a></p> </li> 
    <li> <p>Wikipedia - <a href="https://en.wikipedia.org/wiki/Parallel_computing">Parallel computing</a></p> </li> 
    <li> <p>Wikipedia - <a href="https://en.wikipedia.org/wiki/Multithreading_%28computer_architecture%29">Multithreading (computer architecture)</a></p> </li> 
    <li> <p>Stackoverflow - <a href="https://stackoverflow.com/questions/1713554/threads-processes-vs-multithreading-multicore-multiprocessor-how-they-are">Threads &amp; Processes Vs MultiThreading &amp; Multi-Core/MultiProcessor: How they are mapped?</a></p> </li> 
    <li> <p>Stackoverflow - <a href="https://stackoverflow.com/questions/19225859/difference-between-core-and-processor">Difference between core and processor?</a></p> </li> 
    <li> <p>Wikipedia - <a href="https://en.wikipedia.org/wiki/Thread_%28computing%29">Thread (computing)</a></p> </li> 
    <li> <p>Wikipedia - <a href="https://en.wikipedia.org/wiki/Computer_multitasking">Computer multitasking</a></p> </li> 
    <li> <p>Ibm.com - <a href="https://www.ibm.com/support/knowledgecenter/en/ssw_aix_71/generalprogramming/benefits_threads.html">Benefits of threads</a></p> </li> 
    <li> <p>Haskell.org - <a href="https://wiki.haskell.org/Parallelism_vs._Concurrency">Parallelism vs. Concurrency</a></p> </li> 
    <li> <p>Stackoverflow - <a href="https://stackoverflow.com/questions/16116952/can-multithreading-be-implemented-on-a-single-processor-system">Can multithreading be implemented on a single processor system?</a></p> </li> 
    <li> <p>HowToGeek - <a href="https://www.howtogeek.com/194756/cpu-basics-multiple-cpus-cores-and-hyper-threading-explained/">CPU Basics: Multiple CPUs, Cores, and Hyper-Threading Explained</a></p> </li> 
    <li> <p>Oracle.com - <a href="https://docs.oracle.com/cd/E19205-01/820-0619/geojs/index.html">1.2 What is a Data Race?</a></p> </li> 
    <li> <p>Jaka’s corner - <a href="http://jakascorner.com/blog/2016/01/data-races.html">Data race and mutex</a></p> </li> 
    <li> <p>Wikipedia - <a href="https://en.wikipedia.org/wiki/Thread_safety">Thread safety</a></p> </li> 
    <li> <p>Preshing on Programming - <a href="https://preshing.com/20130618/atomic-vs-non-atomic-operations/">Atomic vs. Non-Atomic Operations</a></p> </li> 
    <li> <p>Wikipedia - <a href="https://en.wikipedia.org/wiki/Green_threads">Green threads</a></p> </li> 
    <li> <p>Stackoverflow - <a href="https://stackoverflow.com/questions/617787/why-should-i-use-a-thread-vs-using-a-process">Why should I use a thread vs. using a process?</a></p> </li> 
   </ul> 
  </div> 
  <div class="paragraph"> 
   <p>本文译自https://www.internalpointers.com/post/gentle-introduction-multithreading，英文读者可直接阅读原文。</p> 
  </div> 
 </div> 
</div></p>

	<hr />
	
	<p><a href="../archive.html">点击查看更多文章</a>.</p>

		</div>
		<div id="push"></div>
    </div>
    
    <div id="footer">
      <div class="container">
        <p class="muted credit">&copy; 2020 | Mixed with <a href="http://getbootstrap.com/">Bootstrap v3.1.1</a> | Baked with <a href="http://jbake.org">JBake v2.7.0.8</a></p>
      </div>
    </div>
    
    <!-- Le javascript
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="../js/jquery-1.11.1.min.js"></script>
    <script src="../js/bootstrap.min.js"></script>
    <script src="../js/prettify.js"></script>


<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  messageStyle: "none",
  tex2jax: {
    inlineMath: [["\\(", "\\)"]],
    displayMath: [["\\[", "\\]"]],
    ignoreClass: "nostem|nolatexmath"
  },
  asciimath2jax: {
    delimiters: [["\\$", "\\$"]],
    ignoreClass: "nostem|noasciimath"
  },
  TeX: { equationNumbers: { autoNumber: "none" } }
})
MathJax.Hub.Register.StartupHook("AsciiMath Jax Ready", function () {
  MathJax.InputJax.AsciiMath.postfilterHooks.Add(function (data, node) {
    if ((node = data.script.parentNode) && (node = node.parentNode) && node.classList.contains('stemblock')) {
      data.math.root.display = "block"
    }
    return data
  })
})
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_HTMLorMML"></script>
  </body>
</html>